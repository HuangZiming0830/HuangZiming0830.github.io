<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Computer Network</title>
      <link href="/2023/11/22/computer-network/"/>
      <url>/2023/11/22/computer-network/</url>
      
        <content type="html"><![CDATA[<ul><li>电路交换、报文交换、分组交换</li></ul>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> technology </tag>
            
            <tag> network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computor Operator</title>
      <link href="/2023/11/22/computor-operator/"/>
      <url>/2023/11/22/computor-operator/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解计算机系统"><a href="#深入理解计算机系统" class="headerlink" title="深入理解计算机系统"></a>深入理解计算机系统</h1><h2 id="Chapter-One"><a href="#Chapter-One" class="headerlink" title="Chapter One"></a>Chapter One</h2><ul><li>预处理器、编译器、汇编器、链接器</li><li>总线、I/O设备、主存（DRAM动态随机存取存储器）、处理器</li><li>进程（上下文切换、线程）、虚拟存储器（程序代码和数据、堆、共享库、栈、内核虚拟存储器）、文件<h2 id="Chapter-Two-信息表示和处理"><a href="#Chapter-Two-信息表示和处理" class="headerlink" title="Chapter Two 信息表示和处理"></a>Chapter Two 信息表示和处理</h2></li><li>long int &amp; char * : 机器全字长</li><li>小端法：最低有效字节在最前面</li><li>使用ASCII码作为字符码的任何系统都将得到相同的结果</li><li>&amp;&amp; || 存在短路情况，即依据第一个表达式结果判断</li><li>算术右移补最高有效位拷贝，逻辑右移补0</li></ul>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> technology </tag>
            
            <tag> Operator </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>毛选</title>
      <link href="/2023/11/20/mao-xuan/"/>
      <url>/2023/11/20/mao-xuan/</url>
      
        <content type="html"><![CDATA[<h2 id="中国社会各阶级的分析"><a href="#中国社会各阶级的分析" class="headerlink" title="中国社会各阶级的分析"></a>中国社会各阶级的分析</h2><ul><li>地主阶级和买办阶级：最落后和最反动的生产关系，极端的反革命派</li><li>中产阶级：城乡资本主义的生产关系。民族资产阶级</li><li>小资产阶级：左派、中派、右派</li><li>半无产阶级</li><li>无产阶级：新生产力的代表者，最进步的阶级。<br>一切勾结帝国主义的军阀、官僚、买办阶级、大地主阶级以及附属于他们的一部分反动知识界，是我们的敌人。工业无产阶级是我们革命的领导力量。一切半无产阶级、小资产阶级，是我们最接近的朋友。动摇不定的中产阶级，要时常提防，不要让他们扰乱了我们的阵线。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Books </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Party </tag>
            
            <tag> Mao </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nerf: 3D content generation</title>
      <link href="/2023/11/18/nerf-3d-content-generation/"/>
      <url>/2023/11/18/nerf-3d-content-generation/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Tmux</title>
      <link href="/2023/03/27/tmux/"/>
      <url>/2023/03/27/tmux/</url>
      
        <content type="html"><![CDATA[<h1 id="Tmux"><a href="#Tmux" class="headerlink" title="Tmux"></a>Tmux</h1><h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><pre class="line-numbers language-linux"><code class="language-linux">    tmux new -s <session_name>    # 分离session,即使终端窗口关闭也可在后台继续运行进程    tmux detach    # 接入session    tmux attach -t <session_name>    tmux ls    tmux switch -t <session_name>    tmux kill-session -t <session_name>    tmux rename-session -t <old_name> <new_name><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Window"><a href="#Window" class="headerlink" title="Window"></a>Window</h2><pre class="line-numbers language-linux"><code class="language-linux">    tmux new-window    tmux new-window -n <window_name>    tmux select-window -t <window_number>/<window_name>    tmux rename-window <new_name><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Pane"><a href="#Pane" class="headerlink" title="Pane"></a>Pane</h2><p>对于一个session进行不同的操作，将窗口分割成多个区域分别进行</p><pre class="line-numbers language-linux"><code class="language-linux">    tmux split-window -h    # 切换光标    tmux select-pane -U/D/L/R    # 切换窗格    tmux swap-pane -U/-D<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>ElementTree</title>
      <link href="/2023/03/27/elementtree/"/>
      <url>/2023/03/27/elementtree/</url>
      
        <content type="html"><![CDATA[<h1 id="xml文件解析"><a href="#xml文件解析" class="headerlink" title="xml文件解析"></a>xml文件解析</h1><h2 id="xml-etree-ElementTree"><a href="#xml-etree-ElementTree" class="headerlink" title="xml.etree.ElementTree"></a>xml.etree.ElementTree</h2><pre class="line-numbers language-python"><code class="language-python">    tree <span class="token operator">=</span> ET<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>file<span class="token punctuation">)</span>    root <span class="token operator">=</span> tree<span class="token punctuation">.</span>getroot<span class="token punctuation">(</span><span class="token punctuation">)</span>    size <span class="token operator">=</span> root<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'size'</span><span class="token punctuation">)</span>    height <span class="token operator">=</span> int<span class="token punctuation">(</span>size<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'height'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span>    <span class="token keyword">for</span> obj <span class="token keyword">in</span> root<span class="token punctuation">.</span>iter<span class="token punctuation">(</span><span class="token string">'object'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        cls <span class="token operator">=</span> obj<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'name'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/02/14/bagu/"/>
      <url>/2023/02/14/bagu/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习八股文"><a href="#机器学习八股文" class="headerlink" title="机器学习八股文"></a>机器学习八股文</h1><h2 id="Machine-Leaning"><a href="#Machine-Leaning" class="headerlink" title="Machine Leaning"></a>Machine Leaning</h2><h3 id="ML-基础概念"><a href="#ML-基础概念" class="headerlink" title="ML 基础概念"></a>ML 基础概念</h3><ol><li><p>Overfitting / Underfitting  </p><p><strong>过拟合</strong>指模型与数据的匹配程度过高，将训练数据一些正常的起伏、波动、异常值也当作是数据的特征，导致模型对新数据的泛化能力变差。具体的表现为在训练集上表现非常优秀，而在验证集/测试集中表现非常差。</p><ul><li>解决过拟合的方法一般有：1) 适量减少特征的数量；2) 添加<strong>正则化项</strong>(Regularization)。正则化，顾名思义，目的是为了降低特征对于预测结果的影响能力。常见的正则化项有L1正则项和L2正则项。详见正则化。</li></ul><p> <strong>欠拟合</strong>与过拟合相反，指的是模型缺乏足够的泛化能力。</p><ul><li>解决欠拟合的方法有：1) 增加训练轮数；2) 增加模型特征；3) 减少正则项。</li></ul></li><li><p>Bias / Variance trade-off</p><p> 偏差(Bias)指模型预测结果与真实值的差异程度，描述了模型的拟合能力；方差(Varience)指模型面对不同数据集时的差异程度，描述了数据扰动对模型的影响。<br> 一般来说，越简单模型的偏差越高，方差越低；越复杂模型的偏差越低，方差越高。这同样也对应着模型的过拟合与欠拟合。</p><p> 权衡偏差与方差的常见方法有<strong>交叉认证</strong>(Cross-Validation)。K折交叉验证的基本方法为：将训练集平均分为$k$份，每次训练取其中一份作为验证集，剩下$k-1$份作为训练集，重复$k$次，直到每一份小数据集都被作为过验证集。最终的损失为$k$次训练的损失取平均。</p></li></ol><h3 id="正则化-Regularization"><a href="#正则化-Regularization" class="headerlink" title="正则化 Regularization"></a>正则化 Regularization</h3><ol><li><p>L1 vs L2</p><ul><li><p>L1正则化，又称LASSO、L1范数，是所有参数的绝对值之和。<br>  $$\lVert x \lVert_1=\sum_{i=1}^m\lvert x_i \lvert$$</p></li><li><p>L2正则化，又称Ridge，岭回归，是所有参数的平方和的平方根。</p><p>  $$</p><pre><code>  \lVert x \lVert_2=\sqrt{\sum_{i=1}^m x_i^2}</code></pre><p>  $$</p></li><li><p>两种范数都有助于降低过拟合风险。L1范数可以用于<strong>特征选择</strong>，但不能直接求导，因此不能使用常规的梯度下降法/牛顿法等进行优化（常见方法有坐标轴下降法和 Lasso 回归法）；L2范数方便求导。</p></li></ul></li><li><p>L1范数的稀疏性 / 为何L1正则化可以用于特征选择？</p><p> L1范数相比于L2范数，更容易得到<strong>稀疏解</strong>，即L1范数可以将不重要的特征参数优化至<strong>0</strong>.</p><ul><li>如何理解？<blockquote><p>假设损失函数 $L$ 与某个参数 $x$ 的关系如下图所示：此时最优点位于红色点处，$x&lt;0$.</p><p><img src="imgs/l1vsl2_01.jpg" alt="l1vsl2_01"></p><p>这时施加 L2 正则化，新的损失函数 $(L+Cx^2)$ 如下图黄线所示，可以看到最优的 $x$ 在蓝点处，$x$ 的绝对值减小了，但依然非零。</p><p><img src="imgs/l1vsl2_02.jpg" alt="l1vsl2_02"></p><p>而如果施加 L1 正则化，则新的损失函数 $(L+C\lvert x \lvert)$ 如下图绿线所示，最优的 $x$ 就变成了 0。</p><p><img src="imgs/l1vsl2_03.jpg" alt="l1vsl2_03"></p><p>略加推导可以得到，当施加 L2 正则化时，当且仅当损失函数原本的导数为 0 时，损失函数才会在 $x=0$ 处极小；而施加 L1 正则化时，参数 $C$ 与损失函数的导数仅需满足 $C&gt;\lvert L \lvert$ 的关系，$x=0$ 便会成为损失函数的一个极小值点。 </p><p>上面只分析了一个参数 $x$。事实上 L1 正则化会使得许多参数的最优值变成 0，使得模型变得稀疏。利用这样的特性，我们便可以使用L1正则化来帮助筛选特征。</p></blockquote></li></ul></li></ol><h3 id="机器学习中的评估指标-Metrics"><a href="#机器学习中的评估指标-Metrics" class="headerlink" title="机器学习中的评估指标 Metrics"></a>机器学习中的评估指标 Metrics</h3><ol><li><p>Precision / Recall / $F_1$ Score</p><p> 对于二分类问题，我们常常使用精确率(Precision)、召回率(Recall)以及$F_1$ Score来评估二分类模型的性能。对于一个二分类器，在数据集上的预测情况可以分为以下4种：</p><ul><li><p>TP(True Positive)，将正类<strong>正确</strong>预测为正类；</p></li><li><p>TN(True Negative)，将负类<strong>正确</strong>预测为负类；</p></li><li><p>FP(False Positive)，将负类<strong>错误</strong>预测为正类；</p></li><li><p>FN(False Negative)，将正类<strong>错误</strong>预测为负类；</p><p>有了以上概念，我们可以给出以下评估指标的定义：</p></li><li><p>精确率定义为：<br>  $$</p><pre><code>  P=\frac{TP}{TP+FP}</code></pre><p>  $$<br>  即在模型<strong>预测为正类</strong>的样本中，预测正确的比例。可以看到，精确率更加关注于模型认为是正类样本的结果。</p></li><li><p>召回率定义为：<br>  $$</p><pre><code>  R=\frac{TP}{TP+FN}</code></pre><p>  $$<br>  即在正类的样本中，模型预测正确的比例。相比之下，召回率更加关注于那些<strong>真实值为正类</strong>的样本。</p></li><li><p>此外，$F_1$ 值定义为精确率与召回率的调和均值，即<br>  $$</p><pre><code>  \frac{2}{F_1}=\frac{1}{P}+\frac{1}{R}</code></pre><p>  $$<br>  $$</p><pre><code>  F_1 = \frac{2 \times P \times R}{P + R} = \frac{2TP}{2TP+FP+FN}</code></pre><p>  $$<br>  当精确率和召回率都高时，$F_1$ 值也会高。</p></li></ul></li><li><p>混淆矩阵 Confusion Matrix</p><p> 分类结果的混淆矩阵如下表所示。</p><p> <img src="imgs/ConfusionMatrix.jpg" alt="ConfusionMatrix"></p></li><li><p>macro-$F_1$ vs micro-$F_1$</p><p> 很多时候我们有多个二分类混淆矩阵（例如多次训练与测试 / 多个数据集 / 多分类任务中每两两类别的组合等），这是我们希望在 $n$ 个二分类混淆矩阵上综合考察模型性能。</p><ul><li><p>macro-$F_1$</p><p>  一种直接的做法是直接计算各个混淆矩阵的精确率和召回率，再计算平均值，分别得到 macro-$P$、macro-$R$和对应的macro-$F_1$.<br>  $$</p><pre><code>  \text{macro-}P = \frac{1}{n}\sum_{i=1}^n P_i, \qquad  \text{macro-}R = \frac{1}{n}\sum_{i=1}^n R_i,</code></pre><p>  $$<br>  $$</p><pre><code>  \text{macro-}F_1 = \frac{2 \times \text{macro-}P \times \text{macro-}R}{\text{macro-}P + \text{macro-}R}</code></pre><p>  $$</p></li><li><p>micro-$F_1$</p><p>  另一种做法是先将各个混淆矩阵的对应元素进行平均，得到$\overline{TP}$、$\overline{TN}$、$\overline{FP}$和$\overline{FN}$，再基于这些值计算出micro-$P$、micro-$R$和对应的micro-$F_1$.<br>  $$</p><pre><code>  \text{micro-}P = \frac{\overline{TP}}{\overline{TP}+\overline{FP}}, \qquad  \text{micro-}R = \frac{\overline{TP}}{\overline{TP}+\overline{FN}},</code></pre><p>  $$<br>  $$</p><pre><code>  \text{micro-}F_1 = \frac{2 \times \text{micro-}P \times \text{micro-}R}{\text{micro-}P + \text{micro-}R}</code></pre><p>  $$</p></li></ul></li><li><p>ROC 曲线 / AUC 面积</p><p> ROC 曲线(Receiver Operating Characteristic)与 AUC (Area Under ROC Curve)是面对<strong>不平衡分类问题</strong>时最常用的评估指标。要了解 ROC 是什么，首先我们根据混淆矩阵再定义两个指标：True Positive Rate(TPR) 以及 False Positive Rate(FPR). </p><p> $$</p><pre><code> TPR = R = \frac{TP}{TP+FN}, \qquad FPR = \frac{FP}{TN+FP},</code></pre><p> $$<br> 正常来说，一个好的模型应该满足高 TPR 和低 FPR。对于任意一个训练好的模型，在给定测试数据上我们都能计算出它的 TPR 和 FPR。以 FPR 为横坐标，TPR 为纵坐标，我们可以将任意模型的一对 (FPR, TPR) 画在该坐标图中，如下图所示。同时我们将由该坐标轴构成的空间称为 ROC 空间。图1中假设有 A、B、C、D、E 共计五个模型。在 ROC 空间中，模型越靠近左上角，表明模型效果越好。</p><p> <img src="imgs/ROC_01.png" alt="ROC_01"></p><p> 在二分类问题的大多数情况中（尤其是神经网络中），我们判定一个样本是正类和负类的依据是设置一个阈值，超过该阈值的样本被标记为正类，反之则为负类。一般而言，这个阈值被设置为0.5。那么如果我们尝试使用不同的阈值来划分正负类，我们就能得到多组 (FPR, TPR)。我们可以根据这些坐标近似地在 ROC 空间中画出一条曲线，即 <strong>ROC 曲线</strong>。只要 (FPR, TPR) 点足够多，我们可以计算出曲线下的面积，即 <strong>AUC面积</strong>，如下图所示。</p><p> <img src="imgs/ROC_02.png" alt="ROC_02"></p></li></ol><h3 id="Loss与优化"><a href="#Loss与优化" class="headerlink" title="Loss与优化"></a>Loss与优化</h3><ol><li><p>凸优化问题</p><p> 对于一个优化问题，如果其目标函数是<strong>凸函数</strong>，且可行域是<strong>凸集</strong>（集合中任意两点连线上的任意点都在集合内），那么它就是一个凸优化问题。</p><p> 定义域 $\mathbb{D}$ 是一个凸集的函数 $f$ 是凸函数，当且仅当对于任意的 $x,y \in \mathbb{D}$ 和 $\theta \in [0,1]$，都有：</p><p> $$</p><pre><code> f(\theta x+(1-\theta)y) \le \theta f(x)+(1-\theta) f(y)</code></pre><p> $$</p><p> <img src="imgs/convex_func.jpg" alt="convex_func"></p><p> 数学中强调凸优化问题的重要性，在于凸优化问题的<strong>局部最优解</strong>必然也是其<strong>全局最优解</strong>。这个特性使得我们可以使用贪心算法、梯度下降法、牛顿法等方法来求解凸优化问题。事实上，我们求解许多非凸优化问题，也是通过将其拆解为若干个凸优化问题，再分别进行求解。</p></li><li><p>MSE / MSELoss</p><p> 均方误差 (Mean Square Error, MSE)，是回归任务中最常见的度量指标。</p><p> $$</p><pre><code> E(f;D)=\sum_{i=1}^m (f(x_i) - y_i)^2</code></pre><p> $$</p></li><li><p>以 MSELoss 为损失函数的逻辑回归是凸优化问题吗？</p><p> <strong>不是</strong>。逻辑回归将线性模型通过 sigmoid 非线性函数映射为分类问题，其 MSE 是一个非凸函数，优化时可能得到局部最优解而得不到全局最优解，所以以 MSELoss 为损失函数的逻辑回归不是凸优化问题。</p></li></ol><ol start="4"><li><p>线性回归，最小二乘法与最大似然估计的关系？</p><p> 求解线性回归常用的方法有<strong>最小二乘法 (OLS)</strong>和<strong>最大似然估计 (MLE)</strong>。</p><ul><li><p>最小二乘法以预测值和真实值的平方和作为损失函数 (MSELoss)。</p><p>  $$</p><pre><code>  J(w)=\sum_{i=1}^m (h_w(x_i) - y_i)^2</code></pre><p>  $$</p></li><li><p>最大似然估计在已知 $x$ 与 $y$ 的情况下，以<strong>概率最大</strong>的角度，估计模型可能性最大的参数 $h_w$。设误差 $\epsilon_i = y_i - h_w(x_i)$， 由于 $\epsilon_i$ 符合高斯分布，可得概率密度函数：</p><p>  $$</p><pre><code>  p(\epsilon_i) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(\epsilon_i)^2}{2\sigma^2}}</code></pre><p>  $$</p><p>  将 $\epsilon_i = y_i - h_w(x_i)$ 代入，可得：</p><p>  $$</p><pre><code>  p(y_i | h_w(x_i)) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(y_i - h_w(x_i))^2}{2\sigma^2}}</code></pre><p>  $$</p><p>  则似然函数公式如下：</p><p>  $$</p><pre><code>  \begin{aligned}      L(h_w(x_i)) &amp;= \prod_{i=1}^m p(y_i | h_w(x_i))\\      &amp;= \prod_{i=1}^m \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(y_i - h_w(x_i))^2}{2\sigma^2}} \\  \end{aligned}</code></pre><p>  $$</p><p>  等号两边取对数，不影响函数的极值点。</p><p>  $$</p><pre><code>  \begin{aligned}      \log L(h_w(x_i)) &amp;= \sum_{i=1}^m \log \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(y_i - h_w(x_i))^2}{2\sigma^2}}\\      &amp;= m \log \frac{1}{\sigma \sqrt{2\pi}} - \frac{1}{2\sigma^2} \sum_{i=1}^m (y_i - h_w(x_i))^2  \end{aligned}</code></pre><p>  $$</p><p>  我们知道 $h_w(x)$ 是关于权重 $w$ 的函数，不妨设为 $l(w)$。因此有：</p><p>  $$</p><pre><code>  \begin{aligned}      l(w) = m \log \frac{1}{\sigma \sqrt{2\pi}} - \frac{1}{2\sigma^2} \sum_{i=1}^m (y_i - h_w(x_i))^2  \end{aligned}</code></pre><p>  $$</p><p>  去除前面的常数项和常数系数，可以看到与最小二乘法的的公式一致，之后求解过程同最小二乘法。因此得出结论，最小二乘法与最大似然估计从两个不同的角度出发，得到一致的结果。</p></li></ul></li><li><p>相对熵与交叉熵 Ralative-Entropy / Cross-Entropy</p><p> 我们常用<strong>信息量</strong>来量化数据中的信息。设事件 $x_0$ 发生的概率为 $p(x_0)$，则其信息量为：</p><p> $$</p><pre><code> I(x_0) = -\log p(x_0)</code></pre><p> $$</p><p> <strong>熵</strong> (Entropy) 被用来度量一个系统的混乱程度，代表一个系统中所有事件信息量的期望。熵越大，该系统的不确定性也越大。</p><p> $$</p><pre><code> H(X) = -\sum_{x \in X}p(x_i) \log p(x_i)</code></pre><p> $$</p><p> <strong>相对熵</strong> (Ralative Entropy)，又称 <strong>KL 散度</strong> (Kullback-Leibler Divergence)，是两个随机分布 $p$ 与 $q$ 之间的对数差值的期望。</p><p> $$</p><pre><code> D_{KL}(p||q)=\sum_{x\in X} p(x)\log\frac{p(x)}{q(x)}=-\sum_{x\in X} p(x)[\log q(x) - \log p(x)]</code></pre><p> $$</p><p> <strong>交叉熵</strong> (Cross-Entropy)，与 KL 散度类似，是两个随机分布 $p$ 与 $q$ 之间距离的另一种度量。</p><p> $$</p><pre><code> CEH(p,q)=−\sum_{x \in X}p(x)logq(x)</code></pre><p> $$</p><blockquote><p><strong>为何在机器学习中常使用交叉熵而不是 KL 散度作为损失函数？</strong></p><p>可以看到，相对熵、交叉熵之间存在以下关系：</p><p>   $$</p><pre><code>  D_{KL}(p||q) = CEH(p,q) - H(p)</code></pre><p>   $$</p><p>在机器学习中，可以将 $p$ 看作真实分布，$q$ 为预测分布。则当 $p$ 的分布已知时，$H(p)$ 为常数，交叉熵与 KL 散度等价。</p></blockquote></li></ol><pre><code>***在分类问题中***，常使用交叉熵作为损失函数，公式表达如下：* 二分类问题中，交叉熵损失函数为:    $$        L = -\frac{1}{N} \sum_i [y_i \log(p_i) + (1 - y_i) \log (1 - p_i)]    $$* 多分类问题中，交叉熵损失函数为：    $$        L = -\frac{1}{N} \sum_i \sum_c^M [y_{ic} \log (p_{ic})]    $$    其中，$M$ 为类别数量。</code></pre><h3 id="朴素贝叶斯-Naive-Bayes"><a href="#朴素贝叶斯-Naive-Bayes" class="headerlink" title="朴素贝叶斯 Naive Bayes"></a>朴素贝叶斯 Naive Bayes</h3><ol><li><p>概率相关公式及贝叶斯定理</p><ul><li>条件概率：事件 A 在另外一个事件 B 已经发生条件下的发生概率，即 $p(A|B)$；</li><li>联合概率：事件 A 和事件 B 同时发生的概率，即 $p(A, B) = p(A|B) * p(B)$；</li><li>全概率：若事件 B1, B2, …, Bn 构成一个<strong>完备事件组</strong>，即他们两两不相容，且和为全集，则对于任意事件 A 有：<br>$p(A)=\sum^n_{i=1} [p(A|B_i)*p(B_i)]$</li><li>贝叶斯概率：在日常生活中，有时候我们难以直接求出 $p(A_i|B)$，但我们若已知 $p(B|A_i)$，$p(A_i)$ 和 $p(B)$，则有：<br>  $$<pre><code>  p(A_i|B) = \frac{p(B|A_i)*p(A_i)}{p(B)} = \frac{p(B|A_i)*p(A_i)}{\sum^n_{j=1}p(B|A_j)*p(A_j)}</code></pre>  $$<br>  其中，$p(A_i|B)$ 被称为<strong>后验概率</strong>，$p(A_i)$ 被称为<strong>先验概率</strong>。</li></ul></li></ol><ol start="2"><li><p>朴素贝叶斯分类器</p><ul><li>设 $x=\{a_1,a_2,…,a_m\}$ 为一个待分类项，其中 $a_i$ 是 $x$ 的特征属性。</li><li>有类别集合 $C=\{y_1,y_2,…,y_n\}$。</li><li>对每一个类别 $y_i$，统计各个特征属性的条件概率，即 $p(a_1|y_1)$, $p(a_2|y_1)$, …, $p(a_m|y_1)$。</li><li>根据贝叶斯公式，求得 $p(y_i|x)=\frac{p(x|y_i)*p(y_i)}{p(x)}$。</li><li>计算所有类别的 $p(y_i|x)$，概率最大的 $y_k$ 即为预测的类别。</li><li>该分类器之所以被称为“朴素”贝叶斯，是因为模型假设待分类项 $x$ 的所有特征都是<strong>独立的</strong>事件。</li><li>常见的朴素贝叶斯分类器有：<ul><li>GaussianNB，该分类器用<strong>高斯分布</strong>来假设类别的先验概率分布，一般用于连续型数据。</li><li>MultinomialNB，该分类器用<strong>多项式分布</strong>来假设类别的先验概率分布，用于多项式数据。</li><li>BernoulliNB，该分类器用<strong>伯努利分布</strong>来假设类别的先验概率分布，用于二项分布数据。</li></ul></li></ul></li></ol><ol start="3"><li><p>朴素贝叶斯分类器的优缺点</p><p> 朴素贝叶斯分类器的主要优点有：</p><ul><li><p>模型发源于古典数学概论，算法比较简单，且有稳定的分类效率；</p></li><li><p>对小规模的数据表现好，适合多分类任务；</p></li><li><p>对缺失数据不敏感，例如文本分类等任务；</p></li><li><p>不存在过拟合的说法。</p><p>朴素贝叶斯分类器的缺点有：</p></li><li><p>朴素贝叶斯假设特征之间相互独立，但在现实中这个假设往往不成立；</p></li><li><p>朴素贝叶斯需要先估计先验概率，如果估计不准确容易影响分类结果；</p></li><li><p>基于概率的分类有可能会不准确。</p></li></ul></li></ol><ol start="4"><li><p>Generative Model vs Discriminative Model 生成模型 / 判别模型</p><p> 生成模型通过学习联合概率 $P(X,Y)$，即特征 $x$ 与类别 $y$ 同时出现的概率，再对每一个类别求条件概率，取概率最大的类别作为预测结果，即 $P(Y|X) = \frac{P(X,Y)}{P(X)}$。</p><ul><li><p>生成模型能学习到更多信息，如每个特征的边缘分布 $p(x)$；</p></li><li><p>生成模型收敛速度快，且对小规模数据或稀疏数据表现较好；</p></li><li><p>生成模型不容易出现过拟合现象；</p></li><li><p>生成模型的效果一般没有判别模型好。</p><p>判别模型则是通过学习条件概率，即直接预测特征 $x$ 下类别 $y$ 的概率。</p></li><li><p>判别模型的分类边界更加灵活，能够拟合更加复杂的边界；</p></li><li><p>只用学习分类的信息，问题得到简化；</p></li><li><p>准确率普遍较生成模型较高。</p></li></ul></li></ol><h3 id="支持向量机-Support-Vector-Machine-SVM"><a href="#支持向量机-Support-Vector-Machine-SVM" class="headerlink" title="支持向量机 Support Vector Machine, SVM"></a>支持向量机 Support Vector Machine, SVM</h3><ol><li><p>SVM 的核心思想？</p><p> SVM 是定义在特征空间中的线性分类器，目标是使得分隔超平面两边的数据点离超平面的<strong>间隔最大</strong>。当数据线性可分时，可以通过<strong>硬间隔最大化</strong>来学习一个线性的超平面；当数据近似线性可分时，则可以通过加上一个松弛变量，通过<strong>软间隔最大化</strong>来学习超平面；当线性不可分时，也可以使用核函数，将输入空间映射到高维的特征空间。</p></li><li><p>硬间隔最大化</p><p> 首先定义超平面 $(w,b)$ 关于样本点 $(x_i,y_i)$ 的<strong>函数间隔</strong>为 $\hat{\gamma}_i=y_i(wx_i+b)$ 但是，如果成比例地改变 $w$ 和 $b$ 的值，函数间隔会发生改变，但其超平面并没有变。为了解决这个问题，引入<strong>几何间隔</strong>为超平面与样本点的直线距离 $\gamma_i=y_i(\frac{w}{||w||}x_i+\frac{b}{||w||})$。硬间隔最大化的优化目标就是找到合适的超平面 $(w,b)$，使得点到超平面的间隔最大，即：<br> $$</p><pre><code> \max_{w,b} \gamma, \text{s.t.,} y_i(\frac{w}{||w||}x_i+\frac{b}{||w||}) \geq \gamma, i=1,2,...,N</code></pre><p> $$<br> 我们可以将这个优化问题转化为：<br> $$</p><pre><code> \min_{w,b} \frac{1}{2}||w||^2, \text{s.t.,} y_i(wx_i+b)-1 \geq 0,i=1,2,...,N</code></pre><p> $$<br> 可以使用拉格朗日乘子将该问题转换为对偶问题，这样可以便于求解：<br> $$</p><pre><code> \min_\alpha \frac{1}{2}\sum_i^N \sum_j^N \alpha_i \alpha_j y_iy_j(x_i\cdot x_j)-\sum_i^N \alpha_i, \text{s.t.,} \sum_i^N \alpha_i y_i=0, \alpha_i \geq 0,i=1,2,...,N</code></pre><p> $$<br> 转换为对偶问题还可以便于引入<strong>核技巧</strong>来解决非线性问题，即将内积 $(x_i\cdot x_j)$ 用核函数 $K(x_i,x_j)=\phi(x_i)\cdot\phi(x_j)$ 来代替。</p></li><li><p>软间隔最大化</p><p> 在现实中数据并不可能总是线性可分（可能存在噪音点、离群点等脏数据），线性不可分意味着有些样本点 $(x_i,y_i)$ 不能满足函数间隔大于 1 的约束条件。为了使得模型更加鲁棒，我们需要将硬间隔转换为软间隔。对于每一个样本点，我们引进一个松弛变量 $\xi_i$，使得函数间隔加上松弛变量大于 1，即 $y_i(wx_i+b)\geq1-\xi_i$。</p><p> 同时，添加一个惩罚参数 $C$，目标函数变为 $\frac{1}{2}||w||^2 + C\sum_i^N \xi_i$。惩罚参数的添加是使得<strong>函数间隔尽可能大，而误分类点尽可能少</strong>，惩罚参数是调和二者的系数。当 $\xi_i = 0$ 时，样本点在间隔之外；当 $0 &lt;\xi_i &lt; 1$ 时，分类正确，样本点在超平面与间隔边界之间；当 $\xi_i &gt; 1$ 时，样本点被误分。</p></li><li><p>Hinge Loss 合页损失函数</p><p> Hinge Loss 的图像如图所示，横轴是函数间隔 $\hat{\gamma}_i=y_i(wx_i+b)$，当间隔 $\hat{\gamma}_i\geq 1$ 时，表示正确分类，损失值为 0；当间隔 $\hat{\gamma}_i &lt; 0$ 时分类错误；当间隔 $0 &lt; \hat{\gamma}_i &lt; 1$ 时，分类正确，但样本点在间隔边界与超平面之间。Hinge Loss 对这样的样本点也会进行惩罚，提高了样本点的利用率，这使得 SVM 对训练样本数的依赖大大减少。</p><p> <img src="imgs/hinge-loss.jpg" alt="hinge-loss"></p></li></ol><h3 id="逻辑回归-Logistic-Regression-LR"><a href="#逻辑回归-Logistic-Regression-LR" class="headerlink" title="逻辑回归 Logistic Regression, LR"></a>逻辑回归 Logistic Regression, LR</h3><ol><li><p>逻辑回归的核心思想？</p><p> 逻辑回归主要用于分类问题，对于所给数据集，认为可以用一条直线将数据线性分类。逻辑回归与线性回归的最主要区别在于逻辑回归主要关注于分类概率与输入向量的关系，即 $P(Y=1)$ 与 $x$ 的直接关系，然后通过概率值来判断是否属于某一类别。</p><p> 逻辑回归主要考虑二分类问题。给定数据集：</p><p> $$</p><pre><code> D=(x_1,y_1), (x_2,y_2),...,(x_N,y_N), x_i\in R^n</code></pre><p> $$</p><p> 由于 $w^T x+b$取值连续，因此可以用它来拟合条件概率 $p(Y=1|x)$. 最理想的函数其实是：</p><p> $$</p><pre><code> p(Y=1|x)= \begin{cases}     0, &amp; z &lt; 0\\     0.5, &amp; z = 0 \\     1, &amp; z &gt; 0 \end{cases} , z = w^T x + b</code></pre><p> $$</p><p> 但是，这个函数不可微，因此，我们使用 sigmoid 函数来拟合概率：</p><p> $$</p><pre><code> y=\frac{1}{1+e^z}, z=w^T x + b</code></pre><p> $$</p><p> 将 $y$ 视为类后验概率估计，则重写公式有：</p><p> $$</p><pre><code> P(Y=1|x)=\frac{1}{1+e^z}, z=w^T x + b,\\</code></pre><p> $$</p><p> $$</p><pre><code> z = \ln\frac{P(Y=1|x)}{1-P(Y=1|x)}</code></pre><p> $$</p><p> 因此，逻辑回归实际上是<strong>使用线性回归模型的预测值来逼近分类任务的对数几率</strong>，其优点有：</p><ul><li>不仅能够预测出类别，还能预测出属于该类别的概率，对于一些需要预测概率的任务很适用；</li><li>对数几率函数在任意阶都是<strong>连续可导的凸函数</strong>，因此可以使用许多优化算法求解。</li></ul></li><li><p>逻辑回归的损失函数与梯度</p><p> 设：$P(Y=1|x) = p(x), P(Y=0|x) = 1 - p(x)$，则似然函数可以写为：</p><p> $$L(w) = \prod[p(x_i)]^{y_i}[1-p(x_i)]^{1-y_i}$$</p><p> 为了方便求解，一般取对数似然函数：</p><p> $$<br> \begin{aligned}</p><pre><code> l(w) = \ln L(w) &amp; = \sum[y_i\ln p(x_i) + (1-y_i)\ln (1-p(x_i))] \\ &amp; = \sum[y_i\ln\frac{p(x_i)}{1-p(x_i)} + \ln(1-p(x_i))] \\ &amp; = \sum[y_i z_i - \ln(1 + e^{z_i})]</code></pre><p> \end{aligned}<br> $$</p><p> 使用梯度下降法求解时，取似然函数的<strong>相反值</strong>进行优化，求其梯度为：</p><p> $$<br> \begin{aligned}</p><pre><code> \frac{\partial J(w)}{\partial w_j} &amp; = -\sum_i \frac{\partial [y_i z_i - \ln(1 + e^{z_i})]}{\partial z_i} \cdot \frac{\partial z_i}{\partial w_j} \\ &amp; = -\sum_i (y_i - p(x_i)) \cdot x_j</code></pre><p> \end{aligned}<br> $$</p><p> 权重更新为：</p><p> $$w_j := w_j + \eta(\sum_i (y_i - p(x_i)) \cdot x_j),\text{ for }i\text{ in range}(n)$$</p></li><li><p>与 SVM 的区别？</p><ul><li>同样是更加关注于分类边界附近的数据点，不同之处在于，LR 通过非线性映射减小离分类平面远的数据点的权重，提升离分类平面近的数据点的权重；而 SVM 则是完全只关注于分类错误的点以及靠近分类平面的数据点，而不关注那些离分类平面较远的普通样本。</li><li>LR 是参数模型，而 SVM 是非参数模型。参数模型的前提是假设数据符合某种分布（如 LR 假设数据服从伯努利分布），该分布由一些参数决定。依赖数据分布会使得 LR 模型在样本不均衡时影响分类效果；而非参数模型不直接依赖于分布。</li><li>LR 能够产生概率，而 SVM 不能直接产生概率。</li></ul></li></ol><h3 id="决策树-Decision-Tree"><a href="#决策树-Decision-Tree" class="headerlink" title="决策树 Decision Tree"></a>决策树 Decision Tree</h3><ol><li><p>什么是决策树？</p><p> 决策树以树状的结构对数据特征进行分类。建立一棵树，树上的每一个节点都是一个决策的判断，记为<strong>分支</strong>。将数据输入决策树，当在某节点数据不再分裂，则形成一个叶子节点，完成最终的分类。</p></li><li><p>如何确定分类的指标？</p><p> 简要来说，我们在每次选择划分特征时，都会选择<strong>对分类最有帮助</strong>的特征来作为接下来的划分特征。具体来说，我们通过计算特征的<strong>熵</strong>来评价特征的重要程度。<br> <strong>熵</strong> (Entropy) 被用来度量一个系统的混乱程度，代表一个系统中所有事件信息量的期望。<br> $$</p><pre><code> H(X) = -\sum_{x \in X}p(x_i) \log p(x_i)</code></pre><p> $$<br> $$</p><pre><code> H(X|A) = -\sum_{i=1}^d p(A=a_i)H(X|A=a_i)</code></pre><p> $$<br> 熵越大，该系统的不确定性也越大。构造树的基本思想时随着树深度的增加，节点的熵迅速降低。熵降低的速度越快越好，以便生成一个高度尽可能<strong>矮</strong>的决策树。</p><p> 首先，我们根据分类的 label，计算不选择任何特征时，系统的熵值 $H(D)$。随后，我们分别计算考虑了各个特征之后，系统的熵值。我们计算每个特征的<strong>信息增益</strong> $Gain(D|A) = H(D) - H(D|A)$，并选择信息增益最大的特征作为新节点的划分特征。</p></li><li><p>决策树的分类</p><ul><li>ID3。使用<strong>信息增益</strong>作为特征选择的评估方式。缺点主要是：当遇到稀疏特征时（如用户 ID），由于每项特征的样本比较少，可能会出现信息增益特别大的情况，导致决策树错误选择该稀疏特征作为划分特征。通常来说，ID3决策树偏向选择那些取值较多的特征属性。</li><li>C4.5。使用<strong>信息增益率</strong>作为特征选择的评估方式。信息增益率计算方式如下：<br>  $$<pre><code>  GainRatio(D|A) = \frac{Gain(D|A)}{H(A)} = \frac{H(D)-H(D|A)}{H(A)}</code></pre>  $$<br>  然而，信息增益率偏向选择取值较少的特征。因此，C4.5决策树会选择信息增益大于平均水平的特征来进行信息增益率的计算。此外，C4.5相对于ID3决策树，增加了对连续值和缺失值的处理过程。</li><li>CART。对于分类问题，CART 决策树使用 <strong>Gini 系数</strong>作为评估标准；而对于回归问题，CART 决策树使用 <strong>MSE</strong> 作为评估标准。公式如下：<br>  $$<pre><code>  Gini(X) = \sum_{x\in X} p(x_i)(1-p(x_i))</code></pre>  $$<br>  $$<pre><code>  Gini(X|A) = \sum_{i=1}^d p(A=a_i) Gini(X|A=a_i)</code></pre>  $$</li></ul></li><li><p>随机森林 Random Forest, RF</p><p> 使用 <strong>Bagging 算法</strong>，即有放回采样地选取 $n$ 个样本，建立 $m$ 个决策树分类器。多个分类器采用<strong>投票机制</strong>来产生最终的分类结果。<br> 随机森林的“随机”有两重含义：</p><ul><li>样本随机选择，即 $n &lt; \lVert D\rVert$，在每个决策树中选择一部分样本，有利于增加模型对离群点、噪音点的鲁棒性。</li><li>特征随机选择，每个决策树中只挑选一部分特征进行分类，有利于筛选不重要的特征或无效的特征。</li></ul></li></ol><h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><ol><li><p>Boosting 思想</p><p> 当每个弱分类器的分类效果不理想时，我们可以尝试将多个不同的弱分类器组合起来，形成效果更好的强分类器。Boosting 着重于减小模型的 <strong>bias</strong>。Boosting 与 Bagging 的区别如下：</p><ul><li><p>样本选择上，Bagging 在每次训练中是通过 Bootstrap 有放回选取不同的数据，每轮训练的数据集是独立的；Boosting 中每轮的训练集不变，只是训练集中每个样本的权重在训练中发生变化，样本的权重根据上一轮的分类结果进行调整。</p></li><li><p>模型预测上，Bagging 中每个模型的权重相等，通过投票或取均值的方式进行结合；Boosting 中每个弱分类器都有对应的权重，对于分类误差小的分类器分配更大的权重。</p></li><li><p>计算方式上，Bagging 的各个模型可以并行训练；Boosting 中每个模型只能串行训练，因为后一个模型的样本权重需要通过上一轮的训练结果来调整。</p></li><li><p><em>Bagging 着重于减小模型的 Variance；Boosting 着重于减小模型的 bias。</em></p><blockquote><p><strong>为何说 Bagging 是减小 Variance，Boosting 是减小 bias？</strong></p><p>在 Bagging 中，对样本重采样，每个子样本训练一个强（甚至过强）模型，最后取平均。由于子样本之间的相似程度高，多个模型的类型、结构与分布也非常相似，故多个模型有着近似的效果。而经过 Bagging 后，可以有效减小子模型的过拟合情况，因此可以显著降低模型的 Variance。<br>在 Boosting 中，把许多个弱分类器组合成一个强的分类器，着重于提高弱模型的性能，即着重降低模型的 bias。而 Variance 则不在 Boosting 的考虑范围之内。在 Boosting 中，多个模型有着同样的优化目标，并且通过在每一轮中的不断优化，能够达到降低 bias 的目的。</p></blockquote></li></ul></li></ol><ol start="2"><li><p>XGBoost 基本原理</p><p> 在第 $t$ 轮训练中，在<strong>保留前 $t-1$ 轮训练结果</strong>的前提下，加入一棵树 $f_t$，使得目标函数<strong>尽可能地降低</strong>。用公式表达如下：<br> $$</p><pre><code> \begin{aligned}     Obj_t &amp; = \sum_{i=1}^n l(y_i, \hat{y}_i^t) \\     &amp; = \sum_{i=1}^n l(y_i, \hat{y}_i^{t-1} + f_t(x_i)) \\ \end{aligned}</code></pre><p> $$<br> 设损失函数为 MSE，则原目标函数写为：<br> $$</p><pre><code> \begin{aligned}     Obj_t &amp;= \sum_{i=1}^n (y_i - (\hat{y}_i^{t-1} + f_t(x_i)))^2 \\     &amp; = \sum_{i=1}^n[2(\hat{y}_i^{t-1} - y_i)f_t(x_i)+f_t(x_i)^2] + \sum_{i=1}^n ({y_i - \hat{y}_i^{t-1}})^2 \end{aligned}</code></pre><p> $$<br> 其中，$\sum_{i=1}^n ({y_i - \hat{y}_i^{t-1}})^2$ 与本轮无关，可以视为常数，$(\hat{y}_i^{t-1} - y_i)$ 一般被叫做<strong>残差</strong>，表示了上一轮预测值与真实值之间的差异，也是 XGBoost 算法在每一轮中预测的主要目标。即，将上一轮的训练结果看作一个整体，而新的一轮则对残差值进行预测。</p><p> <img src="imgs/XGBoost.png" alt="xgboost"></p><p> 此外，XGBoost 在每个叶子节点上都增加了正则化项 $\Omega(f_t) = \gamma T + \lambda\frac{1}{2}\sum^T_{j=1} w_j^2$，其中，$T$ 代表叶子节点数量，$\lambda\frac{1}{2}\sum^T_{j=1} w_j^2$ 为 L2 正则化项。</p></li></ol><h2 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h2><h3 id="DL-基础概念"><a href="#DL-基础概念" class="headerlink" title="DL 基础概念"></a>DL 基础概念</h3><ol><li><p>为什么神经网络需要偏置项？</p><p> 对于神经网络中的每一个神经元，都有 $y_i = W^TX_i + b$。这个式子本质上就是要用这个函数在空间中划分决策面。而如果没有偏置项，那么划分的超平面就只能经过原点。偏置项的加入使得神经网络的拟合更加灵活，如果没有偏置项，训练可能难以收敛或出现其他 bug。</p><blockquote><p><strong>在所有场合都可以使用偏置项吗？</strong></p><p>不是。例如在卷积层之后，如果要添加 Batch Normalization 层，最好不添加偏置项，因为不起作用，且会占用显卡内存。</p><p>在 BN 中，有一步关键操作为：</p><p>$$</p><pre><code>  \hat{x_i} = \frac{x_i - \mu_\mathcal{B}}{\sqrt{\sigma^2_{\mathcal{B}} + \epsilon}}</code></pre><p>$$</p><p>其中，$\mu_\mathcal{B}$ 为均值，$\sigma^2_{\mathcal{B}}$ 为方差。在该操作中，偏置项在计算中会被抵消掉，故偏置项不起作用。</p></blockquote></li></ol><ol start="2"><li><p>Back Propagation</p><p> BP 神经网络是由一个输入层、一个输出层和若干个隐藏层构成的。输入信号从输入层进入，经过隐藏层计算，并由输出层输出。将输出的结果和真实值进行比对得到训练的误差。该误差沿着输出层，经过隐藏层，最终传播到输入层的权值参数。由于误差传播方向和训练方向相反，故称“反向传播”。</p><p> 反向传播是为了解决神经网络无法直接应用梯度下降法的问题。由于梯度下降法只能用于“能够通过得到误差”的情况，例如逻辑回归。但隐藏层并不存在所谓“误差”，因此只能通过先将误差反向传播到隐藏层，应用链式法则得到求导函数，再使用梯度下降法进行优化。反向传播算法可以看作是梯度下降法在链式法则（Chain Rule）中的应用。</p></li></ol><ol start="3"><li><p>梯度消失和梯度爆炸问题</p><p> 在反向传播的梯度更新中，若更新的梯度一直小于 0，就可能触发连乘效应，在之后的传播中越传越小，导致靠近输入层的权值几乎不更新，训练收敛速度变慢，这便是<strong>梯度消失</strong>。与之相反，若梯度过大则会触发<strong>梯度爆炸</strong>，以致于溢出，出现梯度为 NaN 的问题。</p><blockquote><p>当激活函数为 Sigmoid 时，容易触发梯度消失问题。因为 Sigmoid 函数的导数最大值只有 0.25，如图所示。</p><p><img src="imgs/sigmoid.jpg" alt="sigmoid"></p></blockquote><p> 常见的缓解梯度消失 / 梯度爆炸的方法有：</p><ul><li>使用其他<strong>激活函数</strong>，如ReLU等；</li><li>用更合理的<strong>权值初始化</strong>方式，如 Xavier 初始化，He 初始化。这两种初始化方法都能保证在传播时权值的方差不变。</li><li><strong>Batch Normalization</strong>. 梯度的更新与 $x$ 的值也有关系，因此用 BN 限制 $x$ 的分布也有利于缓解梯度消失 / 梯度爆炸问题；</li><li>对权重进行<strong>正则化</strong>（L1、L2）；</li><li>使用 <strong>ResNet 网络</strong>。ResNet 通过添加 Shortcut Connections，使得层与层之间可以跨层连接，减少了梯度消失 / 梯度爆炸的问题。</li><li>通过<strong>梯度截断</strong>（Gradient Truncation）手动防止梯度爆炸。</li></ul></li></ol><ol start="4"><li><p>能不能将神经网络的所有权值都初始化为 0？</p><p> 不能。事实上，不能将神经网络的所有权值都设置为同一值。否则，在神经网络的更新中，两权值的更新将一模一样。多个相同的神经元相当于只有一个神经元，会使得神经网络无法拟合。</p><p> 因此，一般我们选择随机初始化，或是使用其他初始化方法，如 Xavier 初始化，He 初始化。这两种初始化方法都能保证在传播时权值的方差不变。</p></li></ol><ol start="5"><li><p>在深度学习中缓解过拟合问题</p><p> 深度学习中防止过拟合常见的方法有：</p><ul><li>获取更多、质量更高的数据<ul><li>采集新的数据</li><li>数据增强（图片镜像、翻转等）</li><li>利用对抗网络生成数据</li></ul></li><li>正则化（L1、L2）</li><li>Dropout</li><li>Early Stopping</li><li>集成学习，如 Bagging、Boosting 等。</li></ul></li></ol><ol start="6"><li><p>Dropout 是什么？</p><p> Dropout 是在每次训练过程中都随机舍弃一些神经元之间的连接。这样做可以降低对部分上层神经元的依赖关系，迫使模型去学习一些更具有鲁棒性的特征，使得模型泛化能力更强。</p><p> <img src="imgs/dropout.png" alt="dropout"></p></li></ol><ol start="7"><li><p>Dropout 和 Batch Normalization 在训练和预测中的区别？</p><p> Dropout 在训练时采用，是为了减少神经元对部分上层神经元的依赖，减少过拟合的风险。而在预测中，应该用训练完成的模型，不需要 Dropout。</p><p> 对于 BN，在训练时使用每一批数据的均值和方差进行计算，对每一批数据单独进行归一化。但在测试时，可能不存在 batch 的概念（例如预测单条数据）。因此在测试时，一般使用所有训练数据的均值和方差进行计算。</p><blockquote><p><strong>为什么不在训练的时候使用所有训练数据的均值和方差？</strong></p><p>因为在训练中使用所有数据的均值和方差容易出现过拟合现象。</p><p>BN 的原理就是将每一批数据都归一到相同的分布。而每一批数据的均值和方差都不相同，这个差别能够增加模型的鲁棒性，在一定程度上减少模型的过拟合现象。</p><p>也正是因此，当应用 BN 时，一般要求将训练集完全打乱，并用一个较大的 batch size，否则，一批数据可能无法较好得代表训练集的分布，会影响模型训练的效果。</p></blockquote></li></ol><ol start="8"><li><p>常见的 Non-Linear Activation Function 及其优缺点</p><p> 非线性激活函数是神经网络与感知机网络最大的区别，即将非线性特性引入到网络中。如果不用非线性激活函数，则每一层都是上一层的线性变换，无论网络有多少层，输出都是输入的线性组合。而加入非线性层后，神经网络便拥有了学习非线性关系的能力，这使得神经网络可以逼近任意形状的函数。</p><table><thead><tr><th align="center">函数名</th><th align="center">函数表达式</th><th align="left">优点</th><th align="left">缺点</th></tr></thead><tbody><tr><td align="center">Sigmoid</td><td align="center">$\displaystyle f(z)=\frac{1}{1+e^{-z}}$</td><td align="left">1. 将输入转换为 (0, 1) 的区间。</td><td align="left">1. 在神经网络反向传播中可能出现梯度消失问题；<br>2. 函数均值不为 0，使得权值总往同一方向更新，<br>收敛速度慢。</td></tr><tr><td align="center">tanh</td><td align="center">$\displaystyle f(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}$</td><td align="left">1. 将输入转换为 (0, 1) 的区间；<br>2. 解决 Sigmoid 均值非 0 问题。</td><td align="left">1. 依然存在梯度消失问题；<br>2. 幂函数计算复杂，训练时间大。</td></tr><tr><td align="center">ReLU</td><td align="center">$f(z)=max(0,x)$</td><td align="left">1. 解决了梯度消失的问题；<br>2. 计算与收敛速度快。</td><td align="left">1. 函数均值不为 0；<br>2. Dead ReLU Problem. 当 $x&lt;0$ 时梯度为 0，且<br>该神经元之后的神经元梯度永远为 0，即神经元直接<br>失效。通过合理的初始化，或是降低学习率来解决。</td></tr><tr><td align="center">Leaky ReLU</td><td align="center">$f(z)=max(\alpha \cdot x,x)$</td><td align="left">1. 使得神经元在负数区域偏向于<br>激活而不是直接失效。</td><td align="left">1. 函数均值不为 0；<br>2. $\alpha$ 的值需要确定且比较敏感（通常是一个非常小<br>的值，如 0.01）。</td></tr></tbody></table></li></ol><ol start="9"><li><p>Gradient Descent vs Stochastic Gradient Descent vs Mini-Batch Gradient Descent</p><table><thead><tr><th align="center">方法</th><th align="left">优点</th><th align="left">缺点</th></tr></thead><tbody><tr><td align="center">Gradient Descent</td><td align="left">1. 参数梯度更新方向大致确定；<br>2. 适合并行化计算。</td><td align="left">1. 训练时收敛速度慢；<br>2. 当数据量大时，需要大量显存。</td></tr><tr><td align="center">Stochastic Gradient<br> Descent (SGD)</td><td align="left">1. 每次只随机抽取一条数据进行梯度更新，<br>花费代价小；<br>2. 适合大量数据的训练。</td><td align="left">1. 需要更多迭代次数；<br>2. 参数更新的过程震荡很大，参数更新方向有很大的波动；<br>3. 不适合并行化计算。</td></tr><tr><td align="center">Mini-Batch Gradient<br> Descent (MBGD)</td><td align="left">结合了前两种方法的优势：<br>1. 比 GD 收敛速度快，比 SGD 更加稳定；<br>2. 能利用高度优化的矩阵运算，适合并行化；</td><td align="left">1. 难以选择合适的学习率。太小的学习率会导致收敛缓慢；<br>太大的学习率会导致波动过大，可能跳出局部最优解。<br>可以采用动态调整学习率的方法（learning rate decay）。</td></tr></tbody></table></li></ol><ol start="10"><li><p>常见的优化器及其对比</p><table><thead><tr><th align="center">方法</th><th align="left">特点</th></tr></thead><tbody><tr><td align="center">GD / SGD / MBGD</td><td align="left">1. 难以选择合适的学习率。学习率太小会导致收敛缓慢；学习率太大会导致波动过大，可能跳出局部最优解。<br>2. 每个参数的学习率都是相同的。如果数据是稀疏的，且不同特征的出现频率相差较大，则会出现部分特征<br>学习不足的问题；<br>3. 在训练中容易陷入鞍点，即局部最优点，在这些点的梯度为 0，无法继续训练。</td></tr><tr><td align="center">Momentum</td><td align="left">1. 借鉴了物理中的动量概念，模拟物体运动时的惯性，即更新的时候在一定程度上保留之前更新的方向，而不<br>是像 GD 算法一样完全按照新的梯度方向更新。这样可以增加稳定性，并且有一定的摆脱局部最优解的能力。<br>2. Momentum 算法会观察上一步的梯度，若当前梯度方向与历史梯度一致，则增强该方向的梯度，否则则削<br>弱该方向的梯度。</td></tr><tr><td align="center">AdaGrad</td><td align="left">1. 针对 GD 算法中对于每个参数都保持同一学习率的问题，AdaGrad 算法能在训练中自动对不同参数的学习率<br>进行调整。对于出现频率比较低的特征，加大更新的学习率；对于出现频率高的，减小学习率。<br>2. 由于这个特性，AdaGrad 非常适合用于处理稀疏的数据。</td></tr><tr><td align="center">RMSprop</td><td align="left">1. Root Mean Square prop. 对 AdaGrad 算法的改进，把 AdaGrad 的将历史梯度相加变成对历史梯度求均值；<br>2. 这种方法可以缓解 AdaGrad 算法学习率下降较快的问题。</td></tr><tr><td align="center">Adam</td><td align="left">1. Adam 算法结合了 AdaGrad 和 RMSprop 的优点，即动态更新参数的学习率。不同于 RMSprop 只参考了参<br>数的历史平均值，Adam 同时参考了梯度的平均值和方差。<br>2. 在各大机器学习库中，两次估计的衰减率默认值 $\beta_1$ 和 $\beta_2$ 分别为 0.9 和 0.999.</td></tr><tr><td align="center">AdamW</td><td align="left">1. 针对 Adam 算法中先进行梯度衰减再进行正则化，使得梯度大的参数无法正常被正则化的问题，在 AdamW<br>中将梯度衰减的步骤移到正则化后，解决了这一问题。</td></tr></tbody></table></li></ol><ol start="11"><li><p>如何正确使用迁移学习？</p><p>通过使用之前在大数据集上经过训练的预训练模型，我们可以直接使用相应的结构和权重，将它们应用到我们正在面对的问题上。</p><ul><li><p>场景一：现有数据集<strong><em>大</em></strong>，数据与原数据相似度<strong><em>高</em></strong></p><p>  这是最理想的情况，采用预训练模型会变得非常高效。最好的运用方式是保持模型原有的结构和初始权重不变，随后在新数据集的基础上重新训练 / 微调。</p></li><li><p>场景二：现有数据集<strong><em>小</em></strong>，数据与原数据集相似度<strong><em>高</em></strong></p><p>  在这种情况下，由于数据和原数据集相似度高，我们不需要重新训练模型，只需要将输出层改为新问题的结构即可。</p></li><li><p>场景三：现有数据集<strong><em>大</em></strong>，数据与原数据集相似度<strong><em>低</em></strong></p><p>  因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。因此最好的方法还是只沿用预训练模型的结构。将预处理模型中的权重全都初始化后，在新数据集上<strong>重新</strong>开始训练。</p></li><li><p>场景四：现有数据集<strong><em>小</em></strong>，数据与原数据集相似度<strong><em>低</em></strong></p><p>  这是最糟糕的一种情况。为了防止过拟合，我们不能从头开始训练。我们可以利用预训练模型较低的层进行特征提取，弥补数据集大小不足的缺陷，再利用较高的层进行训练（一般而言，神经网络较高的层具有较高的区分度，更适合用来训练数据本身）。因此，我们<strong>冻结</strong>预训练模型前 $k$ 层的权重，用于提取数据的特征，然后训练后 $n-k$ 层，并将原输出层改为新问题的结构。</p></li></ul></li></ol><h2 id="Natural-Language-Processing"><a href="#Natural-Language-Processing" class="headerlink" title="Natural Language Processing"></a>Natural Language Processing</h2><h3 id="NLP-基本概念"><a href="#NLP-基本概念" class="headerlink" title="NLP 基本概念"></a>NLP 基本概念</h3><ol><li><p>常见的文本相似度计算方法</p><ul><li>欧式距离，用于计算两等长<strong>句子向量</strong>的相似度。 $\text{distance} = \sqrt{(A-B)*(A-B)^T}$；</li><li>余弦距离，用于计算两等长<strong>句子向量</strong>的相似度。 $\text{distance} = \frac{A<em>B^T}{|A|</em>|B|}$；</li><li>Jaccard 相似度。将句子看作单词的集合。则 A 与 B 的 Jaccard 相似度为：$\text{similarity} = \frac{|A\cap B|}{|A\cup B|}$；</li><li>TF-IDF。TF 是词频 (Term Frequency)，表示在一个文章中某个单词出现的频率；IDF 是逆文本频率指数 (Inverse Document Frequency)，表示含有该关键词的文档占所有文档的比例。TF-IDF 建立在以下假设上：对区别文档最有意义的词语应该是那些在<strong>文档中出现频率高</strong>，而在整个文档集合的<strong>其他文档中出现频率少</strong>的词语；</li><li>最小编辑距离。一种经典的距离计算方法，用来度量字符串之间的差异。将字符串 A 不断修改（增删改），直至成为字符串 B，所需要的修改次数代表了字符串 A 和 B 的差异大小。常使用动态规划来计算最小编辑距离。</li></ul></li></ol><ol start="2"><li><p>word2vec 模型</p><p> 在 NLP 中，我们希望用一个数学形式表示不同的单词，于是便有了词向量。最初的词向量是 one-hot 词向量，但这种向量维度过大，非常稀疏，且不能反映词与词之间的关系。于是便有了<strong>分布式词向量</strong>，即固定 embedding 的维度，embedding 中的每一个值都是通过计算不同单词的贡献得到的。</p><p> 训练 word2vec 模型主要有两种方式：CBOW 和 Skip-Gram。</p><ul><li><p>CBOW 是让模型根据某个词前面的 C 个词和之后的 C 个词，预测这个词出现的概率。如图，训练过程其实就是学习这两个矩阵 $W$ 和 $W’$，其中，$W$ 矩阵又被叫做 lookup table，即所有词嵌入向量的词表。</p><p>  <img src="imgs/word2vec-CBOW.jpg" alt="word2vec-CBOW"></p></li><li><p>Skip-Gram 和 CBOW 相反，是根据某一个词来预测它的前 C 个词和后 C 个词。同样训练两个矩阵 $W$ 和 $W’$，其中，$W$ 矩阵是 lookup table。一般来说，Skip-Gram 的训练时间比 CBOW 要慢。</p><p>  <img src="imgs/word2vec-skip-gram.jpg" alt="word2vec-skip-gram"></p><p>为了加快训练速度，word2vec 采用了两种优化方式。</p></li><li><p>Hierarchical Softmax，用霍夫曼树代替神经网络，本质上是将 n 分类变成 log(n) 次二分类。</p></li><li><p>Negative Sampling，由于霍夫曼树中高频词离根结点较近，但是如果中心词是较生僻的词，那么就要消耗很长时间。简要来说就是从负样本中选取一部分来更新，而不是更新全部的权重。</p></li></ul></li></ol><ol start="3"><li><p>GloVe 模型</p><p> GloVe 模型利用了词语的共现频率来计算相关性。首先引入词语的共现矩阵 $X$，其中 $X_{ij}$ 是在 word i 的上下文中 word j 的出现次数，$X_i = \sum_k X_{ik}$ 是出现在 word i 的上下文中所有词的出现次数，则共现概率为 $P_ij = P(j|i) = \frac{X_{ij}}{X_i}$，是word j 出现在 word i 上下文的概率。可以发现，共现概率的比例可以反映两个词的<strong>相关度</strong>。</p></li></ol><h3 id="HMM-CRF"><a href="#HMM-CRF" class="headerlink" title="HMM / CRF"></a>HMM / CRF</h3><ol><li><p>隐马尔可夫模型 Hidden Markov Model, HMM</p><ul><li><p>马尔可夫链，即一个状态序列，满足在任意时刻 $t$ 的状态仅与其前一时刻的状态有关。隐马尔可夫链，则是无法直接观测到某一时刻的状态，而是要通过其他的观测状态才能预测隐藏的状态。</p></li><li><p>隐马尔可夫模型的两个基本假设：</p><ul><li><strong>齐次性假设</strong>：即隐藏的马尔可夫状态在任意时刻的状态只依赖于前一时刻的状态，与其他时刻的状态无关；</li><li><strong>观测独立性假设</strong>：任意时刻的观测状态只取决与当前状态的隐藏状态，和其他时刻的观测状态或隐藏状态无关。</li></ul></li><li><p>隐马尔可夫模型的五个要素：</p><ul><li><strong>隐藏状态集</strong> $Q$ = {$q_1$, $q_2$, …, $q_N$}，即隐藏节点只能取值于该集合中的元素。</li><li><strong>观测状态集</strong> $V$ = {$v_1$, $v_2$, …, $v_M$}，即观测节点的状态也只能取值于该集合中的元素。</li><li><strong>隐藏状态转移矩阵</strong> $A$ = $[a_{ij}]_{N\times N}$，表示从一种隐藏状态到另一种隐藏状态的转移概率。</li><li><strong>观测概率矩阵</strong> $B$ = $[b_{ij}]_{N\times M}$，表示对于某一种隐藏状态，其观测状态的分布概率。</li><li><strong>初始隐藏状态概率</strong> $\pi$ = $[p_1, p_2, …, p_n]$，表示初始时刻处于各个隐藏状态的概率。</li></ul></li><li><p>隐马尔可夫模型要求解的基本问题：</p><ul><li><strong>概率计算问题</strong>。对于已知模型 $\lambda$ = $(A, B, \pi)$，和已知观测序列 $O$ = {$o_1$, $o_2$, …, $o_M$}，求产生这种观测序列的概率是多少，即求 $p(O|\lambda)$。</li><li><strong>学习问题</strong>。对于已知观测序列 $O$ = {$o_1$, $o_2$, …, $o_M$}，求解模型 $\lambda$ = $(A, B, \pi)$ 的参数，使得产生这种观测序列的概率 $p(O|\lambda)$ 最大，即用<strong>最大似然估计</strong>方法估计模型的参数。</li><li><strong>解码问题</strong>。同样对于已知模型 $\lambda$ = $(A, B, \pi)$，和已知观测序列 $O$ = {$o_1$, $o_2$, …, $o_M$}，求解最优的隐藏状态序列 $I$ = {$i_1$, $i_2$, …, $i_N$}，使得 $p(I|O)$ 最大。</li></ul></li><li><p>对于基本问题的解法：</p><ul><li><p>对第一个问题的解法：</p><ul><li>暴力解法：时间复杂度为 $O(TN^T)$；</li><li>前向算法：利用动态规划思想，将前面时刻计算过的概率保存下来。<ul><li>对于第一个时刻的状态：$a_1(i) = \pi_ib_i(o_1)$, $i\in [1,N]$；</li><li>对于第 $t$ 个时刻的状态：$a_t(i) = [\sum_{j=1}^N a_{t-1}(j)a_{ji}]b_i(o_t)$。</li></ul></li></ul></li><li><p>对第二个问题的解法：</p><p>Baum-Welch 算法：与 EM 算法相似，在 E-step 中，计算联合分布 $P(O,I|\lambda)$ 和条件分布 $P(I|O,\bar{\lambda})$，根据联合分布和条件分布计算期望表达式 $L(\lambda,\bar{\lambda})$；在 M-step 中最大化 $\lambda$ 的值，使得 $\bar{\lambda} = \argmax_\lambda L(\lambda,\bar{\lambda})$。</p></li><li><p>对第三个问题的解法：</p><p>Viterbi 维特比算法：可以看作一个求最长路径的动态规划算法。</p><p>初始化两个状态变量：$\delta_t(i)$ 表示在 $t$ 时刻隐藏状态为 $i$ 的所有状态转移路径中概率最大值，初始化 $\delta_1(i) = \pi_i b_i(o_1)$。$\psi_t(i)$ 则是在 $t$ 时刻使得隐藏状态为 $i$ 的转移路径中概率最大的前一时刻的隐藏状态，初始化为 0。则两状态变量的递推表达式为：</p><p>$$</p><pre><code>\begin{cases}    \delta_t(i) = \max_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]b_i(o_t) \\    \psi_t(i) = \argmax_{1\leq j\leq N}[\delta_{t-1}(j)a_{ji}]\end{cases}</code></pre><p>$$</p><p>在第 $T$ 步，取 $\delta_T(i)$ 最大值即为最可能隐藏序列出现的概率，此时最大的 $\psi_T(i)$ 即为第 $T$ 的状态。</p><p>随后，从第 $T$ 步开始回溯，即 $i^<em>_{t-1}$ = $\psi_t(i^</em>_t)$，得到完整的隐藏序列 $I=(i^<em>_1, i^</em>_2, …, i^*_T)$。</p></li></ul></li></ul></li></ol><ol start="2"><li><p>条件随机场 Conditional Random Field, CRF</p><p> 首先介绍随机场。一组随机变量，分布在同一个样本空间，那么它们就组成了一个随机场。我们希望利用这些随机变量之间的关系来解决实际问题。</p><p> 马尔可夫随机场是满足马尔可夫独立性的随机场，即每个节点仅与其相邻的节点有关系。并不像贝叶斯网络（有向无环图）一样，通过变量之间的条件分布建模（节点与节点之间的依赖关系），马尔可夫随机场是根据变量之间的联合分布来建模的。当知道了变量之间的联合分布，则它们之间的条件分布也就能求解出来。因此，马尔可夫随机场是<strong>生成模型</strong>。</p><p> 条件随机场则是对条件概率建模。即已经观测到部分点的前提下，求解整张图的分布。</p><p> HMM 是通过对可观测序列和隐藏序列的联合概率建模，估计模型的隐含变量的分布，再计算概率最大的隐藏序列，是一个<strong>生成模型</strong>。CRF 则是直接对条件概率 $P(I|O)$ 建模，通过可观测序列直接判别出隐藏序列，是一个<strong>判别模型</strong>。</p><p> 比较常见的条件随机场是线性链条件随机场。设 $X = (X_1, X_2, …, X_n)$, $Y = (Y_1, Y_2, …, Y_n)$ 均为线性链表示的随机变量序列。在给定 $X$ 的情况下，随机变量序列 $Y$ 的条件概率分布构成线性链条件随机场，即 $Y$ 的分布只与其相邻的节点有关。</p><p> 与 HMM 相似，条件随机场主要求解的也是三个问题：</p><ul><li><p>概率计算问题：给定条件随机场 $P(Y|X)$, 观测序列 $x$ 和隐藏序列 $y$，计算条件概率 $P(Y_i=y_i|x)$，可以通过前向后向解法求解</p></li><li><p>学习问题：已知观测序列和隐藏序列，通过极大似然估计法来学习模型的最大概率参数。</p></li><li><p>预测问题：给定条件随机场 $Y=(Y|X)$ 和观测序列 $x$，求条件概率最大的隐藏序列 $y^<em>$，即<em>*对观测序列进行标注</em></em>。预测问题的常用算法是维特比算法。</p><p>CRF 是一个序列化标注算法，接收一个输入序列 $X = (x_1, x_2, …, x_n)$，输出目标序列 $Y = (y_1, y_2, …, y_n)$，可以被看作是一个 Seq2Seq 模型。在词性标注任务中，输入为文本序列，输出则为对应的词性序列。</p><p>相比于 HMM 需要对状态转移矩阵和观测概率矩阵建模，CRF 属于判别模型，其直接对 $P(I|O)$ 建模：</p><p>$$<br> P(I|O) = \frac{1}{Z(O)}e^{\sum_i^T \sum_k^M \lambda_k f_k(O, I_{i-1}, I_i, i)}<br>$$</p><p>其中，下标 i 表示当前所在的节点（token）位置，下标 k 表示第 k 个特征函数，并且每个特征函数都附属一个权重 $\lambda_k$，$\frac{1}{Z(O)}$ 是归一化系数。</p></li></ul></li></ol><h3 id="RNN-LSTM"><a href="#RNN-LSTM" class="headerlink" title="RNN / LSTM"></a>RNN / LSTM</h3><ol><li><p>为什么需要 RNN？</p><p> 循环神经网络（Recurrent Neural Network, RNN）。当给定的数据是序列型数据，如文本、音频等数据时，我们往往希望模型能够学习到给定数据的上下文环境。例如，对于一个句子，序列模型试图从同一个句子前面的单词推导出关系。</p><p> <img src="imgs/rnn.png" alt="RNN"></p><p> 在循环神经网络的每一个时间步骤（time step）中，我们取一个输入 $x_i$ 和上一个节点的权值 $h_{i-1}$ 作为输入，并产生一个输出 $y_i$ 和权值 $h_i$，这个权值又被传递到下一个时间步骤，直到输入序列被读取完毕。</p><p> <img src="imgs/multi-tasks.jpg" alt="multi-tasks-rnn"></p><p> 普通的 RNN（Vanilla RNN）常使用 BP 算法来训练权值，但由于<strong>梯度消失 / 梯度爆炸</strong>问题，RNN 会丧失学习远距离信息的能力。为了解决远距离依赖问题，提出了 LSTM（Long Short-Term Memory）。</p></li></ol><ol start="2"><li><p>LSTM 网络</p><p> LSTM（Long Short-Term Memory）相对于普通 RNN 网络，能够显著的缓解长期依赖关系丢失的问题。LSTM 的主要思想是利用<strong>门结构</strong>来去除或添加单元之间信息传递的能力。LSTM 拥有三个门，来保护和控制单元状态，分别为<strong>遗忘门</strong>、<strong>输入门</strong>和<strong>输出门</strong>。</p><ul><li><p>遗忘门</p><p>  <img src="imgs/forget-gate.png" alt="forget-gate"><br>  第一步是决定从上一个单元中保留多少消息。将上一单元的状态 $h_{t-1}$ 和这一层的输入 $x_i$ 经过 sigmoid 层，输出一个 0-1 的值，代表要从上一层的单元状态保留多少信息。</p></li><li><p>输入门</p><p>  <img src="imgs/input-gate.png" alt="input-gate"><br>  这一步是决定在这一层的单元状态中保留多少信息。将上一单元的状态 $h_{t-1}$ 和这一层的输入 $x_i$ 分别经过 sigmoid 层和 tanh 层，得到一个候选的单元状态 $\tilde{C}_t$。</p><p>  <img src="imgs/update-cell.png" alt="update-cell"><br>  随后，根据遗忘门得到的遗忘比例 $f_t$ 和这一层要输入的单元状态 $\tilde{C}_t$，得到这一层的最终单元状态 $C_t = f_t<em>C_{t-1} + i_t</em>\tilde{C}_t$。</p></li><li><p>输出门</p><p>  <img src="imgs/output-gate.png" alt="output-gate"><br>  最终，我们需要决定这一层的单元的输出状态。将上一单元的状态 $h_{t-1}$ 和这一层的输入 $x_i$ 经过 sigmoid 层，确定要输出的部分 $o_t$，再将这一层的单元状态 $C_t$ 经过 tanh 层，再与 $o_t$ 结合，得到最终的输出状态 $h_t$。</p></li></ul></li></ol><ol start="3"><li><p>GRU 网络</p><p> 与 LSTM 对比，GRU 网络更加简单，训练更加高效。GRU 去除了单元状态，将 LSTM 的 3 个门减少到 2 个，分别为更新门和重置门，分别决定了应该让多少信息通过单元，以及应该丢弃多少信息。</p><p> <img src="imgs/gru.jpg" alt="gru"></p></li></ol><ol start="4"><li><p>如何计算 LSTM 和 GRU 的参数量？</p><p> 一个单元内一共有四个非线性门 ($W[h_{t-1},x_t] + b$)，每一个门内的可训练变量包括一个矩阵 $W$ 和一个置项 $b$。</p><p> 因此，一个 LSTM 非线性门的参数即为 <strong>(embed_size + hidden_size) * hidden_size +hidden_size</strong>，LSTM 四个门的总参数量为 <strong>((embed_size + hidden_size) <em> hidden_size +hidden_size) </em> 4</strong>。</p><p> 同理，一个 GRU 单元的参数量为 <strong>((embed_size + hidden_size) <em> hidden_size + hidden_size) </em> 3</strong>。</p></li></ol><ol start="4"><li><p>RNN / LSTM 的局限性</p><ul><li>对于 RNN 来说，在访问一个单元前需要遍历之前所有的单元，使得在长文本下极度容易出现梯度消失问题。</li><li>LSTM 利用门机制稍微缓解了 RNN 的梯度消失问题，但在超长文本前仍然存在该问题。</li><li>在 LSTM 中，在每一个单元中都有 4 个 MLP 层，需要消耗大量的计算资源，且模型本身不利于并行化。</li></ul></li></ol><h3 id="TextCNN"><a href="#TextCNN" class="headerlink" title="TextCNN"></a>TextCNN</h3><ol><li><p>如何卷积？</p><p> 输入一个长度为 $s$ 的句子，将其分词后映射到词向量，假设词向量的维度为 $d$，那么该句子可以表示为一个 $s\times d$ 的矩阵。将该矩阵看作一张图像，用卷积神经网络提取特征。</p><p> <strong>文本卷积和图像卷积的区别在与文本序列只在垂直方向做卷积</strong>，即卷积核的宽度固定为词向量的维度 $d$。 </p></li></ol><ol start="2"><li><p>TextCNN 的优缺点？</p><ul><li>优点：网络结构简单，训练速度快，适合进行并行化，对短文本效果好；使用 Max-Pooling，便于提取最关键信息，因此适用于文本分类等任务。</li><li>缺点：全局 Max-Pooling 丢失了结构信息，很难发现文本中的依赖关系；只能学习到关键词是什么，无法学习到关键词的频率和顺序。</li></ul></li></ol><h3 id="Attention-Mechanism-Transformer"><a href="#Attention-Mechanism-Transformer" class="headerlink" title="Attention Mechanism / Transformer"></a>Attention Mechanism / Transformer</h3><ol><li><p>Seq2Seq 中的 Attention 机制</p><p> 在 Seq2Seq 中，我们使用 encoder 将输入文本转化为一个定长向量，再用 decoder 将该向量转换为输出文本。但是，在面对长文本时，我们很难在定长向量中保留完整的输入文本信息，因此在 decode 时会存在信息丢失的问题。为了缓解这个问题，我们引入了 Attention 机制。</p><p> 以机器翻译任务举例，在翻译到某一个单词时，我们希望能够注意到这个单词所对应的上下文，并结合之前已翻译的部分作出相应的翻译。这样，我们在 decoder 中就可以注意到输入文本的全部信息，而不只局限于那个定长的向量。</p><p> Attention 的计算过程如下：</p><ul><li>得到 encoder 中的 hidden state $\overrightarrow{h_e} = (h_1, h_2, …, h_n)$。</li><li>假设当前翻译到的 decoder state 为 $\overrightarrow{s_{t-1}}$，则可以计算该状态与输入的每一个单元 $h_j$ 状态的关联性 $e_{tj} = a(s_{t-1},h_j)$，写成向量形式则为 $\overrightarrow{e_t} = a(\overrightarrow{s_{t-1}}, \overrightarrow{h})$，其中，$a$ 是相关性的计算，常见的计算方式有：<ul><li>直接点乘 $a(s_{t-1},h_j)=\overrightarrow{s_{t-1}}^T\cdot\overrightarrow{h}$；</li><li>加权点乘 $a(s_{t-1},h_j)=\overrightarrow{s_{t-1}}^T\cdot W \cdot\overrightarrow{h}$，其中，$W$ 是可训练矩阵；</li><li>多层感知机 $a(s_{t-1},h_j)=V \cdot \tanh(W_1 \cdot \overrightarrow{s_{t-1}} + W_2 \cdot \overrightarrow{h})$，其中，$V$、$W_1$、$W_2$ 都是可训练矩阵；</li><li>缩放的点乘 $a(s_{t-1},h_j)=\frac{\overrightarrow{s_{t-1}}^T\cdot\overrightarrow{h}}{\sqrt{|\overrightarrow{h}|}}$。Softmax 函数对非常大的输入很敏感。这会使得梯度的传播出现问题，并且会导致学习的速度下降，甚至会导致学习的停止。那如果我们使用 $\sqrt{|\overrightarrow{h}|}$ 来对输入的向量做缩放，就能够防止进入到 softmax 函数的饱和区，使梯度过小。</li></ul></li><li>对 $\overrightarrow{e_t}$ 进行 softmax 操作后得到 Attention 分布 $\overrightarrow{\alpha_t} = softmax(\overrightarrow{e_t})$，其中，$\alpha_{tj} = \frac{\exp(e_{tj})}{\sum_{i=1}^n \exp(e_{ti})}$。</li><li>计算得到<strong>上下文表示</strong> $\overrightarrow{c_t}=\sum_{j=1}^n \alpha_{tj}\cdot h_j$。</li><li>我们可以将该上下文表示利用到下一个时间步的状态生成 $s_t = f(s_{t-1}, y_{t-1}, c_t)$。</li></ul></li></ol><ol start="2"><li><p>Q(Query), K(Key), V(Value)</p><p> 在 Attention 中，Q(Query) 指的是被查询的向量，即根据什么来关注其他的单词；K(Key) 指的是查询的向量，即被关注的向量的关键词；V(Value) 则是的被关注的信息本身。</p><p> 使用 Q 和 K 计算了相似度之后得到相似度评分，之后有了相似度评分，就可以把内容 V 加权回去了。</p></li></ol><ol start="3"><li><p>Transformer</p><p> 既然我们知道 Attention 机制本身就可以获取上下文信息，那么我们可不可以将原本的 RNN 结构完全去掉，仅仅依赖于 Attention 模型呢？这样我们可以使得训练并行化，并且可以拥有全局的信息。根据这个思想，产生了 Transformer 模型。其模型结构如下：</p><p> <img src="imgs/transformer.jpg" alt="transformer"></p><ul><li><p>Self-Attention 机制</p><p>  Seq2Seq 中的 Attention 机制是在 decode 过程中，逐步计算对应的上下文表示，仿照这个思想，Self-Attention 就是在 encode 阶段，便考虑到每个输入单词与其他单词的关联性，从而得到具有上下文信息的 input embedding 信息。因此，对于 Self-Attention，其 Q, K, V 都来自于同一个输入矩阵，即 Q=K=V。</p><p>  Self-Attention 的计算过程如下：</p><ul><li>输入序列 $\overrightarrow{x}$；</li><li>将 $\overrightarrow{x}$ 分别与对应 Q, K, V 的三个可训练矩阵 $W_q$, $W_k$, $W_v$ 点乘，得到 $Q=\overrightarrow{x}\cdot W_q$, $K=\overrightarrow{x}\cdot W_k$, $V=\overrightarrow{x}\cdot W_v$；</li><li>计算 $Attention(Q,K,V)=softmax(\frac{Q\cdot K^T}{\sqrt{d_K}})\cdot V$，其中，$d_K$ 为 $K$ 的维度。</li></ul></li><li><p>Multi-Head Attention</p><p>  为了使模型能够<strong>从不同角度获取输入序列的上下文信息表示</strong>，同时引入多组 ($W_{qi}$, $W_{ki}$, $W_{vi}$) 矩阵，分别得到多个 ($Q_i$, $K_i$, $V_i$)，再将它们<strong>按列拼接</strong>，之后经过一个联合矩阵 $W_o$，得到最终的 Attention 表示。过程如图所示：</p><p>  <img src="imgs/multi-head.jpg" alt="multi-head"></p><p>  注意，在 Transformer 的模型中，有多个 Multi-Head Attention 步骤。其中，encoder 中的 Attention 和 decoder 中的第一步 Attention 的步骤都仅以前一级的输出作为输入，而在 decoder 中的第二步 Attention 则不仅接受来自前一级的输出，还要接收 encoder 的输出。</p><p>  即，在第一种 Multi-Head Attention 中，有 $Q = K = V$，在第二种 Multi-Head Attention 中，则 $Q \neq K = V$: $Q$ 指的是 target 序列，而 $Q$ 和 $K$ 指的是输入序列。</p></li><li><p>Positional Encoding</p><p>  由于 Transformer 模型没有循环结构或卷积结构，为了使模型能够学习到输入序列的顺序，我们需要插入一些关于 tokens 位置的信息。因此提出了 <strong>Positional Encoding</strong> 的概念，其与 input embedding 具有相同的维度，便于相加。</p><p>  但是，如果直接使用计数的方式来进行 encoding，即 $pos = 1, 2, …, n - 1$，那么最后一个 token 的encoding 将会比第一个 token 大很多，与原 embedding 相加后会造成数据不平衡的现象。原论文作者们的方法是使用了不同频率的正弦和余弦函数来作为位置编码：<br>  $$</p><pre><code>  \begin{aligned}      PE_{(pos,2i)}   &amp; = sin(pos/10000^{2i/d_{model}}) \\      PE_{(pos,2i+1)} &amp; = cos(pos/10000^{2i/d_{model}}) \\  \end{aligned}</code></pre><p>  $$</p><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">def</span> <span class="token function">get_positional_embedding</span><span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> max_seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>      positional_embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>              <span class="token punctuation">[</span>pos <span class="token operator">/</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">2.0</span> <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> d_model<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># i 的取值为 [0, d_model)</span>              <span class="token keyword">for</span> pos <span class="token keyword">in</span> range<span class="token punctuation">(</span>max_seq_len<span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># pos 的取值为 [0, max_seq_len)</span>          <span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># 进行 sin / cos 变换</span>      positional_embedding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>positional_embedding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      positional_embedding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>positional_embedding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token keyword">return</span> positional_embedding<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Add &amp; Norm 层</p><ul><li>Add 指的是 Residual Connection，$y=F(x)+x$. 与 ResNet 的原理相似，是将上一层的信息直接传到下一层，可以帮助解决多层神经网络训练困难的问题。同时，引入残差连接有助于减轻神经网络在深层退化的问题。</li><li>Norm 指的是 Layer Normalization，在层与层之间对每一行数据进行缩放。这样可以缓解梯度消失的状况，同时使模型更快收敛。<blockquote><p><strong>Batch Normalization 和 Layer Normalization 的区别？</strong></p><p>在 BN 中，我们将每一个 batch 中的数据<strong>按列</strong>进行缩放。而在 NLP 任务中，由于输入序列的长度是不确定的，且不同行同一位置的单词直接并没有直接联系，直接做缩放可能会影响原语义表达。因此，在 NLP 等序列型任务中，我们一般采用 Layer Normalization，即对每一行数据进行缩放。</p></blockquote></li></ul></li></ul></li></ol><ol start="4"><li><p>BERT: Bi-directional Encoder Representation from Transformers</p><ul><li><p>双向表示</p><p>  区别于 Bi-LSTM 的双向表示，分别正序和反序得到表示再进行拼接，BERT 中的双向指的是根据前文和后文来预测被 masked 的单词。</p></li><li><p>Embedding</p><p>  BERT 中的 embedding 由三个部分组成：Token Embedding，Segment Embedding，Position Embedding。</p><ul><li>Token Embedding 是词向量，其中，第一个词为 [CLS] 标记，可以用于之后的下游任务。</li><li>Segment Embedding 用于区分 BERT 输入的两个句子，之后的 pre-training 将会用到。</li><li>Position Embedding 由学习得到，而不是普通 Transformer 中的三角函数。</li></ul></li><li><p>Pre-training Tasks</p><ul><li><p>Masked LM</p><p>  在训练过程中，将 15% 的单词用 [mask] 代替，让模型去预测被遮挡的单词，最终的损失函数只计算被遮盖的 token。</p><p>  但是如果一直用 [mask] 表示（实际预测时并不会遇到 [mask] 标记）会影响模型，因此作者设置了一下规则：80% 的时间用 [mask] 来代替被遮盖的单词，10% 的时间随机用另一个单词代替，剩下 10% 的时间保留原单词。</p><p>  值得注意的是，模型并不知道哪些单词被遮盖了，这使得模型能够关注到每一个单词，依赖上下文信息预测单词，赋予了模型一定的纠错能力。</p></li><li><p>Next Sentence Prediction</p><p>  对于输入的两个句子 A 和 B，让模型预测 B 是否应该是 A 的后一句。该任务的目的是让模型理解两个句子直接的关系。</p></li></ul></li><li><p>为什么BERT在第一句前会加一个 [CLS] 标志?</p><p>  为了获得整个句子的语义表示，用于其他任务。一个没有明显语义的 [CLS] 标记会更加<strong>公平</strong>地融合句子中每个单词的语义，从而获得更加完整的句子表示。</p></li><li><p>BERT 的优缺点？</p><p>  优点是建立在 Transformer 上，相对rnn更加高效，具有强大的信息提取能力，能捕捉更长距离的依赖。且双向模型比单向的 Transformer 效果更好；</p><p>  缺点则是该模型几乎无法修改，只能拿来直接用。由于只能预测 15% 的词，模型收敛较慢，需要强大算力支撑。</p></li><li><p>使用BERT预训练模型为什么最多只能输入 512 个词，最多只能两个句子合成一句？</p><p>  这是由于在预训练的时候，在参数中设置了 position embedding 的大小和 segment embedding 的大小，分别为 512 和 2。在这之外的单词和句子会没有与之对应的 embedding。</p></li><li><p>BERT 的输入和输出分别是什么？</p><p>  输入是 token embedding，segment embedding 和 position embedding，输出是文本中各个字 / 词融合了全文语义信息后的向量表示。</p></li><li><p>计算 BERT 模型的参数数量？</p><ul><li><p>词向量参数：vocab_size=30522, hidden_size=768, max_position_embedding=512, token_type_embedding=2，因此参数量为 (30522 + 512 + 2) * 768。</p></li><li><p>Multi-head Attention：len = hidden_size = 768, $d_k$ = $d_q$ = $d_v$ = $d_{model}/n_{head}$ = 768 / 12 = 64，将12个头进行拼接后还要进行线性变换，因此参数量为 768 <em> 64 </em> 12 <em> 3 + 768 </em> 768。</p></li><li><p>前馈网络参数：$\text{FFN}(x)=\max(0, xW_1+b_1)W_2 + b_2$，W_1 和 W_2 的参数量均为 768 <em> (768 </em> 4)，总参数量为 768 <em> 768 </em> 4 * 2。</p><p>总参数量 = 词向量参数 + 12 (层数) * (Multi-head + 前馈网络) = 110M</p></li></ul></li></ul></li><li><p>ALBERT</p><ul><li><p>Factorized Embedding Parameterization</p><p>  在 BERT 中，模型直接将词表对应到 word embedding 中，embedding 的维度大小和隐藏层 H 的维度大小相等。这是没有必要的，因为当维度大小 $d_H$ 增加时，word embedding 维度的增加没有意义。因此引入多一层转换矩阵 E，让词表 V 先通过转换矩阵，再转换为隐藏层的维度大小。这样可以明显减小参数量，由之前的 $(d_V <em> d_H)$ 减少为 $(d_V </em> d_E + d_E * d_H)$。</p></li><li><p>Cross-Layer Parameter Sharing</p><p>  BERT 框架中的参数主要包括 Attention 层的参数和 Feed Forward 网络的参数，ALBERT 将这些参数都共享，大大减小了参数量，为了弥补性能的损失，ALBERT 加大了隐藏层的维度大小，由“窄而深”变成“宽而浅”。</p></li><li><p>Sentence Order Prediction </p><p>  针对 BERT 的第二个训练任务，即判断 A 是否是 B 的下一句话，过于简单的问题，ALBERT 增加了预训练的难度，即将负样本换成了两个句子的逆序排列。</p><blockquote><p><strong>[NSP 任务]</strong> 正样本：同一个文档的两个连续句子；负样本：两个连续句子交换顺序</p><p><strong>[SOP 任务]</strong> 正样本：同一个文档的两个连续句子；负样本：不同文档的句子</p></blockquote></li></ul></li></ol><ol start="6"><li><p>XLNet</p><p> 由于 BERT 在预训练过程中需要加入 [mask]，而在下游任务及预测过程中都没有这样的标记，因此会造成性能损失。XLNet 则通过自回归语言模型的思想来解决，即从左到右依次生成。为了保持模型仍然是双向的，能够同时从前文和后文获取信息，XLNet 引入了 Attention Mask 机制。</p><p> 假设模型在预训练过程中需要预测第 $k$ 个词，那么首先先将序列随机打乱，再取前 $k-1$ 个词进行预测，这样既可以读到前后文的信息，又可以省去 [mask] 标记。</p><p> 这样的预训练模式天然符合下游任务序列生成的任务，因此可以预计 XLNet 在文本摘要，机器翻译，信息检索等领域具有优势。</p></li></ol><ol start="7"><li><p>TinyBERT</p><p> 由于 BERT 模型过于庞大，很难实际应用落地。因此提出了一种蒸馏 BERT 的方法 TinyBERT，它的大小不到 BERT 的 1/7，但速度提高了 9 倍。</p><p> 知识蒸馏的基本思想是使用一个大的训练好的模型来知道小模型更好的训练。TinyBERT 的基本思想是减少 Transformer 的层数以及降低 hidden_size 的大小。模型结构如下：</p><p> <img src="imgs/TinyBERT.jpg" alt="TinyBERT"></p><p> TinyBERT 的 loss 分为三部分：</p><ul><li><p>Embedding Layer Distillation</p><p>  TinyBERT 的 embedding 大小比教师模型更小，因此需要通过一个维度变换矩阵来把学生模型的 embedding 映射到教师模型所在空间，再通过 MSE 来计算 loss：<br>  $$</p><pre><code>  \mathcal{L}_{embd}= \text{MSE}(E^SW_e, E^T)</code></pre><p>  $$</p></li><li><p>Transformer Layer Distillation</p><p>  TinyBERT 的知识蒸馏采取每隔 k 层蒸馏的方式。设 Teacher BERT 有 12 层，TinyBERT 有 4 层，则学生模型每隔 3 层就与教师模型计算一次 loss，其中，loss 又分为 Attention Loss 和 Hidden Loss：</p><p>  $$</p><pre><code>  \mathcal{L}_{attn} = \frac{1}{h}\sum_{i=1}^h \text{MSE}(A_i^S, A_i^T)</code></pre><p>  $$<br>  其中，h 为 Attention 头数，$A_i\in \{A_q,A_k,A_v\}$。</p><p>  $$</p><pre><code>  \mathcal{L}_{hidn} = \text{MSE}(H^SW_h, H^T)</code></pre><p>  $$</p></li><li><p>Prediction Layer Distillation</p><p>  在预测层的 loss 计算取决于不同的具体任务，但都需要结合教师模型和学生模型的 loss。</p></li></ul></li></ol><ol start="8"><li><p>RoBERTa</p><ul><li>去除 NSP 任务</li><li>动态掩码。RoBERTa的做法是将训练数据复制多份，每份采用不同的随机挑选 token 进行掩码。这样有助于模型适应不同的掩码策略，学习不同的语言表征。</li><li>文本编码。使用了更大的词汇表来训练。</li><li>可以看作是一个“调过参的 BERT 版本”</li></ul></li></ol><h3 id="Speech-Translation"><a href="#Speech-Translation" class="headerlink" title="Speech Translation"></a>Speech Translation</h3>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ML_Competition</title>
      <link href="/2022/09/28/ml-competition/"/>
      <url>/2022/09/28/ml-competition/</url>
      
        <content type="html"><![CDATA[<h2 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h2><ol><li><p>数据集基本情况：数据大小，字段类型；</p></li><li><p>重复值、缺失值、异常值：去除重复值，缺失值是否严重或有特殊含义，如何发现异常值；</p></li><li><p>特征之间是否冗余：特征之间相似性分析；</p></li><li><p>是否存在时间信息：当存在时间信息时，需要进行相关性、趋势性、周期性和异常点的分析，还有可能涉及潜在的数据穿越问题；</p></li><li><p>标签分布：</p><p> 分类问题：类别分布不均衡；</p><p> 回归问题：存在异常值，整体分布情况，是否需要进行目标转换</p></li><li><p>训练集和测试集的分布： 是否有很多只在测试集中存在的特殊字段</p></li><li><p>单变量/多变量分布：熟悉特征的分布情况以及标签和特征之间的关系</p></li></ol><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><pre class="line-numbers language-Python"><code class="language-Python">train['SalePrice'].describe()plt.figure(figsize=(9,8))sns.distplot(train['SalePrice'], color='g', bins=100, hist_kws={'alpha':0.4})## 相似性矩阵corrmat = train.corr()f, ax= plt.subplots(figsize=(20,9))sns.heatmap(corrmat, vmax=0.8, square=True)## 多变量分析plt.style.use('seaborn-white')type_cluster = train.group_by(['Neighborhood', 'OverallQual']).size()type_cluster.unstack().plot(kind='bar', stacked=True, colormap='Pubu', figsize=(13,11), grid=False)plt.xlable('OverallQual', fontsize=16)plt.show()## 特征关联性分析def feature_select_pearson(train, features):    featureSelect = features[:]    corr = []    for feat in featureSelect:        corr.append(abs(train[['feat', 'target']].fillna(0).corr().values[0][1]))    se = pd.Series(corr, index=featureSelect).sort_values(ascending=False)    feature_select = se[:300].index.tolist()    return train[feature_select]## 特征重要性分析 params = {'max_depth':10,'subsample':1,'verbose_eval':True,'seed':12,'objective':'binary:logistic'}xgtrain = xgb.DMatrix(x, label=y)bst = xgb.train(params, xgtrain, num_boost_round=10)## weight 指代被选为分裂特征的次数；gain 指代特征在所有树中作为分裂节点信息增益之和再除以该特征出现的频次；cover 指代特征被分到该节点的二阶导数之和importance = bst.get_score(fmap='', importance_type='weight')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><ul><li>缺失值处理：<ol><li>类别特征：众数或者新类别；</li><li>数值特征：平均数、中位数、众数、最大最小值；</li><li>有序数据(时间序列)：填充相邻值next|previous</li></ol></li><li>异常值处理：<ol><li>删除含有异常值记录；</li><li>将异常值视为缺失值；</li></ol></li></ul><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><ul><li><p>损失函数：</p><p>  Lasso &amp;&amp; Ridge: 对传统L1/L2正则增加惩罚项</p></li><li><p>树模型：</p><ol><li><p>随机森林(Bagging)：</p><p> 基于非线性树的模型，通过集成学习的思想将多个决策树集成在一起投票得到最终结果</p><p> 并行特性，适合分布式训练，且不易过拟合</p><p> 有放回随机抽样训练决策树，随机选取属性做节点分裂属性(信息增益、信息增益比、基尼指数)，直至不能再分裂(节点的所有样本均属于同一类)</p><pre class="line-numbers language-Python"><code class="language-Python"> from sklearn.ensemble import RandomForestClassifier rf = RandomForestClassifier(max_fefatures='auto', oob_score=True, random_state=1, n_jobs=1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>梯度提升树(Boosting):</p><p> 串行学习一系列基学习器，每次生成一棵树，学习目标是上棵树的残差</p><p> 估计方差增加，对数据中的噪声敏感(可通过子采样减弱)，非并行操作计算成本显著</p></li><li><p>XGBoost:</p><p> 采用稀疏感知算法。利用稀疏矩阵节省内存(不需要密集矩阵)和计算时间(特殊方式处理零值)；</p><p> 加权分位数略图近似树学习节省分支切割探索时间(广度优先搜索BFS)；</p><p> 利用核外计算的优化算法解决磁盘读取数据时间过长问题(独立线程专门读取并行运行数据加载和计算)；</p><p> 有效处理缺失值，训练时对缺失值自动学习切分方向</p><pre class="line-numbers language-Python"><code class="language-Python"> import xgboost as xgb params = {'eta':0.01, 'max_depth':11, 'objective':'reg:linear', 'eval_metric': 'rmse'} dtrain = xgb.DMatrix(data=X_train, label=y_train) dtest = xgb.DMatrix(data=X_valid, label=y_valid) watchlist=[(train_data, 'train'), (valid_data, 'valid')] model= xgb.train(param,train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose=500) y_pred = model.predict(xgb.DMatrix(X_test), ntree_limit= model.best_ntree_limit)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>LightGBM:</p><p> 基于分布式，可以快速处理大量数据，在非常复杂的树中捕获训练数据的底层模式；</p><p> 专注于按叶子节点进行划分以便获得更好的拟合(深度优先搜索DFS);</p><pre class="line-numbers language-Python"><code class="language-Python"> import lightgbm as lgb params = {'num_leaves':54, 'objective':'regression', 'max_depth':18, 'learning_rate':0.01, 'boosting':'gbdt', 'metric':'rmse', 'lambda_l1':0.1} model = lgb.LGBMRegressor(**params, n_estimators=20000, nthread=4, n_jons=-1) model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',verbose=1000, early_stopping_rounds=200) y_pred = model.predict(X_test, num_iteration=model.best_iteration_)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>CatBoost:</p><p> 支持类别特征，无需预处理类别特征，采用独热编码和均值编码混合的策略处理类别特征；</p><p> 提出全新梯度提升机制(Ordered Boosting)，减少过拟合风险，提升准确性；</p><p> 支持GPU训练(设置task_type=’GPU’)；</p><p> 训练中使用组合类别特征，利用特征之间的联系极大丰富了特征维度</p><pre class="line-numbers language-Python"><code class="language-Python"> from catboost import CatBoostRegressor params = {'learning_rate':0.02, 'depth':13, 'bootstrap_type':'Bernoulli', 'od_type':'Iter', 'od_wait': 50, 'random_seed': 11} model = CatBoostRegressor(iterations=20000, eval_metrix='RMSE', **params) model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False) y_pred = model.fit(X_test)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>模型对比：</p><ol><li>XGBoost 使用Level-wise按层生长，可以同时分裂同一层叶子，从而进行多线程优化，不容易过拟合。但很多叶子节点的分裂增益较低会影响性能；LightGBM使用Leaf-wise分裂方式，每次都从当前叶子中选择增益最大的结点进行分裂。但会生成非常深的决策树导致过拟合；CatBoost使用oblivious-tree，节点镜像生长。这种树结构起到了正则化的作用不容易过拟合；</li><li>XGBoost和LightGBM都是有偏梯度估计，梯度估计和建立模型使用的数据是相同的，这样会导致数据泄漏产生过拟合；CatBoost通过利用所有的数据集(除第i条)构建模型$M_i$，并利用1到i-1条数据建造修正树累加到原有模型上；</li><li>XGBoost不能处理类别特征，需要搜互动根据数据实际情况进行独热编码、count编码和目标编码；LightGBM直接支持类别特征，不需要独热展开；CatBoost在处理类别特征时可以选择不进行多余的编码方式；</li><li></li></ol></li></ol></li></ul><h2 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h2><ol><li><p>减少内存占用：</p><p> 类别型变量可采用(有顺序关系)自然数编码(无顺序关系)独热编码，数值型变量采用归一化*100/1000取整</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Book </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Competetion </tag>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Video_Enhance</title>
      <link href="/2022/09/26/video-enhance/"/>
      <url>/2022/09/26/video-enhance/</url>
      
        <content type="html"><![CDATA[<h1 id="Video-Enhance"><a href="#Video-Enhance" class="headerlink" title="Video Enhance"></a>Video Enhance</h1><ul><li><p>Faster Super-Resolution CNN:</p><p>  使用反卷积代替插值的预处理实现上采样，大大减少模型计算量；</p><p>  使用ResNet bottleneck 架构提高模型精度；</p><p>  使用更小的卷积和更多的卷积层来替代大的卷积核</p></li><li><p>Efficient Sub-Pixel CNN:</p><p>  只在模型末端使用亚像素卷积(将特征图通道数中连续的c个通道作为一个整体进行像素重排列，最终得到多通道的上采样图)的方式上采样，在低分辨率空间中保留更多的纹理区域，同时在视频超分中做到实时；</p></li></ul><h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN:"></a>GAN:</h2><ul><li><p>CGAN:</p><p>  在生成网络的输入上将类别标签和噪声信号组成起来作为输入；</p><p>  在判别网络中将类别标签和图像数据拼接后作为输入；</p></li></ul><h2 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h2><ol><li>1*1 卷积核增加非线性</li><li>Dropout防止过拟合</li><li>K_Means 聚类后去Anchor比例</li><li>梯度消失(Gradient Vanishment): 传统神经网络采用Sigmoid作为激活函数，当层数较高时，Sigmoid函数在反向传播中的梯度值随着多次相乘逐渐减小，经过多层传递后会呈现指数级减小，发生梯度消失现象<br>。ReLU函数可以解决此现象</li></ol><h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object_Detection:"></a>Object_Detection:</h2><ul><li><p>Region CNN:</p><p>  首次将手动提取特征的方法更换为卷积神经网络，将经典目标检测算法中通过滑动窗口对所有可能区域的判断更换为提取一系列可能是物体的候选区域，并在候选区域上提取特征进行判断</p><p>  候选框大量重复，计算速度很慢，大量特征冗余，目标分类和定位回归的特征存储需要占用大量的内存</p></li><li><p>Selective Search:</p><p>  假设：物体存在的区域之间有相似性或连续性</p><p>  首先使用分割手段将图像分割成小区域并计算每两个相邻区域的相似度，合并可能性最高的两个区域(颜色直方图相近、梯度直方图相近、合并后总面积最小、在其边界框所占比例大优先合并)，依据生成顺序对每个图像块添加权重</p></li><li><p>Bounding Box Regression:</p><p>  对每一类目标使用一个线性回归器进行精修，候选框和真实边界框近似为线性关系。</p><p>  候选区域$P^i=(P_x^i, P_y^i, P_w^i, P_h^i)$，真实边界框$G=(G_x, G_y, G_w, g_h)$，线性变换的参数为$d_x(P), d_y(P), d_w(P), d_h(P)$<br>  $$\hat G_x=P_wd_x(P) + P_x$$<br>  $$\hat G_y=P_hd_y(P) + P_y$$<br>  $$\hat G_w=P_wexp(d_w(P))$$<br>  $$\hat G_h=P_hexp(d_h(P))$$<br>  假设任意一个线性变换的参数是特征$\phi(P)$的一个线性映射<br>  $$d_<em>(P)=w_</em>^T\phi(P)$$<br>  损失函数使用带L2范数的最小均方误差，$t_<em>^i$是优化问题的目标<br>  $$w_</em>=\argmin_{\hat w_<em>}\sum_i^N(t_</em>^i-\hat w_<em>^T\phi_5(P^i))^2+\lambda \hat w_</em>^2$$<br>  $$t_x=(G_x- P_x)/P_w$$<br>  $$t_y=(G_y- P_y)/P_h$$<br>  $$t_w=log(G_w/P_w)$$<br>  $$t_h=log(G_h/P_h)$$</p></li><li><p>Fast R-CNN:</p><p>  候选特征不需要重复计算；</p><p>  Region of Interest pooling 生成固定尺寸特征，代替R-CNN中的区域图像缩放；</p><p>  利用深度神经网络的全连接神经网络，设计分类和回归同步的多任务损失，同步完成整个算法的目标分类和定位回归任务</p></li><li><p>Faster R-CNN:</p><p>  设计以全卷积网络为基础的Region Proposal Network并与目标检测的卷积神经网络共享，将目标检测的四个基本步骤统一为一个端到端的神经网络，大大提高速度</p></li><li><p>Mask R-CNN:</p><p>  使用RoI Align代替RPN，双线性内插值解决区域不匹配问题</p><p>  在每一个RoI上的小全连接神经层加入一个应用，实现在像素级别上预测分割mask</p></li><li><p>Cascade R-CNN:</p><p>  在基于不同IOU阈值确定的正负样本上，通过训练R-CNN系列来检测网络级联。级联的结构是为了通过调整边界框给下一阶段找到一个IOU更好的正样本来训练</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Book </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Basic </tag>
            
            <tag> Competetion </tag>
            
            <tag> Video_Enhance </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge_Graph</title>
      <link href="/2022/09/22/knowledge-graph/"/>
      <url>/2022/09/22/knowledge-graph/</url>
      
        <content type="html"><![CDATA[<h1 id="KnowLedge-Graph"><a href="#KnowLedge-Graph" class="headerlink" title="KnowLedge_Graph"></a>KnowLedge_Graph</h1><ul><li><p>Main works:</p><ol><li><p>Named Entity Recognition:</p><p> 负责三元组(SPO)中主客体的边界与类别的识别工作</p></li><li><p>Relation Extraction:</p><p> 负责三元组中主客体之间关系类别的分类工作</p></li><li><p>Knowledge Fusion:</p><p> 对来自给定的多个不同知识图谱的三元组进行对齐</p><ul><li>无监督实体对齐: 通过对实体属性提取特征，并根据特征相似度进行聚类来实现对齐。<em>编辑距离、Jaccard系数、余弦相似度</em>衡量实体相似度</li><li>有监督实体对齐: 通过PairWise方法对来自不同知识图谱的实体进行两两配对，并利用人工标注标签来构建训练集</li></ul></li><li><p>Referential Resolution:</p><ul><li>Mention Pair: 与有监督实体对齐方法类似。通过实体识别得到句子中所有Mention词，再使用PairWise方法对Mention词两两配对，最终训练出二分类分类器表示Mention词是否指代同一事物。进行预测时需要通过共指传递性进行补全<br>$$Loss=-\sum_{ij}y_{ij}logP(m_i,m_j)$$<br>正例$y_{ij}=1$,负例$y_{ij}=-1$</li><li>Mention Ranking:通过对某个Mention词只预测一个相关Mention的方式来减少错误传递，提高预测准确率<br>$$Loss=-\sum_i\sum_jy_{ij}logP(m_i,m_j)$$<br>正例$y_{ij}=1$,负例$y_{ij}=0$</li></ul></li></ol></li></ul><h2 id="知识推理：知识图谱的补全和质量校验"><a href="#知识推理：知识图谱的补全和质量校验" class="headerlink" title="知识推理：知识图谱的补全和质量校验"></a>知识推理：知识图谱的补全和质量校验</h2><ol><li><p>基于符号逻辑的推理</p><p> 符号逻辑推理主要是基于描述逻辑的本体推理。描述逻辑是一种基于对象的知识形式化表达，具有很强的表达能力与可判定性。包含概念与关系、Tbox公理集、Abox断言集、推理机制</p></li><li><p>基于表示学习的推理<br> 通过将学习的对象自动地由机器表示为隐式特征来获取更强的表达能力。</p><ul><li><p>Translating Embedding:</p><p>  将实体与关系映射为同样维度的向量，通过随机替换头尾实体得到负样本。只能处理一对一的关系<br>  $$Loss = \sum max(0, \gamma+d_{pos}(h+r,t)- d_{neg}(h’+r’, t’))$$</p></li><li><p>Random Walk:</p><p>  尝试对图中节点进行表示学习的方法: 给定图中节点，从其邻居中随机采样作为下一个访问节点，直到序列长度符合预设条件</p></li><li><p>Graph Neural Network:</p><p>  针对图结构的表示学习方法，主要通过图卷积对目标周围邻居节点所携带的信息进行聚合<br>  $$x_i^k=\gamma^k(x_i^{k-1}, AGG(\phi^k(x_i^{k-1}, x_j^{k-1}, e_{ij})))$$<br>  其中AGG为聚合方法(SUM|MEAN),$\gamma$和$\phi$是两个需要学习的层</p></li></ul></li></ol><h2 id="神经语言模型"><a href="#神经语言模型" class="headerlink" title="神经语言模型"></a>神经语言模型</h2><ul><li><p>Skip-Gram模型: 通过中心词预测上下文窗口的词。</p><p>  计算中心词和上下文窗口词的损失，反向传播回对应的词向量，从而进行词向量的学习与更新</p></li><li><p>CBOW模型: 通过上下文的全部词预测中心词</p></li></ul><h2 id="自然语言处理深度学习基本结构"><a href="#自然语言处理深度学习基本结构" class="headerlink" title="自然语言处理深度学习基本结构"></a>自然语言处理深度学习基本结构</h2><ul><li><p>CNN1D: </p><p>  首先训练出每个单词的词向量，然后将处理为单词索引的句子作为输入，在经过Embedding层转换为对应的特征张量(bs, len, dim),提供给卷积CNN1D层，最后CNN1D层通过在句子长度方向上滑动卷积核来计算特征张量(bs, len, 1)。使用k种卷积核并对其分别进行最大池化再拼接得到池化张量，最终通过MLP和softmax层得到类别概率。</p></li><li><p>Recurrent Neural Network:</p><p>  循环神经网络对序列的每一个位置进行同样的循环单元计算，每一个循环单元除了要接受该位置的信息，还要接受上一个循环单元的输出作为输入，保持了长距离的上下文信息。<em>在训练过程中由于反向传播算法，梯度会在不同的时刻以乘法的形式进行积累，最终导致梯度爆炸或消失的问题</em></p></li><li><p>Long Short Term Memory:</p><p>  在RNN基础上增加Cell state来直接传递相邻时刻之间的信息，缓解了梯度消失的问题。同时引入采用Sigmoid激活的门控机制(遗忘门、输入门与输出门)，来分别控制上一时刻的细胞状态、输入信息及输出信息的进一步传递，从而实现信息的长短期记忆</p></li><li><p>Gated Recurrent Unit:</p><p>  对LSTM进行简化，将细胞状态和隐藏状态合并，经遗忘门和输入门合二为一，降低计算复杂度。由于门控单元使信息经过多次Sigmoid激活，减小了梯度爆炸的可能性，实际操作中可采用梯度裁剪进一步避免梯度爆炸。</p></li><li><p>Attention Mechannical:</p><p>  将编码器的全部隐藏状态与当前时刻输入解码器的词向量做矩阵乘法，并进行Softmax归一化得到注意力权重，再与编码器的全部隐藏状态相乘的得到上下文向量。将该向量与输入的词向量进行拼接传入解码器中进行训练</p></li><li><p>Hidden Markov Model:</p><ul><li>观测独立性假设：任意时刻的观测只依赖于该时刻的状态；</li><li>一阶马尔可夫假设：任意时刻的状态只依赖于前一时刻的状态；<br>生成式有向图模型，由Viterbi算法解码求解概率模型。但受一阶马尔可夫假设限制，表达能力有限<br>$$P(X,Y)=P(y_0)\prod_{t=1}^nP(y_t|y_{t-1})P(x_t|y_t)$$<br>Viterbi: 对于给定的观测序列，寻找概率最大的隐藏状态序列，即在有向无环图中寻找一条最大路径<br>$$D_{t,j}=max(D_{t,j}, D_{t-1,k} + \theta_{kj})$$</li></ul></li><li><p>Maximum ENtropy Markov Models:</p><p>  判别式有向图模型，由于归一化参数是在累乘内部，局部归一化，每次状态转移都会倾向于选择拥有更少转移的状态,产生标注偏置问题。<br>  $$P(Y|X)=\prod_t P(y_t|y_{t-1}, x_t)$$<br>  $$P(y_t|y_{t-1}, x_t)=\frac{1}{Z}e^{\sum\lambda f(x,y)}$$</p></li><li><p>Conditional Random Filed:</p><p>  判别式无向图模型，全局归一化函数<br>  $$P(Y|X)=\frac{1}{Z}\prod_c\phi_c(y_c|x)$$<br>  $$\phi_c(y_c|x)=e^{\sum_k\lambda_kf_k(y_t,y_{t-1},x_t) + \mu_ks_k(y_t,x_t)}$$<br>  $$Z = \sum_y\prod_c\phi_c(y_c|x)$$</p></li><li><p>Bidirectional LSTM:</p><p>  利用前向循环网络和反向循环网络得到的输出按一定方式叠加，可以在任意时刻获得前后时刻的信息，自动构建输入数据特征与双向表达，比单向循环网络有更强的表达能力，但是预测的前后两个特征是相互独立的，出现如连续的<strong>Begin标签</strong>，可通过替换softmax为CRF,充分学习到标注之间信息。</p></li></ul><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo:"></a>Demo:</h2><pre class="line-numbers language-Python"><code class="language-Python">import jieba# 词性特征word_flags = []for text in texts:    for word, flag in jieba.posseg.cut(text):        word_flags += [flag] * len(word)# 词边界特征word_flags = []word_bounds = ['I' for s in texts for x in s]for text in texts:    for word, flag in jieba.posseg.cut(text):        if len(word)==1:            start = len(word_flags)            word_bounds[start] = 'S'            word_flags.append(flag)        else:            start = len(word_flags)            word_bounds[start] = 'B'            word_flags += [flag] * len(word)            end = len(word_flags) - 1            word_bounds[end] = 'E'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Relation-Extraction"><a href="#Relation-Extraction" class="headerlink" title="Relation Extraction:"></a>Relation Extraction:</h2><ul><li><p>基于依存句法的抽取：</p><p>  依存句法分析描述了单词之间的丰富的修饰关系，借助于修饰关系可以制定一些通用的规则，避免对每个关系逐一构建规则模板。</p></li><li><p>Multiple Instance Learning:</p><p>  多示例学习的基本单位为Bag,一个Bag中有多个Instance。</p><p>  Piecewise Convolutional Neural Network + Attention Implementation: 对Bag中的每个句子x,使用基本的PCNN模型计算得到(3k,1)的池化张量。由于包中共享一组实体对，首先计算实体对特征张量(dim,1)，然后将池化张量与实体对特征张量分别输入Attention层，通过注意力机制计算上下文权重，并利用该权重与包中所有句子的池化张量来计算包特征，再经过MLP层与Softmax层，最终输出包类别概率。</p></li></ul><h2 id="Feature-Project"><a href="#Feature-Project" class="headerlink" title="Feature Project:"></a>Feature Project:</h2><pre class="line-numbers language-Python"><code class="language-Python"># Instance distanceouter_len = max(e1['end'] - e2['end'])-  min(e1['start'], e2['start'])inner_len = max(e1['start'], e2['start']) - min(e1['end'], e2['end'])# Instance speechtext = []flags = []for w, flag in jieba.posseg.cut(sent):    text.append(w)    flags.append(flag)# Instance position hintseg = np.zeros(len(text))seg[e1b:e1e] += 0.1seg[e2b:e2e] -= 0.1# Instance relative positiondef cal_pos(begin, end, l):    if begin<0:        begin += 1        end += 1    median = (begin + end) /2    return np.arange(l) - mediane1pos = cal_pos(e1b, e1e, len(text))e2pos = cal_pos(e2b,e2e, len(text))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="NOTES"><a href="#NOTES" class="headerlink" title="NOTES:"></a>NOTES:</h2><ol><li>信息标注格式化解析<pre class="line-numbers language-Python"><code class="language-Python">label_r = label[label[0].str.startswith('R')]label_r.columns = ['id', 'relation']label_r['catagory'] = [r.split()[0] for r in label_r['relation'].tolist()]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>多线程并行处理<pre class="line-numbers language-Python"><code class="language-Python">def process_text(idx, target_dir='train', split_method=None): # process *.txt文件和对应的*.ann文件import multiprocessing as mpnum_worker = mp.cpu_count()pool = mp.Pool(num_worker)results = []# 获取文件idids = set([x.split('.')[0] for x in os.listdir('../data/train/')])for idx in ids: result = pool.apply_async(process_text, args=(idx, 'train', split_method)) reuslts.append(result)pool.close()pool.join()[r.get() for r in tqdm(results)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>远程监督<pre class="line-numbers language-Python"><code class="language-Python"># 关系列表relation = set([ 'Test_Disease', 'Symptom_Disease'])# 遍历全部关系datasets = []for r in tqdm(relation): c1, c2= r.split('_') e1_data = label_T[label_T['category']==c1] e2_data = label_T[label_T['category']==c2] # 实例两两组成三元组 for i, e1 in e1_data.iterrows():     for j, e2 in e2_data.iterrows():         begin = min(e1['start'], e2['start'])         end = max(e1['end'], e2['end'])         # 负样本筛选         if end - begin > max_len:             continue         sentence = clean(texts[begin:end])         datasets.append([e1['id'], e2['id'],e1['category'] + '_' + e2['category'], -1, sentence])label_R = set((r['arg1'], r['arg2']) for r in label_R)for i in range(len(datasets)): if tuple(datasets[i][:2]) in label_R:     datasets[i][3] = 1 else:     datasets[i][3] = 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li>句子窗口：<pre class="line-numbers language-Python"><code class="language-Python">if end - begin <=100: window = 50elif end - begin <= 140: window = 30else: window = 0num_pad = max_len - (end-begin)left_w = min(num_pad //2 , window)right_w = min(num_pad - left_w, window)begin = max(0, begin - left_w)end = min(len(text), end + right_w)sentence = clean(text[begin:end])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> Book </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Basic </tag>
            
            <tag> Knowledge_graph </tag>
            
            <tag> Competetion </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bayes_basic</title>
      <link href="/2022/09/21/bayes-basic/"/>
      <url>/2022/09/21/bayes-basic/</url>
      
        <content type="html"><![CDATA[<h2 id="参数化建模学习：概念和方向"><a href="#参数化建模学习：概念和方向" class="headerlink" title="参数化建模学习：概念和方向"></a>参数化建模学习：概念和方向</h2><h3 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h3><ol><li>一个无约束的最小化问题总是会导致损失函数小于或等于有约束的对应情形；</li><li>通过在最小方差无偏(Minimum Variance Unbiased)估计量中引入偏差缩小范数，可以获得比MVU更好的结果；</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>HDFS</title>
      <link href="/2022/09/17/hdfs/"/>
      <url>/2022/09/17/hdfs/</url>
      
        <content type="html"><![CDATA[<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><ul><li><p>Advantages:</p><ol><li>超大文件(TB,PB级)，主要处理搞数据吞吐量的应用;</li><li>支持流式数据访问。一次写入，多次读取;</li><li>低成本运行;</li></ol></li><li><p>Disadvantages:</p><ol><li>不适合处理低延时的数据访问；</li><li>不适合处理大量小文件。过多的小文件会消耗NameNode的内存；</li><li>不适合多用户写入及任意修改文件；</li></ol></li><li><p>Components &amp; Arch</p><ol><li><p>NameNode:</p><p> 负责管理和维护HDFS的NameSpace,维护操作日志文件edits和命名空间镜像文件fsimage；</p><pre><code> fsimage包含Hadoop文件系统中所有目录和文件的序列化信息;edits记录NameNode启动后对HDFS进行的各种更新操作</code></pre><p> 管理DataNode的Block，维持副本数量;</p><pre><code> 文件-&gt;数据块、数据块-&gt;DataNode映射列表</code></pre></li></ol></li></ul><pre><code>    接收客户端请求(上传、下载,等)2. DataNode:    数据块大小: 磁盘进行读、写最小单位。大数据块会减少寻址开销，减少磁盘一次读取时间。    数据节点存储数据块ID和内容，以及之间的映射关系。但一个数据块在一个DataNode上最多只有一个备份    DataNode和NameNode定时通信，接收NameNode的指令，通过启动时上报的方式更新NameNode上的映射表。3. SecondaryNameNode:    与NameNode运行在不同的机器上，内存一样大；    Checkpoint: 定期将NameNode的fsimage和edits下载到本地，并将它们加载到内存进行合并，最终将合并后的新的fsimage上传回NameNode；</code></pre><ul><li><p>Mechanical:</p><ol><li><p>rack-aware:</p><p> 通过外在脚本实现机架感知</p></li><li><p>副本冗余存储:</p><p> 提供容错机制，副本丢失或宕机时自动修复。副本一放置在上传文件的数据节点，副本二放置在与副本一不同的机架节点上，副本三放置在与副本二相同机架上的其他节点上。</p><p> 减少了机架间数据传输，提高写操作的效率及读取数据时需要的网络传输总带宽。</p></li><li><p>HDFS Shell operators:</p><pre class="line-numbers language-Shell"><code class="language-Shell">     hdfs dfs -mkdir [-p] <path>     # -h 人性化显示 -R级联显示     hdfs dfs -ls [-d][-h][-R] <path>     # 新建文件     hdfs dfs -touchz <path>     # 上传文件     hdfs dfs -put [-f][-p] <localsrc> <dst>     hdfs dfs -copyFromLocal [-f][-p][-l] <localsrc> <dst>     hdfs dfs -moveFromLocal <localsrc> <dst>     # 下载文件     hdfs dfs -get [-p] <src> <localdst>     hdfs dfs -copyToLocal [-p] [-ignoreCrc] [-crc] <src> <localdst>     # 查看文件 -ignoreCrc: 忽略循环检验失败的文件 -f: 动态更新显示数据     hdfs dfs -cat/text[-ignoreCrc] <src>     hdfs dfs -tail [-f] <file>     # 追写文件     hdfs dfs -appendToFile <localsrc> <dst>     hdfs dfs -rm [-f] [-r] <src>     # 显示占用的磁盘空间大小 -s: 显示指定目录下文件总大小     hdfs dfs -du [-s] [-h] <path>     # 复制文件 -f: 强行覆盖 -p: 保留文件属性     hdfs dfs -cp [-f] [-p|-p[topax]] <src> <dst>     # 文件合并后下载     hdfs dfs -getmerge [-nl] <src> <localdst>     # 统计目录下子文件及文件大小     hdfs dfs -count [-q] [-h] <path>     # 报告文件系统的信息     hdfs dfsadmin -report     hdfs dfsadmin -printTopology<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>HDFS Java API</p><pre class="line-numbers language-Java"><code class="language-Java">     // 实例化Configuration&FileSystem类     Configuration conf= new Configuration();     FileSystem fs= FileSystem.get(uri, conf, "username");     // 设置目标对象路径     Path path= new Path("/test");     // 执行文件或目录操作     package org.apache.hadoop.examples;     import java.io.FileInputSystem;     import java.io.InputStream;     import java.io.OutputStream;     import java.net.URI;     import org.apache.hadoop.conf.Configuration;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol></li></ul><pre><code>    ```</code></pre>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CV_Knowledge</title>
      <link href="/2022/09/14/cv-knowledge/"/>
      <url>/2022/09/14/cv-knowledge/</url>
      
        <content type="html"><![CDATA[<h2 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a><font color="blue"><strong>VAE</strong></font></h2><ul><li>INPUT: sample X</li><li>DISTRIBUTION: p(X)</li><li>HIDDEN VARIABLE: $Z:N(Mean, \delta^2)$<br>$$ p(X)=\sum_Z p(X|Z)p(Z) $$</li></ul>]]></content>
      
      
      <categories>
          
          <category> STUDY </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CV </tag>
            
            <tag> BASIC_KNOWLEDGE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>optimal_algorithms</title>
      <link href="/2022/09/13/optimal-algorithms/"/>
      <url>/2022/09/13/optimal-algorithms/</url>
      
        <content type="html"><![CDATA[<h1 id="PSO-Particle-Swarm-Optimization"><a href="#PSO-Particle-Swarm-Optimization" class="headerlink" title="PSO(Particle Swarm Optimization)"></a><font color="blue"><strong>PSO(Particle Swarm Optimization)</strong></font></h1><ul><li><p>Features:</p><ol><li>search global solution by iteration as anneal simulation</li></ol></li><li><p>PSO Standard format<br>$$ v_i = v_i + c_1 <em>rand() </em> (pbest_i - x_i) + c_2 <em> rand() </em> (gbest_i - x_i)     $$<br>$$ x_i = x_i + v_i $$<br>$$ v_i = w<em>v_i + c_1</em>rand()<em>(pbest_i-x_i)+c_2</em>rand()*(gbest_i-x_i)    $$<br>动态w可在PSO搜索过程中线性变化，w越大，全局寻优能力强；越小，局部寻优能力强。</p></li><li><p>LDW(Linearly Decreasing Weight)<br>$$ w^{(t)}=(w_{ini} - w_{end})*(G_k-g) / G_k +w_{end}   $$<br>其中$G_k$为最大迭代次数，$w_{ini}$为初始惯性权值，$w_{end}$为迭代至最大进化代数式的惯性权值</p></li><li><p>PSO Standard Flow</p><ol><li>初始化一群微粒(N);</li><li>评价每个微粒的适应度;</li><li>对每个微粒，将其适应值与经过的最好位置pbest作比较;</li><li>对每个微粒，将其适应值与其经过的最好位置gbest作比较;</li><li>根据公式调整微粒速度和位置；</li></ol></li></ul><h1 id="SA-Simulate-Annealing"><a href="#SA-Simulate-Annealing" class="headerlink" title="SA(Simulate Annealing)"></a><font color="blue"><strong>SA(Simulate Annealing)</strong></font></h1><pre class="line-numbers language-PYTHON"><code class="language-PYTHON">from numpy import asarrayfrom numpy import expfrom numpy.random import randnfrom numpy.random import randfrom numpy.random import seedfrom matplotlib import pyplot as pltdef objective(x):    return x[0]**2.0def simulated_annealing(objective, bounds, n_iterations, step_size, temp):    # generate an initial point    best = bounds[:, 0] + randn(len(bounds)) * (bounds[:, 1] - bounds[:, 0])    # evaluate the initial point    best_eval = objective(best)    # current working solution    curr, curr_eval = best, best_eval    scores = list()    for i in range(n_iterations):        # take a step        candidate = curr + randn(len(bounds)) * step_size        # evaluate candidate point        candidate_eval = objective(candidate)        # check for new best solution        if candidate_eval < best_eval:            best, best_eval = candidate, candidate_eval            scores.append(best_eval)            print('>%d f(%s)=%.5f' % (i, best, best_eval))        diff = candidate_eval - curr_eval        # calculate temperature for each epoch        t = temp / float(i +1)        # calculate metropolis acceptance criterion        metropolis = exp(-diff / t)        if diff <0 or rand() < metropolis:            curr, curr_eval = candidate, candidate_eval    return [best, best_eval, scores]seed(1)# define range for inputbounds = asarray([[-5.0, 5.0]])n_iterations = 100step_size = 0.1temp = 10best, score, scores = simulated_annealing(objective, bounds, n_iterations, step_size, temp)print("done!")print("f(%s)=%f" % (best, score))plt.plot(scores, ',-')plt.xlabel('Improvement Number')plt.ylabel('Evaluation f(x)')plt.show()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multiprocessing</title>
      <link href="/2022/09/13/multiprocessing/"/>
      <url>/2022/09/13/multiprocessing/</url>
      
        <content type="html"><![CDATA[<h2 id="DistributedDataParallel"><a href="#DistributedDataParallel" class="headerlink" title="DistributedDataParallel"></a>DistributedDataParallel</h2><pre class="line-numbers language-PYTHON"><code class="language-PYTHON">    import torch    import torch.distributed as dist    import torch.multiprocessing as mp    def parse_args():        # Code Block        return args    def main():        args = parse_args()        args.nprocs = torch.cuda.device_count()        mp.spawn(main_worker, nprocs=args.nprocs, args=(args.nprocs, args))    def main_worker(local_rank, nprocs, args):        args.local_rank = local_rank        if args.seed is not None:            random.seed(args.seed)            torch.manual_seed(aegs.seed)            cudnn.deterministic = True        dist.init_process_group(backend='nccl',                                init_method='tcp://127.0.0.1:23456',                                world_size=args.nprocs,                                rank=local_rank)        # create model        torch.cuda.set_device(local_rank)        model.cuda(local_rank)        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])        criterion = nn.CrossEntropyLoss().cuda(local_rank)        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)        train_loader = torch.utils.data.DataLoader(train_dataset,                                                    batch_size=args.batch_size,                                                    num_workers=2,                                                    pin_memory=True,                                                    sampler=train_sampler)        for epoch in range(args.start_epoch, args.epoch):            train_sampler.set_epoch(epoch)            adjust_learning_rate(optimizer, epoch, args)            train(train_loader, model, criterion, optimizer, epoch, local_rank, args)            if args.local_rank == 0:                save_checkpoint({                    'epoch':epoch+1,                    'arch':args.arch,                    'state_dict':model.module.state_dict(),                }, is_best)    def train(*args, **kwargs):        model.train()        for i, (images, target) in enumerate(train_loader):            images = images.cuda(local_rank, non_blocking=True)            # when func is not the main_process(rank!=0,-1), context_manegementor will barrier processor util all processors reach barrier            torch.distributed.barrier()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><a href="https://github.com/tczhangchi/pytorch-distributed/" target="_blank" rel="noopener">reference</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> MultiProcessing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++_Basic</title>
      <link href="/2022/08/25/c-basic/"/>
      <url>/2022/08/25/c-basic/</url>
      
        <content type="html"><![CDATA[<h1 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h1><p>##<br>definition = declaration + initialisation</p><pre class="line-numbers language-C++"><code class="language-C++">#include <iostream>using namespace std:int main(){    char a123 = 'a':    cout << a123 << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Basic-knowledge"><a href="#Basic-knowledge" class="headerlink" title="Basic_knowledge"></a>Basic_knowledge</h3><ol><li><p><strong>Static Variables</strong> are similarly declared as <strong>Instance Variables</strong>, but using the <em>static keyword</em> within a class outside any method constructor or block</p><ul><li>Changes maded in an <strong>instance variable</strong> using one object will <strong>not reflected</strong> in other objects, while in an <strong>instance variable</strong> things are different.</li><li><strong>Instance variables</strong> can be accessed by <strong>object references</strong>, while <strong>static variables</strong> via <strong>class name</strong></li><li>Each object have its <strong>own copy</strong> of <strong>instance variable</strong> whereas we can only have <strong>one copy</strong> of a <strong>static variable</strong> per class.</li></ul></li><li><p>Loops:</p><ul><li>for</li><li>while</li><li>do while<pre class="line-numbers language-C++"><code class="language-C++">      do      {          //statement      } while (test_expression);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>If-else: the variables created in C/C++ will be local to that block only.</p><pre class="line-numbers language-C++"><code class="language-C++"> #include <iostream> using namespace std; void printNumbers() {     int n = 1; label:     cout << n << " ";     n++;     if (n <= 10)         goto label; } int main() {     printNumbers();     return 0; }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Redirect IO: istream ostream iostream<br><code>freopen (&quot;text_file.txt&quot;, &quot;w&quot;, stdout)</code></p><pre class="line-numbers language-C++"><code class="language-C++">#include <fstream>#include <iostream>#include <string><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><p>using namespace std;</p><p>int main()<br>{<br>    fstream file;<br>    file.open(“cout.txt”, ios::out);<br>    string line;</p><pre><code>// backup streambuffersstreambuf* stream_buffer_cout = cout.rdbuf();streambuf* stream_buffer_cin = cin.rdbuf();// get streambuffer of filestreambuf* stream_buffer_file = file.rdbuf();// redirect cout to filecout.rdbuf(stream_buffer_file);cout &lt;&lt; &quot;This line written to file&quot; &lt;&lt; endl;// redirect cout back to screencout.rdbuf(stream_buffer_cout);cout &lt;&lt; &quot;This line is written to screen&quot; &lt;&lt; endl;file.close();return 0;</code></pre><pre><code>Also the above can be condensed as follows:```C++auto cont_buf = cout.rdbuf(file.rdbuf())// sets couts streambuffer and returns the oldstreambuffer back to cont_buf</code></pre><ul><li>Standard IO format<pre class="line-numbers language-C++"><code class="language-C++">#include <iostream>using namespace std;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><p>int main()<br>{<br>    int age;</p><pre><code>cout &lt;&lt; &quot;Enter your age:&quot;;cin &gt;&gt; age;cout &lt;&lt; &quot;\n Your age is: &quot; &lt;&lt; age;return 0;</code></pre><p>}</p><pre><code>*cerr* is un-buffered standard error stream which doesn&#39;t get stored in file.*clog* is different from *cerr* as it stores the erroe in the buffer.+ Clear input buffer```C#include&lt;stdio.h&gt;int main(){    char str[80], ch;    // scan input from user    scanf(&quot;%s&quot;, str);    // flushes the standard input &amp; clears the input buffer    while ((getchar()) != &#39;\n&#39;);    // scan character from user    ch = getchar();    printf(&quot;%s\n&quot;, str);    printf(&quot;%c&quot;, ch);    return 0;}</code></pre><pre class="line-numbers language-C++"><code class="language-C++">#include<iostream>#include<ios>#include<limits>using namespace std;int main(){    int a;    char str[80];    cin >> a;    // type 1    cin.ignore(numeric_limits<streamsize>::max(), '\n');    // type 2: discards the input buffer and initial white spaces of string    cin >> ws    cin.getline(str, 80);    cout << a << endl;    cout << str << endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>Operators</p><table><thead><tr><th align="left">operator</th><th align="left">function</th></tr></thead><tbody><tr><td align="left">&amp;</td><td align="left">bitwise AND</td></tr></tbody></table></li><li><p>Dynamic memory: remain until being deallocated by program</p><pre class="line-numbers language-C"><code class="language-C">malloc()calloc()free()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-C++"><code class="language-C++">int *p = new(nothrow) int;if (!p)  cout << "allocation of memory failed\n";delete p;// release block memory pointed by point-variabledelete[] p;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Arrays</p><pre class="line-numbers language-C++"><code class="language-C++">// array declaration by specifying the sizeint arr1[10];int n = 10;int arr2[n];// array declaration by initializing elementsint arr[] = {10, 20, 30, 40};// array declaration by specifying the size and initializing elementsint arr[6] = {10, 20, 30, 40};// dynamic allocationint** x = new int*[3];for (int i=0;i<3;i++){  x[i] = new int[4];  for (int j=0;j<4;j++)  {      cin >> x[i][j];  }}// use template and reference to find size of any type arraytemplate <typename T, size_t, n>void findSize(T (&arr)[n]){  cout << sizeof(T) * n << endl;}int main(){  int a[10];  cout << sizeof(a) << " ";  findSize(a);  return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>String</p></li></ul><p><em>push_back(str)</em>: input a character at the end of the string<br><em>pop_back(str)</em>: delete the last character from the string</p><pre class="line-numbers language-C++"><code class="language-C++">#include <iostream>#include <string>using namespace std;int main(){    string str = "helloword";    std::string::iterator it;    std::string::reverse_iterator it1;    cout<< "The string using forward iterators is : ";    for (it=str.begin();it!=str.end();it++)        cout<< *it;    cout << endl;    cout<< "The reverse string using reverse iterators is ":" ";    for (it1=str.rbegin();it1!=str.rend();it1++)        cout <<*it1;    cout<<endl;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>Array<pre class="line-numbers language-C++"><code class="language-C++">#include <iostream>#include <stdio.h>int main(){  const char* colour[4] = {"Blue", "Red","Orange","Yellow"};  for(int i=0;i<4;i++)      std::cout << colour[i]<< "\n";  return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h3 id="Search-amp-Insert"><a href="#Search-amp-Insert" class="headerlink" title="Search &amp; Insert"></a>Search &amp; Insert</h3><pre class="line-numbers language-C++"><code class="language-C++">#include <bits/stdc++.h>using namespace std;const int ALPHABET_SIZE = 26;// trie nodestruct TrieNode{    struct TrieNode *children[ALPHABET_SIZE];    bool isEndOfWord;};// returns new trie nodestruct TrieNode *getNode(void){    struct TrieNode *pNode = new TrieNode;    pNode->isEndOfWord = false;    for(int i=0; i<ALPHABET_SIZE; i++)        pNode->children[i] = Null;    return pNode;}// search && insertvoid insert(struct TrieNode *root, string key){    struct TrieNode *pCrawl = root;    for(int i=0;i<key.length();i++)    {        int index = key[i] - 'a';        if (!pCrawl->children[index])            pCrawl->children[index] = getNode();        pCrawl = pCrawl->children[index];    }    // mark last node as leaf    pCrawl->isEndOfWord = true;}// generate resultbool search(struct TrieNode *root, string key){    struct TrieNode *pCrawl = root;    for(int i=0;i<key.length();i++)    {        int index = key[i] - 'a';        if(!pCrawl->children[index])            return false;        pCrawl = pCrawl->children[index];    }    return (pCrawl->isEndOfWord);}// driverint main(){    // input keys    string keys[] = {"the", "a", "there", "answer", "any", "by", "bye", "their"};    int n = sizeof(keys)/sizeof(keys[0]);    struct TrieNode *root = getNode();    // construct trie    for(int i=0;i<n;i++)        insert(root, keys[i]);    // search    search(root, "the")? cout << "Yes\n" : cout << "No\n";    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Binary-Indexed-Tree"><a href="#Binary-Indexed-Tree" class="headerlink" title="Binary Indexed Tree"></a>Binary Indexed Tree</h3><pre class="line-numbers language-C++"><code class="language-C++">#include <iostream>using namespace std;int getSum(int BITree[], int index){    int sum = 0;    index = index + 1;    while (index>0)    {        sum += BITree[index];        index -= index & (-index);    }    return sum;}void updateBIT(int BITree[], int n, int index, int val){    index = index + 1;    while (index<=n)    {        BITree[index] += val;        index += index & (-index);    }}int *constructBITree(int arr[], int n){    int *BITree = new int[n+1];    for (int i=1;i<=n;i++)        BITree[i] = 0;    for (int i=0;i<n;i++)        updateBIT(BITree, n, i, arr[i]);    return BITree;}int main(){    int freq[] = {2, 1, 1, 3, 2, 3, 4, 5, 6, 7, 8, 9};    int n = sizeof(freq)/sizeof(freq[0]);    int *BITree = constructBITree(freq, n);    cout << "Sum of elements in arr[0..5] is " << getSum(BITree, 5);    freq[3] += 6;    updateBIT(BITree, n, 3, 6);    cout << "Sum of elements in arr[0..5] is " << getSum(BITree, 5);    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Segment-tree"><a href="#Segment-tree" class="headerlink" title="Segment tree"></a>Segment tree</h3><p>```C++</p><p>#include &lt;bits/stdc++.h&gt;<br>using namespace std;</p><p>int minVal(int x, int y)<br>{<br>    return (x &lt; y)? x: y;<br>}</p><p>int getMid(int s, int e)<br>{<br>    return s + (e - s) / 2;<br>}<br>// st: pointer to segment tree;<br>// index: index of current node;<br>// ss &amp; se: index of segment represented by current node;<br>// qs &amp; qe: index of query range;<br>int RMQUtil(int *st, int ss, int se, int qs, int qe, int index)<br>{<br>    if (qs &lt;= ss &amp;&amp; qe &gt;= se)<br>        return st[index];</p><pre><code>if (se &lt; qs || ss &gt; qe)    return InT_MAX;int mid = getMid(ss, se);return minVal(RMQUtil(st, ss, mid, qs, qe, 2 * index + 1), RMQUtil(st, mid+1, se, qs, qe, 2 * index + 2));</code></pre><p>}</p><p>int RMQ(int *st, int n, int qs, int qe)<br>{<br>    if (qs &lt; 0 || qe &gt; n-1 || qs &gt; qe)<br>    {<br>        cout &lt;&lt; “Invalid Input”;<br>        return -1;<br>    }<br>    return RMQUtil(st, 0, n-1, qs, qe, 0);<br>}</p><p>int constructSTUtil(int arr[], int ss, int se, int <em>st, int si)<br>{<br>    if (ss == se)<br>    {<br>        st[si] = arr[ss];<br>        return arr[ss];<br>    }<br>    int mid = getMid(ss, se);<br>    st[si] = minVal(constructSTUtil(arr, ss, mid, st, si </em> 2 + 1), constructSTUtil(arr, mid + 1, se, st, si * 2 + 2));<br>    return st[si];<br>}</p><p>inr <em>constructST(int arr[], int n)<br>{<br>    int x = (int)(ceil(log2(n)));<br>    int max_size = 2 </em> (int)pow(2, x) -1;<br>    int *st = new int[max_size];<br>    constructSTUtil(arr, 0, n-1, st, 0);<br>    return st;<br>}</p><p>int main()<br>{<br>    int arr[] = {1, 3, 2, 7, 9, 11};<br>    int n = sizeof(arr)/sizeof(arr[0]);<br>    int *st = constructST(arr, n);<br>    int qs = 1;<br>    int qe = 5;<br>    cout &lt;&lt; “Minimum of values in range [“ &lt;&lt; qs &lt;&lt; “, “ &lt;&lt; qe &lt;&lt; “] “ &lt;&lt; “is =” &lt;&lt; RMQ(st, n, qs, qe) &lt;&lt; endl;</p><pre><code>return 0;</code></pre><p>}</p>]]></content>
      
      
      <categories>
          
          <category> Teconology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> Basic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSS_basic</title>
      <link href="/2022/08/23/css-basic/"/>
      <url>/2022/08/23/css-basic/</url>
      
        <content type="html"><![CDATA[<h1 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h1><h2 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h2><table><thead><tr><th align="left">selector</th><th align="left">example</th><th align="left">description</th></tr></thead><tbody><tr><td align="left">.class</td><td align="left">.into</td><td align="left">select all class=”intro” elements</td></tr><tr><td align="left">#id</td><td align="left">#firstname</td><td align="left">select all id=”firstname” elements</td></tr><tr><td align="left">*</td><td align="left">*</td><td align="left">select all elements</td></tr><tr><td align="left">element, element</td><td align="left">div, p</td><td align="left">select all div &amp; p elements</td></tr><tr><td align="left">element element</td><td align="left">div p</td><td align="left">select all p within div</td></tr><tr><td align="left">element&gt;element</td><td align="left">div&gt;p</td><td align="left">select p whose parent level is div</td></tr><tr><td align="left">element+element</td><td align="left">div+p</td><td align="left">select first p after div</td></tr><tr><td align="left">[attribute]</td><td align="left">[target]</td><td align="left">select elements with target attribute</td></tr><tr><td align="left">[attribute=value]</td><td align="left">[target=-blank]</td><td align="left">select elements with target=”-blank”</td></tr><tr><td align="left">[attribute~=value]</td><td align="left">[title~=flower]</td><td align="left">select elements whose title attribute contains “flower”</td></tr><tr><td align="left">[attribute</td><td align="left">=language]</td><td align="left">[lang</td></tr><tr><td align="left">:link</td><td align="left">a:link</td><td align="left">select link unvisited</td></tr><tr><td align="left">:visited</td><td align="left">a:visited</td><td align="left">select link visited</td></tr><tr><td align="left">:active</td><td align="left">a:active</td><td align="left">select active link</td></tr><tr><td align="left">:hover</td><td align="left">a:hover</td><td align="left">select when mouse hover link</td></tr><tr><td align="left">:focus</td><td align="left">input:focus</td><td align="left">select input element with focus</td></tr><tr><td align="left">:before</td><td align="left">p:before</td><td align="left">insert before p element</td></tr><tr><td align="left">:after</td><td align="left">p:after</td><td align="left">insert after p element</td></tr><tr><td align="left">element1~element2</td><td align="left">p~ul</td><td align="left">select all ul element after p</td></tr><tr><td align="left">[attribute^=value]</td><td align="left">a[src^=”https”]</td><td align="left">select element whose src attribute starts with “https”</td></tr><tr><td align="left">[attribute$=value]</td><td align="left">a[src$=”.pdf”]</td><td align="left">select element whose src attribute ends with “.pdf”</td></tr><tr><td align="left">[attribute*=value]</td><td align="left">a[src*=”runoob”]</td><td align="left">select element whose src attribute contains “runoob”</td></tr><tr><td align="left">:root</td><td align="left">:root</td><td align="left">select root element of document</td></tr><tr><td align="left">:empty</td><td align="left">p:empty</td><td align="left">select p element without siblings</td></tr></tbody></table><h2 id="HTML"><a href="#HTML" class="headerlink" title="HTML"></a>HTML</h2><pre class="line-numbers language-HTML"><code class="language-HTML">    <!--back to top-->    <a href="#"></a>    <!--refresh page-->    <a href=""></a><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="JQuery"><a href="#JQuery" class="headerlink" title="JQuery"></a>JQuery</h2><ul><li>切换元素的类<pre class="line-numbers language-HTML"><code class="language-HTML">  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>  <script>  $(document).ready(function(){      $(".nav-item").hover(function(){      $(this).toggleClass("m-nav-show");      });  });  </script><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CSS </tag>
            
            <tag> Front_End </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scientific work</title>
      <link href="/2022/08/23/scientific-work/"/>
      <url>/2022/08/23/scientific-work/</url>
      
        <content type="html"><![CDATA[<h2 id="22-08-23"><a href="#22-08-23" class="headerlink" title="22/08/23"></a>22/08/23</h2><h3 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h3><ol><li>While training model without style_transfer, the final model seems to be hard to handle images without much texture features.</li><li>the low SNR image &amp;&amp; obstacles like stars or keypoint_like &amp;&amp; small object</li><li>exists problems like symmetric point mismatches</li></ol><h2 id="22-08-25"><a href="#22-08-25" class="headerlink" title="22/08/25"></a>22/08/25</h2><h3 id="Note-1"><a href="#Note-1" class="headerlink" title="Note:"></a>Note:</h3><ol><li>some keypoints unchecked, some keypoints miracly checked but with relative low response value</li><li>for wrong situations:<ul><li>seems like inplane features are learned while the intro-plane features are not seperate properly.</li><li>dark situation</li></ul></li><li>for true situations:<ul><li>with EPNP algorithm, the other wrong keypoints can be filtered for most cases. (happens with strong keypoint features)</li></ul></li></ol><h3 id="Current-dilemma"><a href="#Current-dilemma" class="headerlink" title="Current dilemma:"></a>Current dilemma:</h3><ol><li>training stage final touch around 0.7, hard to improve;</li><li>testing stage has difficult in handling textureless &amp; dark background situation</li></ol><h3 id="Currnet-summary"><a href="#Currnet-summary" class="headerlink" title="Currnet summary:"></a>Currnet summary:</h3><ol><li>training without style_transfer seems to be helpful for inplane keypoint relations.<br> By introducing the texture feature, the model will give out more proposals than before.</li></ol><h3 id="Current-try"><a href="#Current-try" class="headerlink" title="Current try:"></a>Current try:</h3><ol><li>improve keypoint punish factor to 2.</li></ol><h2 id="22-08-30"><a href="#22-08-30" class="headerlink" title="22/08/30"></a>22/08/30</h2><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ol><li>method need breakthrough. Try to extend the model length for better knowledge learning and expressing.</li><li>other context mixer methods. CCM | PSA</li></ol><h2 id="22-08-31"><a href="#22-08-31" class="headerlink" title="22/08/31"></a>22/08/31</h2><h3 id="Log"><a href="#Log" class="headerlink" title="Log"></a>Log</h3><ol><li>model need basic train before applying DA;</li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Log </tag>
            
            <tag> Graduate_work </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>selenium</title>
      <link href="/2022/08/18/selenium/"/>
      <url>/2022/08/18/selenium/</url>
      
        <content type="html"><![CDATA[<h1 id="Selenium-spider"><a href="#Selenium-spider" class="headerlink" title="Selenium spider"></a>Selenium spider</h1><h2 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h2><pre class="line-numbers language-python"><code class="language-python">    pip install selenium    <span class="token comment" spellcheck="true"># download the browser driver ![chrome](https://chromedriver.storage.googleapis.com/index.html?path=104.0.5112.79/)</span>    <span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver    driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Element-hunter"><a href="#Element-hunter" class="headerlink" title="Element hunter"></a>Element hunter</h2><pre class="line-numbers language-python"><code class="language-python">    find_element_by_id<span class="token punctuation">(</span><span class="token punctuation">)</span>    find_element_by_name<span class="token punctuation">(</span><span class="token punctuation">)</span>    find_element_by_class_name<span class="token punctuation">(</span><span class="token punctuation">)</span>    find_element_by_tag_name<span class="token punctuation">(</span><span class="token punctuation">)</span>    fing_element_by_link_text<span class="token punctuation">(</span><span class="token punctuation">)</span>    find_element_by_partial_link_text<span class="token punctuation">(</span><span class="token punctuation">)</span>    find_element_by_xpath<span class="token punctuation">(</span><span class="token punctuation">)</span>    find_element_by_css_selector<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Browser-operation"><a href="#Browser-operation" class="headerlink" title="Browser operation"></a>Browser operation</h2><pre class="line-numbers language-python"><code class="language-python">    driver<span class="token punctuation">.</span>set_window_size<span class="token punctuation">(</span><span class="token number">480</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>back<span class="token punctuation">(</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>forward<span class="token punctuation">(</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>refresh<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">    driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"kw"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># clear the text</span>    driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"kw"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">"selenium"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># simulate the input</span>    driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"su"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>click<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># click the element</span>    search_text <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">'kw'</span><span class="token punctuation">)</span>    search_text<span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'selenium'</span><span class="token punctuation">)</span>    search_text<span class="token punctuation">.</span>submit<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Mouse-operation"><a href="#Mouse-operation" class="headerlink" title="Mouse operation"></a>Mouse operation</h2><ul><li>perform(): execute the actions stored in ActionChains</li><li>context_click(): right click</li><li>double_click(): double clicks</li><li>drag_and_drop(): drag element</li><li>move_to_element(): suspend above element</li></ul><pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver    <span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>common<span class="token punctuation">.</span>action_chains <span class="token keyword">import</span> ActionChains    driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'https://www.baidu.cn'</span><span class="token punctuation">)</span>    above <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_partial_link_text<span class="token punctuation">(</span><span class="token string">"设置"</span><span class="token punctuation">)</span>    ActionChains<span class="token punctuation">(</span>driver<span class="token punctuation">)</span><span class="token punctuation">.</span>move_to_element<span class="token punctuation">(</span>above<span class="token punctuation">)</span><span class="token punctuation">.</span>perform<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Keyboard-operation"><a href="#Keyboard-operation" class="headerlink" title="Keyboard operation"></a>Keyboard operation</h2><ul><li></li><li>send_keys()： <em>Keys.BACK_SPACE</em> <em>Keys.CONTROL, ‘a’</em> <em>Keys.F1</em></li></ul><pre class="line-numbers language-python"><code class="language-python">    driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"kw"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">"selenium"</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"kw"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span>Keys<span class="token punctuation">.</span>BACK_SPACE<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">    title <span class="token operator">=</span> driver<span class="token punctuation">.</span>title    now_url <span class="token operator">=</span> driver<span class="token punctuation">.</span>current_url    user <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_class_name<span class="token punctuation">(</span><span class="token string">'nums'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text    <span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver    <span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>common<span class="token punctuation">.</span>by <span class="token keyword">import</span> By    <span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>support<span class="token punctuation">.</span>ui <span class="token keyword">import</span> WebDriverWait    <span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>support <span class="token keyword">import</span> expected_conditions <span class="token keyword">as</span> EC    driver<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"https://www.baidu.com"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># WebDriverWait(driver, timeout, poll_frequency=0.5, ignored_exceptions=None)</span>    element <span class="token operator">=</span> WebDriverWait<span class="token punctuation">(</span>driver<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>until<span class="token punctuation">(</span>EC<span class="token punctuation">.</span>presence_of_element_located<span class="token punctuation">(</span><span class="token punctuation">(</span>By<span class="token punctuation">.</span>ID<span class="token punctuation">,</span> <span class="token string">"kw"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    element<span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">"selenium"</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>implicitly_wait<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>    drivet<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://somedomain/url_that_delays_loading"</span><span class="token punctuation">)</span>    myDynamicElement <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"myDynamicElement"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># switch between windows</span>    xf <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_xpath<span class="token punctuation">(</span><span class="token string">'//*[@id="x-URS-iframe"'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># choose from select box</span>    <span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>support<span class="token punctuation">.</span>select <span class="token keyword">import</span> Select    Select<span class="token punctuation">(</span>xf<span class="token punctuation">)</span><span class="token punctuation">.</span>select_by_value<span class="token punctuation">(</span><span class="token string">'50'</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>switch_to_frame<span class="token punctuation">(</span>xf<span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>switch_to_default_content<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Alert-frame"><a href="#Alert-frame" class="headerlink" title="Alert frame"></a>Alert frame</h2><p><code>alert = driver.switch_to_alert()</code></p><ul><li>attribute: text | accept | dismiss | send_keys()</li></ul><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><pre class="line-numbers language-python"><code class="language-python">    driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"file"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'D:\\upload_file.txt'</span><span class="token punctuation">)</span>    driver<span class="token punctuation">.</span>get_screenshot_as_file<span class="token punctuation">(</span><span class="token string">"D:\\baidu_img.jpg"</span><span class="token punctuation">)</span>    js <span class="token operator">=</span> <span class="token string">"window.scrollTo(100, 450);"</span>    driver<span class="token punctuation">.</span>execute_script<span class="token punctuation">(</span>js<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Scrapy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN_articles</title>
      <link href="/2022/08/18/gan-articles/"/>
      <url>/2022/08/18/gan-articles/</url>
      
        <content type="html"><![CDATA[<h2 id="GAN-Articles"><a href="#GAN-Articles" class="headerlink" title="GAN_Articles"></a>GAN_Articles</h2><h3 id="ON-Convergence-and-stability-of-GANs-2017"><a href="#ON-Convergence-and-stability-of-GANs-2017" class="headerlink" title="ON Convergence and stability of GANs(2017)"></a>ON Convergence and stability of GANs(2017)</h3><p><strong><em>Deep Regret Analytic Generative Adversarial Networks</em></strong></p><ol><li>regret minimization is the more appropriate way to think about GAN training dynamics</li><li>previous view off mode collapse and instability is that it results from <strong>attempting to minimize a strong divergence</strong> during training, authors argued to be not ture</li><li>mode collapse situations are often accompanied by sharp gradients of the discriminator function around some real data points</li><li>view alternating gradient updates procedures as regret minimization</li><li>prove the asymptotic convergence of GAN training in the non-parametric limit without requirements of discriminator to be optimal at each step</li><li>AGD can converge to a potentially bad local equilibrium in non-convex games and hypothesize this to be responsible for mode collapse</li></ol>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> technology books </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pose_Estimation</title>
      <link href="/2022/08/18/pose-estimation/"/>
      <url>/2022/08/18/pose-estimation/</url>
      
        <content type="html"><![CDATA[<p><strong>0818</strong></p><ol><li><p>strengthen the difference between keypoints<br> The problem why sometimes the model’s output mismatched is due to the weak feature learned for each keypoints.</p><p> And it comes to the dillima. We seem to enhance the feature difference by adding the texture which is indeed the thing we try to avoid by style transfer</p></li><li><p>strange observation<br> The Grammar correction in chrome limit the utterance comment to be one character input:D</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pose_Estimation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tutorial for online training</title>
      <link href="/2022/08/06/tutorial-for-online-training/"/>
      <url>/2022/08/06/tutorial-for-online-training/</url>
      
        <content type="html"><![CDATA[<h1 id="GPU-Online-Training-Tutorial"><a href="#GPU-Online-Training-Tutorial" class="headerlink" title="GPU Online Training Tutorial"></a>GPU Online Training Tutorial</h1><h2 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h2><ol><li>upload dataset and scripts by oss<pre class="line-numbers language-python"><code class="language-python"> oss login cp G<span class="token punctuation">:</span><span class="token operator">//</span>Datasets<span class="token operator">/</span>speedplus<span class="token punctuation">.</span>zip oss<span class="token punctuation">:</span><span class="token operator">//</span>datasets<span class="token operator">/</span> cp G<span class="token punctuation">:</span><span class="token operator">//</span>CodeSpace<span class="token operator">/</span>KE<span class="token punctuation">.</span>zip oss<span class="token punctuation">:</span><span class="token operator">//</span>datasets<span class="token operator">/</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>upzip datasets &amp; project<pre class="line-numbers language-python"><code class="language-python"> oss cp oss<span class="token punctuation">:</span><span class="token operator">//</span>datasets<span class="token operator">/</span><span class="token punctuation">.</span><span class="token operator">*</span>zip <span class="token operator">/</span>hy<span class="token operator">-</span>tmp<span class="token operator">/</span> ls <span class="token operator">/</span>hy<span class="token operator">-</span>tmp<span class="token operator">/</span> unzip <span class="token operator">-</span>d <span class="token operator">/</span>home<span class="token operator">/</span> <span class="token operator">/</span>hy<span class="token operator">-</span>tmp<span class="token operator">/</span><span class="token punctuation">.</span><span class="token operator">*</span>zip <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li>install necessary dependancies <pre class="line-numbers language-python"><code class="language-python"> pip install <span class="token operator">-</span>r requirements<span class="token punctuation">.</span>txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><pre class="line-numbers language-python"><code class="language-python"> bash trainf1<span class="token punctuation">.</span>sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPU Training </tag>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DL_Model_Training</title>
      <link href="/2022/08/05/dl-model-training/"/>
      <url>/2022/08/05/dl-model-training/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h1><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="load-model"><a href="#load-model" class="headerlink" title="load model"></a>load model</h3><p><strong><code>load_state_dict= net.state_dict</code></strong></p><pre class="line-numbers language-python"><code class="language-python">    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'net'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    model_dict <span class="token operator">=</span> net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>    pretrained_dict <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> checkpoint<span class="token punctuation">[</span><span class="token string">'net'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> k <span class="token keyword">in</span> model_dict<span class="token punctuation">}</span>    model_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>pretrained_dict<span class="token punctuation">)</span>    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="freeze-model"><a href="#freeze-model" class="headerlink" title="freeze model"></a>freeze model</h3><pre class="line-numbers language-python"><code class="language-python">    net<span class="token punctuation">.</span>fc2<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>    net<span class="token punctuation">.</span>fc2<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Aadm<span class="token punctuation">(</span>filter<span class="token punctuation">(</span><span class="token keyword">lambda</span> p<span class="token punctuation">:</span> p<span class="token punctuation">.</span>requires_grad<span class="token punctuation">,</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># unfreeze the fc2 layer for extra tuning if needed</span>    net<span class="token punctuation">.</span>fc2<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>    net<span class="token punctuation">.</span>fc2<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span>    optimizer<span class="token punctuation">.</span>add_param_group<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span>net<span class="token punctuation">.</span>fc2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="load-optimizer"><a href="#load-optimizer" class="headerlink" title="load optimizer"></a>load optimizer</h3><pre class="line-numbers language-python"><code class="language-python">    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'initial_lr'</span><span class="token punctuation">:</span><span class="token number">0.001</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> lr <span class="token operator">=</span> <span class="token number">2.0e-3</span><span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">.</span><span class="token number">0.999</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Model Training </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python_Skills_Plus</title>
      <link href="/2022/07/26/python-skills-plus/"/>
      <url>/2022/07/26/python-skills-plus/</url>
      
        <content type="html"><![CDATA[<h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ul><li>zip  </li></ul><pre class="line-numbers language-python"><code class="language-python">    a<span class="token punctuation">,</span> b <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>    zipped <span class="token operator">=</span> zip<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>    list<span class="token punctuation">(</span>zipped<span class="token punctuation">)</span>    a1<span class="token punctuation">,</span> a2 <span class="token operator">=</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>zip<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span>    list<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>    <span class="token keyword">from</span> zipfile <span class="token keyword">import</span> ZipFile    <span class="token keyword">import</span> os    <span class="token keyword">from</span> os<span class="token punctuation">.</span>path <span class="token keyword">import</span> basename    <span class="token keyword">with</span> ZipFile<span class="token punctuation">(</span><span class="token string">'sampleDir.zip'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> zipObj<span class="token punctuation">:</span>        <span class="token keyword">for</span> folderName<span class="token punctuation">,</span> subfolders<span class="token punctuation">,</span> filenames <span class="token keyword">in</span> os<span class="token punctuation">.</span>walk<span class="token punctuation">(</span>dirName<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> filename <span class="token keyword">in</span> filenames<span class="token punctuation">:</span>                filePath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>folderName<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>                zipObj<span class="token punctuation">.</span>write<span class="token punctuation">(</span>filePath<span class="token punctuation">,</span> basename<span class="token punctuation">(</span>filePath<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>Keywords</p><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">try</span><span class="token punctuation">:</span>  <span class="token keyword">except</span> ZeroDivisionError<span class="token punctuation">:</span>  <span class="token keyword">finally</span><span class="token punctuation">:</span>  <span class="token keyword">global</span> variable  non<span class="token operator">-</span>local variable<span class="token punctuation">:</span> rather than <span class="token keyword">global</span><span class="token punctuation">,</span> declares a variable to point to variable of outside enclosing function<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>print  </p></li><li><pre class="line-numbers language-python"><code class="language-python">  <span class="token comment" spellcheck="true"># without extraline</span>  l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token operator">*</span>l<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>l<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># format output</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Total number is : %3d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"{'Tom'} and {'Jerry'}"</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Apple: {a:5d}, Orange: {o:8.2f}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>a<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span> o<span class="token operator">=</span><span class="token number">21.23</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  data <span class="token operator">=</span> dict<span class="token punctuation">(</span>fun<span class="token operator">=</span><span class="token string">"a"</span><span class="token punctuation">,</span> adj<span class="token operator">=</span><span class="token string">"b"</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{a} and {b}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token operator">**</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>str<span class="token punctuation">.</span>center<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token string">'#'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>str<span class="token punctuation">.</span>ljust<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token string">'#'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>operator  </p></li></ul><pre class="line-numbers language-python"><code class="language-python">    min <span class="token operator">=</span> a <span class="token operator">&lt;</span> b <span class="token operator">and</span> a <span class="token operator">or</span> b    <span class="token comment" spellcheck="true"># overload</span>    <span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>a<span class="token operator">=</span>a        <span class="token keyword">def</span> <span class="token function">__add__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> o<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>a <span class="token operator">+</span> o<span class="token punctuation">.</span>a    <span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> A<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># any &amp; all</span>    all<span class="token punctuation">(</span>empty iterable<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># true</span>    any<span class="token punctuation">(</span>empty iterable<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># false</span>    slice<span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> step<span class="token punctuation">)</span>    setitem<span class="token punctuation">(</span>object<span class="token punctuation">,</span> position<span class="token punctuation">,</span> value<span class="token punctuation">)</span>    delitem<span class="token punctuation">(</span>object<span class="token punctuation">,</span> position<span class="token punctuation">)</span>    getitem<span class="token punctuation">(</span>object<span class="token punctuation">,</span> position<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># == &amp; is</span>     <span class="token string">"is"</span> check memory location<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>String  </li></ul><pre class="line-numbers language-python"><code class="language-python">    string <span class="token operator">=</span> r<span class="token string">'this is \110\145'</span> <span class="token comment" spellcheck="true"># ignore the escape sequences in a string</span>    <span class="token comment" spellcheck="true"># string alignment</span>    String1 <span class="token operator">=</span> <span class="token string">"|{:&lt;10}|{:^10}|{:>10}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>List<br>list are <em>mutable</em> while tuple is immutable  </li></ul><pre class="line-numbers language-python"><code class="language-python">    <span class="token comment" spellcheck="true"># store in a list using map, split and strip functions</span>    lst <span class="token operator">=</span> list<span class="token punctuation">(</span>map<span class="token punctuation">(</span>int<span class="token punctuation">,</span> input<span class="token punctuation">(</span><span class="token string">"Enter the integer elements:"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>n<span class="token punctuation">]</span>    lst<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'hihi'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># apply function to list</span>    <span class="token keyword">import</span> functools    functools<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token keyword">lambda</span> a<span class="token punctuation">,</span>b<span class="token punctuation">:</span>a<span class="token operator">+</span>b<span class="token punctuation">,</span> lst<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>Set<br>unordered, cannot access by index  </li></ul><pre class="line-numbers language-python"><code class="language-python">    set1  <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>    set1<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    set1<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>Dictionary  </li></ul><pre class="line-numbers language-python"><code class="language-python">    Dict <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    Dict<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>Array  </li></ul><pre class="line-numbers language-python"><code class="language-python">    array<span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>Loop  </li></ul><pre class="line-numbers language-python"><code class="language-python">    L1<span class="token punctuation">,</span> L2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> a<span class="token punctuation">,</span>b <span class="token keyword">in</span> zip<span class="token punctuation">(</span>L1<span class="token punctuation">,</span> L2<span class="token punctuation">)</span><span class="token punctuation">:</span>    d <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'a'</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">}</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> d<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><ul><li>Variable-length arguments<br>*args: Non-Keyword Arguments<br>**kwargs: Keyword Arguments<br>function_name.__doc__: docstring of function</li></ul><p><strong>when we pass a variable to a function, a new reference to the object is created. Same as in Java</strong><br><strong>when we pass a reference and change the received reference to something else, the connection between the passed and received parameter is broken</strong></p><pre class="line-numbers language-python"><code class="language-python">    <span class="token comment" spellcheck="true"># pass by reference or pass by value </span>    <span class="token keyword">def</span> <span class="token function">myFun</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">120</span>    lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>    myFun<span class="token punctuation">(</span>lst<span class="token punctuation">)</span>    myFun<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">)</span>    myFun<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>yield</li></ul><p><em>Return</em> sends a specified value back to its caller whereas <em>Yield</em> can produce a sequence of values.</p><pre class="line-numbers language-python"><code class="language-python">    <span class="token keyword">def</span> <span class="token function">simpleGenerationFun</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">yield</span> <span class="token number">1</span>        <span class="token keyword">yield</span> <span class="token number">2</span>    x <span class="token operator">=</span> simpleGenerationFun<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>next<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p>lambda</p><pre class="line-numbers language-python"><code class="language-python">  x <span class="token operator">=</span> <span class="token string">'Today is Saturday'</span>  <span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># filter &amp; map</span>  a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span>  filtered <span class="token operator">=</span> filter<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token operator">%</span><span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>list<span class="token punctuation">(</span>filtered<span class="token punctuation">)</span><span class="token punctuation">)</span>  mapped <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token operator">%</span><span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>list<span class="token punctuation">(</span>mapped<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p><strong>Functions are objects | can be passed as arguments to other functions | can return another function</strong></p>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Functions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kaggle_Competitons</title>
      <link href="/2022/06/30/space-titanic/"/>
      <url>/2022/06/30/space-titanic/</url>
      
        <content type="html"><![CDATA[<hr><h1 id="Feature-extraction"><a href="#Feature-extraction" class="headerlink" title="Feature extraction"></a>Feature extraction</h1><h2 id="Classic-methods"><a href="#Classic-methods" class="headerlink" title="Classic methods"></a>Classic methods</h2><pre class="line-numbers language-Python"><code class="language-Python">## PCAfrom sklearn.decomposition import PCAfrom matplotlib import pypylot as pltestimator = PCA(n_components=2)X_pca = estimator.fit_transform(X_digits)def plot_pca_scatter():    colors = ['black', 'blue', 'purple', 'yellow', 'white']    for i in xrange(len(colors)):        px = X_pca[:,0][y_digits==i]        py = x_pca[:, 1][y_digits==i]        plt.scatter(px, py, c=colors[i])    plt.legend(digits.target_names)    plt.xlabel('First Principal Component')    plt.ylabel('Second Principal Component')    plt.show()plot_pca_scatter()## Feature_Selectionfrom sklearn.cross_validation import cross_val_scorefrom sklearn import feature_selectionpercentiles = range(1,100,2)results = []for i in percentiles:    fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=i)    X_train_fs = fs.fit_transform(X_train, y_train)    scores = cross_val_score(dt, X_train_fs, t_train, cv=5)    results = np.append(results, scores.mean())print(results)## Grid_Searchfrom sklearn.pipeline import Pipelineclf = Pipeline([('vect', TfidfVectorizer()), ('svc',SVC())])parameters = {'svc_gamma': np.logspace(-1,2,4), 'svc_C': np.logspace(-1,1,3)}gs = GridSearchCV(clf, parameters, verbose=2, refit=True, cv=3)print(gs.best_params_, gs.best_score_, gs.score(X_test, y_test))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Kaggle-Spaceship-Titanic"><a href="#Kaggle-Spaceship-Titanic" class="headerlink" title="Kaggle-Spaceship Titanic"></a>Kaggle-Spaceship Titanic</h2><ol><li><p>Data Statistics</p><ul><li>passengerId: unique ID. Format gggg_pp. gggg indicates passengers travel with same group</li><li>HomePlanet: discrete noun. can be replaced by digits.</li><li>CryoSleep: bool value. seems relevent to final result.</li><li>Cabin: deck/num/side. seems relevent to final result. need further discussion</li><li>Destination: like HomePlanet.</li><li>Age: discrete digits. can be assembled as bins.</li><li>VIP: bool value.</li><li>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck: bill amount. process as Age.</li><li>Name: no use.</li><li>Transported: final results.</li></ul></li><li><p>Data Preprocess</p><ul><li>null value | error value :<br>mean, zero, etc depends on circumstance</li></ul></li><li><p>Model Training Strategy</p><ul><li>Decision Tree | RandomForest | KNN Classifier</li><li>K-Folder crossover</li></ul></li></ol><h2 id="Notifications"><a href="#Notifications" class="headerlink" title="Notifications"></a>Notifications</h2><ol><li>NaN</li></ol><ul><li>Generally speaking, we need to process the NaN value first in the purpose of avoiding the influence for the sequence operations.<br>Nan +/ -/ /* / sth equals Nan</li><li>the <em>NaN</em> value filled should be returned to origin position or just add the <strong>inplace=True</strong> so as to maintain the changes.</li></ul><ol start="2"><li><p>Kaggle strategy</p><pre class="line-numbers language-Python"><code class="language-Python"> # data description from pandas_profiling import ProfileReport profile = ProfileReport(train_df, title='Profileing Report') # data preprocess train_df.drop('Name', axis=1, inplace=True) train_df['Transported'].replace(True, 1, inplace=True) trian_df[['deck', 'num', 'side']] = train_df['Cabin'].str.split('/', expand=True) col_to_sum = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'] train_df['SumSpends'] = train_df[col_to_sum].sum(axis=1) null_cols = train_df.isnull().sum().sort_values(ascending=True) null_cols = list(null_cols[null_cols>1].index) object_cols = [col for col in train_df.columns if train_df[col].dtype=='object' or train_df[col].dtype=='category'] numeric_cols = [col for col in train_df.columns if train_df[col].dtype=='float64'] from sklearn.preprocessing import OrdinalEncoder oc = OrdinalEncoder() df_for_encode = pd.concat([train_df, test_df]) df_for_encode[object_cols] = df_for_encode[object_cols].astype('category') df_for_encode[object_cols] = oc.fit_transform(df_for_encode[object_cols]) from sklearn.impute import SimpleImputer from sklearn.compose import ColumnTransformer ct = ColumnTransformer([('imp', SimpleImputer(strategy='mean'), null_cols)]) train_df[null_cols] = ct.fit_transform(train_df[null_cols]) # Backward feature selection from sklearn.feature_selection import SequentialFeatureSelector model_fs = CatBoostClassifier(verbose=False) sf = SequentialFeatureSelector(model_fs, scoring='accuracy', direction='backward') sf.fit(X, y) best_features = list(sf.get_feature_names_out())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>```</p>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Feature Extraction </tag>
            
            <tag> Kaggle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_base</title>
      <link href="/2022/05/26/pytorch-base/"/>
      <url>/2022/05/26/pytorch-base/</url>
      
        <content type="html"><![CDATA[<h1 id="natural-languare-processing"><a href="#natural-languare-processing" class="headerlink" title="natural languare processing"></a>natural languare processing</h1><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><h3 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h3><ol><li>view() 只改变观察角度</li><li>numpy() from_numpy() 与原始张量共享同一块内存</li></ol><h3 id="Mechanism"><a href="#Mechanism" class="headerlink" title="Mechanism"></a>Mechanism</h3><ul><li>broadcast 自动补齐，维度不足前面加1</li><li>autograd<br>|||<br>|no tracking | tracking|<br>|<code>with torch.no_grad()   .detach()</code>|<code>requires_grad=True x.grad</code>|</li><li><em>torch.nn</em> 实现高层API | <em>torch.nn.functional</em> 实现低层API(仅仅运算功能)</li><li>super(Linear, self).init()继承<em>nn.module</em>的构造函数</li><li><em><strong>init</strong>()</em>层中储存具有可学习参数的层，通过<strong>nn.Parameter()</strong>以parameter形式保存在Module中</li></ul><h2 id="Language-Model"><a href="#Language-Model" class="headerlink" title="Language Model"></a>Language Model</h2><h3 id="n-gram-Model"><a href="#n-gram-Model" class="headerlink" title="n-gram Model"></a>n-gram Model</h3><ul><li>uni bi tri<h3 id="数据缺失"><a href="#数据缺失" class="headerlink" title="数据缺失"></a>数据缺失</h3></li><li>加法平滑</li><li>折扣法</li><li>插值法<h3 id="Wordvector"><a href="#Wordvector" class="headerlink" title="Wordvector"></a>Wordvector</h3></li><li>Continuous Bag-of-Words: 上下文预测中间词</li><li>Skip-gram<h3 id="Hierarchical-Softmax-Negative-Sample"><a href="#Hierarchical-Softmax-Negative-Sample" class="headerlink" title="Hierarchical Softmax  Negative Sample"></a>Hierarchical Softmax  Negative Sample</h3></li><li>哈夫曼树构造：权重低码长长，降低计算复杂度</li><li>Global Vectors:统计全局词汇共现信息学习词向量</li></ul>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python_Skills</title>
      <link href="/2022/04/01/python-skills/"/>
      <url>/2022/04/01/python-skills/</url>
      
        <content type="html"><![CDATA[<h1 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h1><h2 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><ul><li><p>matplotlib.backend_bases.FigureCanvas </p></li><li><p>matplotlib.backend_bases.Renderer</p></li><li><p>matplotlib.artist.Artist 调用Renderer接口在Canvas绘图</p><ul><li>primitives: 标准图形对象(Line2D, text, Rectangle, image)</li><li>containers: figure, Axes, Axis<h3 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h3></li></ul></li><li><p>annotate </p></li><li><p>errorbar | pie | GridSpec(非均匀子图)</p><h2 id="Python-tips"><a href="#Python-tips" class="headerlink" title="Python tips"></a>Python tips</h2><h3 id="map替换标签"><a href="#map替换标签" class="headerlink" title="map替换标签"></a>map替换标签</h3><pre class="line-numbers language-python"><code class="language-python">  c<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'1'</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">}</span>  a<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token operator">=</span>a<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>c<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="text-encoder"><a href="#text-encoder" class="headerlink" title="text encoder"></a>text encoder</h3></li><li><p>sklearn.preprocessing.LabelEncoder(): <em>编码不连续数值或文本</em></p><ul><li><code>le.fit() | le.transform() | le.inverse_transform() | le.classes_</code></li></ul></li><li><p>sklearn.preprocessing.OneHotEncoder():<em>分类特征可能取值转变为二值特征</em></p><h3 id="warning"><a href="#warning" class="headerlink" title="warning"></a>warning</h3></li><li><p>隐藏<em>python</em>级别的警告</p><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> warnings    warnings<span class="token punctuation">.</span>simplefilter<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="variable-save"><a href="#variable-save" class="headerlink" title="variable save"></a>variable save</h3></li><li><p>shelve</p><pre class="line-numbers language-python"><code class="language-python">      <span class="token keyword">import</span> shelve      shelfFile <span class="token operator">=</span> shelve<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">'mydata'</span><span class="token punctuation">)</span>      cats <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Zonphie'</span><span class="token punctuation">,</span> <span class="token string">'Pooka'</span><span class="token punctuation">,</span> <span class="token string">'Simon'</span><span class="token punctuation">]</span>      shelfFile<span class="token punctuation">[</span><span class="token string">'cat'</span><span class="token punctuation">]</span> <span class="token operator">=</span> cat      shelfFile<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>pprint.pformat()</p><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> pprint  cats <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'name'</span><span class="token punctuation">:</span><span class="token string">'Zonphie'</span><span class="token punctuation">,</span> <span class="token string">'desc'</span><span class="token punctuation">:</span><span class="token string">'chubby'</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span><span class="token string">'name'</span><span class="token punctuation">:</span><span class="token string">'Pooka'</span><span class="token punctuation">,</span><span class="token string">'desc'</span><span class="token punctuation">:</span><span class="token string">'fluffy'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>  fileObj <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'myCats.py'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>  fileObj<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'cats = '</span> <span class="token operator">+</span> pprint<span class="token punctuation">.</span>pformat<span class="token punctuation">(</span>cats<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>  fileObj<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="File-amp-Folder"><a href="#File-amp-Folder" class="headerlink" title="File &amp; Folder"></a>File &amp; Folder</h3></li><li><p>删除文件: <code>os.unlink(path)</code></p></li><li><p>删除空文件夹: <code>os.rmdir(path)</code></p></li><li><p>删除整个文件夹: <code>shutil.rmtree(path)</code></p></li><li><p>可恢复删除: </p><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> send2trash  send2trash<span class="token punctuation">.</span>send2trash<span class="token punctuation">(</span><span class="token string">'bacon.txt'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>遍历目录树: <code>os.walk(path)</code> 返回当前文件夹、子文件夹、文件</p><h4 id="zipfile"><a href="#zipfile" class="headerlink" title="zipfile"></a>zipfile</h4><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> zipfile  newZip <span class="token operator">=</span> zipfile<span class="token punctuation">.</span>ZipFile<span class="token punctuation">(</span><span class="token string">'new.zip'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>  newZip<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'micky.txt'</span><span class="token punctuation">,</span> compress_type<span class="token operator">=</span>zipfile<span class="token punctuation">.</span>ZIP_EDFLATED<span class="token punctuation">)</span>  newZip<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 解压缩</span>  <span class="token keyword">import</span> os  newZip<span class="token punctuation">.</span>extractall<span class="token punctuation">(</span><span class="token string">'.\\zip'</span><span class="token punctuation">)</span>  newZip<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>  newZip<span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token string">'animals/micky.txt'</span><span class="token punctuation">,</span> <span class="token string">'G:\\animals\\folders'</span><span class="token punctuation">)</span>  newZip<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="file-search"><a href="#file-search" class="headerlink" title="file search"></a>file search</h4><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> glob  glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*.txt'</span><span class="token punctuation">)</span>  <span class="token keyword">import</span> fnmatch  fnmatch<span class="token punctuation">.</span>fnmatch<span class="token punctuation">(</span>filename<span class="token punctuation">,</span> pattern<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># MD5判断重复文件</span>  <span class="token keyword">import</span> hashlib  m <span class="token operator">=</span> hashlib<span class="token punctuation">.</span>md5<span class="token punctuation">(</span><span class="token punctuation">)</span>  f <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'bacon.txt'</span><span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span>  m<span class="token punctuation">.</span>update<span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>  md5_value <span class="token operator">=</span> m<span class="token punctuation">.</span>hexdigest<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="automatic-mail"><a href="#automatic-mail" class="headerlink" title="automatic mail"></a>automatic mail</h4><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> smtplib  <span class="token keyword">from</span> smtplib <span class="token keyword">import</span> SMTP_SSL <span class="token comment" spellcheck="true"># 加密邮件内容</span>  <span class="token keyword">from</span> email<span class="token punctuation">.</span>mime<span class="token punctuation">.</span>text <span class="token keyword">import</span> MIMEText  <span class="token keyword">from</span> email<span class="token punctuation">.</span>mime<span class="token punctuation">.</span>image <span class="token keyword">import</span> MIMEImage  <span class="token keyword">from</span> email<span class="token punctuation">.</span>mime<span class="token punctuation">.</span>multipart <span class="token keyword">import</span> MIMEMlutipart  <span class="token keyword">from</span> email<span class="token punctuation">.</span>header <span class="token keyword">import</span> Header  host_server <span class="token operator">=</span> <span class="token string">'smtp.163.com'</span> <span class="token comment" spellcheck="true"># smtp server address</span>  sender_163 <span class="token operator">=</span> <span class="token string">'pythonauto_email@163.com'</span>  pwd <span class="token operator">=</span> <span class="token string">'DAFAPFAGGFA'</span> <span class="token comment" spellcheck="true">#邮件授权码</span>  receiver <span class="token operator">=</span> <span class="token string">'mingming@buaa.edu.cn'</span>  msg <span class="token operator">=</span> MIMEMlutipart<span class="token punctuation">(</span><span class="token punctuation">)</span>  mail_title <span class="token operator">=</span> <span class="token string">'automatic pythonauto_email'</span>  msg<span class="token punctuation">[</span><span class="token string">'Subject'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Header<span class="token punctuation">(</span>mail_title<span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span>  msg<span class="token punctuation">[</span><span class="token string">'From'</span><span class="token punctuation">]</span> <span class="token operator">=</span> sender_163  msg<span class="token punctuation">[</span><span class="token string">'To'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Header<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span>  mail_content <span class="token operator">=</span> <span class="token string">'today is a sunny day'</span>  message_text <span class="token operator">=</span> MIMEText<span class="token punctuation">(</span>mail_content<span class="token punctuation">,</span> <span class="token string">'plain'</span><span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span>  msg<span class="token punctuation">.</span>attach<span class="token punctuation">(</span>message_text<span class="token punctuation">)</span>  image_data <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'G:\\image\\zpphine.jpg'</span><span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span>  message_image <span class="token operator">=</span> MIMEImage<span class="token punctuation">(</span>image_data<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  image_data<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>  msg<span class="token punctuation">.</span>attach<span class="token punctuation">(</span>message_image<span class="token punctuation">)</span>  atta <span class="token operator">=</span> MIMEText<span class="token punctuation">(</span>open<span class="token punctuation">(</span><span class="token string">'G:\\cat.xlsx'</span><span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'base64'</span><span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span>  atta<span class="token punctuation">[</span><span class="token string">'Content-Disposition'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'attachment; filename="cat.xlsx"'</span>  msg<span class="token punctuation">.</span>attach<span class="token punctuation">(</span>atta<span class="token punctuation">)</span>  smtp <span class="token operator">=</span> SMTP_SSL<span class="token punctuation">(</span>host_server<span class="token punctuation">)</span>  smtp<span class="token punctuation">.</span>login<span class="token punctuation">(</span>sender_163<span class="token punctuation">,</span> pwd<span class="token punctuation">)</span>  smtp<span class="token punctuation">.</span>sendmail<span class="token punctuation">(</span>sender_163<span class="token punctuation">,</span> receiver<span class="token punctuation">,</span> msg<span class="token punctuation">.</span>as_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'mail has been send successfully!'</span><span class="token punctuation">)</span>  smtp<span class="token punctuation">.</span>quit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Excel"><a href="#Excel" class="headerlink" title="Excel"></a>Excel</h3><p>依赖:openpyxl, xlrd, xlwings</p><pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> openpyxl  wb <span class="token operator">=</span> openpyxl<span class="token punctuation">.</span>load_workbook<span class="token punctuation">(</span><span class="token string">'G:\\habits.xlsx'</span><span class="token punctuation">)</span>  sheet <span class="token operator">=</span> wb<span class="token punctuation">.</span>get_sheet_by_name<span class="token punctuation">(</span><span class="token string">'Sheet3'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># obtain data via rows</span>  rows <span class="token operator">=</span> sheet<span class="token punctuation">.</span>iter_rows<span class="token punctuation">(</span>min_row<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> max_row<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> min_col<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> max_col<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token keyword">for</span> row <span class="token keyword">in</span> rows<span class="token punctuation">:</span>      <span class="token keyword">for</span> cell <span class="token keyword">in</span> row<span class="token punctuation">:</span>          <span class="token keyword">print</span><span class="token punctuation">(</span>cell<span class="token punctuation">.</span>value<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">'|'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># create new sheet</span>  <span class="token keyword">from</span> openpyxl <span class="token keyword">import</span> Workbook  wb <span class="token operator">=</span> Workbook<span class="token punctuation">(</span><span class="token punctuation">)</span>  sheet <span class="token operator">=</span> wb<span class="token punctuation">.</span>create_sheet<span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'mysheet'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># write formula</span>  sheet<span class="token punctuation">[</span><span class="token string">'D1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'=SUM(D2:D14)'</span>  wb<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'formula.xlsx'</span><span class="token punctuation">)</span>  <span class="token keyword">import</span> xlwings <span class="token keyword">as</span> xw  app <span class="token operator">=</span> xw<span class="token punctuation">.</span>App<span class="token punctuation">(</span>visible<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> add_book<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  wb <span class="token operator">=</span> app<span class="token punctuation">.</span>books<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">'formula.xlsx'</span><span class="token punctuation">)</span>  wb<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>  wb<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>  app<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># basic options</span>  sheet<span class="token punctuation">.</span>insert_cols<span class="token punctuation">(</span>idx<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  sheet<span class="token punctuation">.</span>delete_cols<span class="token punctuation">(</span>idx<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>amount<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>  sheet<span class="token punctuation">.</span>move_range<span class="token punctuation">(</span><span class="token string">'A1:B2'</span><span class="token punctuation">,</span> rows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> cols<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h3 id="decorate"><a href="#decorate" class="headerlink" title="decorate"></a>decorate</h3><ul><li>统一模板：<pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">from</span> functools <span class="token keyword">import</span> wraps  <span class="token keyword">def</span> <span class="token function">decorate</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>      @wraps<span class="token punctuation">(</span>func<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">wrapper</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>          result <span class="token operator">=</span> func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>          <span class="token keyword">return</span> result      <span class="token keyword">return</span> wrapper<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="Pandas-tips"><a href="#Pandas-tips" class="headerlink" title="Pandas tips"></a>Pandas tips</h2><h3 id="datatime"><a href="#datatime" class="headerlink" title="datatime"></a>datatime</h3><ul><li><p>to_datetime | .dt.dayofweek | .dt.month</p><h3 id="index"><a href="#index" class="headerlink" title="index"></a>index</h3></li><li><p>loc:通过选取标签索引数据<br>  <strong>标签索引会将切片末端包含进去</strong></p><pre class="line-numbers language-python"><code class="language-python">      df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token string">'index0'</span><span class="token punctuation">]</span>      df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token string">'index0'</span><span class="token punctuation">:</span><span class="token string">'index3'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>iloc:通过选取位置编号索引数据<br>  <strong>位置编号索引不会将切片末端包含进去</strong></p><pre class="line-numbers language-python"><code class="language-python">      df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>      df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>reset_index: 修改索引行，设置<em>drop=True</em>可丢弃原索引列</p></li><li><p>sort_values(by=’a’, ascending=True) | sort_index(axis=1)</p></li><li><p>data_analyse func</p><pre class="line-numbers language-python"><code class="language-python">  df<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 数据基本信息</span>  df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>  df<span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>  df<span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span>  df<span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span>  df<span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>nunique<span class="token punctuation">(</span><span class="token punctuation">)</span>  df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span> <span class="token operator">==</span> np<span class="token punctuation">.</span>nan<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>  df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> how <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">)</span>  df<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>method<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> value<span class="token operator">=</span>values<span class="token punctuation">)</span>  df<span class="token punctuation">[</span>df<span class="token punctuation">.</span>duplicated<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop_duplicates<span class="token punctuation">(</span><span class="token punctuation">)</span>  df<span class="token punctuation">[</span><span class="token string">'AgeBand'</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  df<span class="token punctuation">[</span><span class="token string">'AgeBand'</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>qcut<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder  <span class="token keyword">for</span> feat <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">,</span> <span class="token string">'Ticket'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>      lbl <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>      label_dict <span class="token operator">=</span> dict<span class="token punctuation">(</span>zip<span class="token punctuation">(</span>df<span class="token punctuation">[</span>feat<span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> range<span class="token punctuation">(</span>df<span class="token punctuation">[</span>feat<span class="token punctuation">]</span><span class="token punctuation">.</span>nunique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      df<span class="token punctuation">[</span>feat<span class="token operator">+</span> <span class="token string">"_labelEncode"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span>feat<span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>label_dict<span class="token punctuation">)</span>      df<span class="token punctuation">[</span>feat <span class="token operator">+</span> <span class="token string">"_labelEncode"</span><span class="token punctuation">]</span> <span class="token operator">=</span> lbl<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df<span class="token punctuation">[</span>feat<span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Onehot encoder</span>  <span class="token keyword">for</span> feat <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">,</span> <span class="token string">"Embark"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>      x <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>df<span class="token punctuation">[</span>feat<span class="token punctuation">]</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span>feat<span class="token punctuation">)</span>      df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span> x<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  df<span class="token punctuation">[</span><span class="token string">'Title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>Name<span class="token punctuation">.</span>str<span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token string">'()'</span><span class="token punctuation">,</span> expand<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 数据重构</span>  pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span> left_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> right_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  result_up<span class="token punctuation">.</span>append<span class="token punctuation">(</span>result_down<span class="token punctuation">)</span>  pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>result_up<span class="token punctuation">,</span> result_down<span class="token punctuation">]</span><span class="token punctuation">)</span>  text_left_up<span class="token punctuation">.</span>join<span class="token punctuation">(</span>text_right_up<span class="token punctuation">)</span>  result<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#列旋转为行</span>  result<span class="token punctuation">.</span>unstack<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 行旋转为列</span>  text<span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>groupby<span class="token punctuation">(</span>text<span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>  text<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">'Sex'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>agg<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'Fare'</span><span class="token punctuation">:</span><span class="token string">'mean'</span><span class="token punctuation">,</span> <span class="token string">'Pclass'</span><span class="token punctuation">:</span><span class="token string">'count'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'Fare'</span><span class="token punctuation">:</span><span class="token string">'mean_fare'</span><span class="token punctuation">,</span><span class="token string">'Pclass'</span><span class="token punctuation">:</span><span class="token string">'count_pclass'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>  text<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">,</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unstack<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind<span class="token operator">=</span><span class="token string">'bar'</span><span class="token punctuation">,</span>stacked<span class="token operator">=</span><span class="token string">'True'</span><span class="token punctuation">)</span>  facet <span class="token operator">=</span> sns<span class="token punctuation">.</span>FacetGrid<span class="token punctuation">(</span>text<span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token string">'Survived'</span><span class="token punctuation">,</span> aspect<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  facet<span class="token punctuation">.</span>map<span class="token punctuation">(</span>sns<span class="token punctuation">.</span>kdeplot<span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">,</span> shade<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  facet<span class="token punctuation">.</span>set<span class="token punctuation">(</span>xlim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> text<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  facet<span class="token punctuation">.</span>add_legend<span class="token punctuation">(</span><span class="token punctuation">)</span>  text<span class="token punctuation">.</span>Age<span class="token punctuation">[</span>text<span class="token punctuation">.</span>Pclass<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind<span class="token operator">=</span><span class="token string">'kde'</span><span class="token punctuation">)</span>  text<span class="token punctuation">.</span>Age<span class="token punctuation">[</span>text<span class="token punctuation">.</span>Pclass<span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind<span class="token operator">=</span><span class="token string">'kde'</span><span class="token punctuation">)</span>  text<span class="token punctuation">.</span>Age<span class="token punctuation">[</span>text<span class="token punctuation">.</span>Pclass<span class="token operator">==</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind<span class="token operator">=</span><span class="token string">'kde'</span><span class="token punctuation">)</span>  plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'age'</span><span class="token punctuation">)</span>  plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><pre><code>model = [&#39;rfc&#39;, &#39;gddt&#39;]temp = []rfc = RandomForestClassifier(random_state=0)params = {&#39;n_estimators&#39;:[50, 100]}temp.append([rfc, params])for i in range(len(model)):    best_model = GridSearchCV(temp[i][0], param_grid=temp[i][1], refit=True, cv=5).fit(train, train_label)    print(model[i], &#39;:&#39;)    print(&#39;best parameters:&#39;, best_model.best_params_)</code></pre><pre><code># Pytorch ## Function### Tips- clone():不共享数据内存，但提供梯度回溯- detach():共享数据内存，不提供梯度回溯- new_tensor():不共享不提供- 类型转换: ```python    tensor.type(torch.IntTensor)    tensor.type_as(tensor)    tensor.int()</code></pre><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><ul><li>Sequential:简单串联各层计算，接收OrderedDict或者子模块作为参数<pre class="line-numbers language-python"><code class="language-python">  <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn  net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>      nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用OrderedDict</span>  <span class="token keyword">import</span> collections  net2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>      collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>          <span class="token punctuation">(</span><span class="token string">'fc1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>RelU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>          <span class="token punctuation">(</span><span class="token string">'fc2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h2><ul><li><p>Hook</p><pre class="line-numbers language-python"><code class="language-python">          <span class="token keyword">class</span> <span class="token class-name">Hook</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>                  self<span class="token punctuation">.</span>module_name <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                  self<span class="token punctuation">.</span>features_in_hook <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                  self<span class="token punctuation">.</span>features_out_hook <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>              <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module<span class="token punctuation">,</span> fea_in<span class="token punctuation">,</span> fea_out<span class="token punctuation">)</span><span class="token punctuation">:</span>                  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hooker working"</span><span class="token punctuation">,</span> self<span class="token punctuation">)</span>                  self<span class="token punctuation">.</span>module_name<span class="token punctuation">.</span>append<span class="token punctuation">(</span>module<span class="token punctuation">.</span>__class__<span class="token punctuation">)</span>                  self<span class="token punctuation">.</span>feature_in_hook<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fea_in<span class="token punctuation">)</span>                  self<span class="token punctuation">.</span>features_out_hook<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fea_out<span class="token punctuation">)</span>          <span class="token keyword">def</span> <span class="token function">plot_feature</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>              hh <span class="token operator">=</span> Hook<span class="token punctuation">(</span><span class="token punctuation">)</span>              model<span class="token punctuation">.</span>features<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">.</span>register_forward_hook<span class="token punctuation">(</span>hh<span class="token punctuation">)</span>              forward_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span>              <span class="token keyword">print</span><span class="token punctuation">(</span>hh<span class="token punctuation">.</span>module_name<span class="token punctuation">)</span>              <span class="token keyword">print</span><span class="token punctuation">(</span>hh<span class="token punctuation">.</span>features_in_hook<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>              <span class="token keyword">print</span><span class="token punctuation">(</span>hh<span class="token punctuation">.</span>features_out_hook<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>              out1 <span class="token operator">=</span> hh<span class="token punctuation">.</span>features_out_hook<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>              total_ft <span class="token operator">=</span> out1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>              first_item <span class="token operator">=</span> out1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>              plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">)</span><span class="token punctuation">)</span>              <span class="token keyword">for</span> ftidx <span class="token keyword">in</span> range<span class="token punctuation">(</span>total_ft<span class="token punctuation">)</span><span class="token punctuation">:</span>                  <span class="token keyword">if</span> ftidx<span class="token operator">></span> <span class="token number">99</span><span class="token punctuation">:</span>                      <span class="token keyword">break</span>                  ft <span class="token operator">=</span> first_item<span class="token punctuation">[</span>ftidx<span class="token punctuation">]</span>                  plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> ftidx<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>                  plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>                  plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>ft<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      ```<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>CAM</p><pre class="line-numbers language-python"><code class="language-python">          <span class="token keyword">import</span> torch          <span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">import</span> vgg11<span class="token punctuation">,</span> resnet18<span class="token punctuation">,</span> resnet101<span class="token punctuation">,</span> resnext101_32x8d          <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt          <span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image          <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np          model <span class="token operator">=</span> vgg11<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>          img_path <span class="token operator">=</span> <span class="token string">'./dog.jpg'</span>          img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span>          rgb_img <span class="token operator">=</span> np<span class="token punctuation">.</span>float32<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255</span>          plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>          <span class="token keyword">from</span> pytorch_grad_cam <span class="token keyword">import</span> GradCAM<span class="token punctuation">,</span> ScoreCAM<span class="token punctuation">,</span> GradCAMPlusPlus<span class="token punctuation">,</span> AblationCAM<span class="token punctuation">,</span> XGradCAM<span class="token punctuation">,</span> EigenCAM<span class="token punctuation">,</span> FullGradCAM          <span class="token keyword">from</span> pytorch_grad_cam<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>model_targets <span class="token keyword">import</span> ClassifierOutputTarget          <span class="token keyword">from</span> pytorch_grad_cam<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>image <span class="token keyword">import</span> show_cam_on_image          <span class="token comment" spellcheck="true"># ScoreCAM 和AblationCAM需要batch_size</span>          target_layers <span class="token operator">=</span> <span class="token punctuation">[</span>model<span class="token punctuation">.</span>feature<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>          cam <span class="token operator">=</span> GradCAM<span class="token punctuation">(</span>model<span class="token operator">=</span>model<span class="token punctuation">,</span> target_layers<span class="token operator">=</span>target_layers<span class="token punctuation">)</span>          targets <span class="token operator">=</span> <span class="token punctuation">[</span>ClassifierOutputTarget<span class="token punctuation">]</span>          grayscale_cam <span class="token operator">=</span> cam<span class="token punctuation">(</span>input_tensor<span class="token operator">=</span>img_tensor<span class="token punctuation">,</span> targets<span class="token operator">=</span>targets<span class="token punctuation">)</span>          grayscale_cam <span class="token operator">=</span> grayscale_cam<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>          cam_img <span class="token operator">=</span> show_cam_on_image<span class="token punctuation">(</span>rgb_img<span class="token punctuation">,</span> grayscale_cam<span class="token punctuation">,</span> use_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>          <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>cam_img<span class="token punctuation">)</span><span class="token punctuation">)</span>          Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>cam_img<span class="token punctuation">)</span>      ```<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>FlashTorch</p><pre><code>  ```python      import matplotlib.pyplot as plt      import torchvision.models as models      from flashtorch.utils import apply_transforms, load_image      from flashtorch.saliency import Backprop      model = models.alexnet(pretrained=True)      backprop = Backprop(model)      image = load_image(&#39;./image.jpg&#39;)      owl = apply_transforms(image)      target_class = 24      backprop.visualize(owl, target_class, guided=True, use_gpu=True)  ```</code></pre></li></ul><h2 id="Emotion-Classifier-APIs"><a href="#Emotion-Classifier-APIs" class="headerlink" title="Emotion Classifier APIs"></a>Emotion Classifier APIs</h2><ul><li><p>HuggingFace</p><pre class="line-numbers language-python"><code class="language-python">      <span class="token keyword">from</span> transformers <span class="token keyword">import</span> DistilBertTokenizerFast      <span class="token keyword">from</span> transformers <span class="token keyword">import</span> TFDistilBertForSequenceClassification<span class="token punctuation">,</span> TFTrainer<span class="token punctuation">,</span> TFTrainingArguments      tokenizer <span class="token operator">=</span> DistilBertTokenizerFast<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'distilbert-base-uncased'</span><span class="token punctuation">)</span>      train_encodings <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>train_texts<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>      val_encodings <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>val_texts<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>      test_encodings <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>test_texts<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>      training_args <span class="token operator">=</span> TFTrainingArguments<span class="token punctuation">(</span>          output_dir<span class="token operator">=</span><span class="token string">'./results'</span><span class="token punctuation">,</span>          num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>          per_device_train_batch_size<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>          per_device_eval_batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>          warmup_steps<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>          weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>          logging_dir<span class="token operator">=</span><span class="token string">'./logs'</span><span class="token punctuation">,</span>          logging_steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">)</span>      model <span class="token operator">=</span> TFDistilBertForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'distilbert-base-uncased'</span><span class="token punctuation">)</span>      trainer <span class="token operator">=</span> TFTrainer<span class="token punctuation">(</span>          model<span class="token operator">=</span>model<span class="token punctuation">,</span>          args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>          train_dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>          eval_dataset<span class="token operator">=</span>eval_dataset<span class="token punctuation">)</span>      trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>simpletransformers</p><pre class="line-numbers language-python"><code class="language-python">      <span class="token keyword">from</span> simpletransformers<span class="token punctuation">.</span>classification <span class="token keyword">import</span> ClassificationModel      train_args <span class="token operator">=</span> <span class="token punctuation">{</span>          <span class="token string">'num_train_epochs'</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span>          <span class="token string">'train_batch_size'</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">,</span>          <span class="token string">'eval_batch_size'</span><span class="token punctuation">:</span> <span class="token number">64</span><span class="token punctuation">,</span>          <span class="token string">'warmup_steps'</span><span class="token punctuation">:</span> <span class="token number">500</span><span class="token punctuation">,</span>          <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0.01</span><span class="token punctuation">,</span>          <span class="token string">'logging_steps'</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span>          <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span>          <span class="token string">'fp16'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span>          <span class="token string">'wandb_project'</span><span class="token punctuation">:</span> <span class="token string">'gallery'</span><span class="token punctuation">,</span>          <span class="token string">'wandb_kwargs'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'entity'</span><span class="token punctuation">:</span> <span class="token string">'wandb'</span><span class="token punctuation">}</span>      <span class="token punctuation">}</span>      model <span class="token operator">=</span> ClassificationModel<span class="token punctuation">(</span><span class="token string">'distilbert'</span><span class="token punctuation">,</span> <span class="token string">'distilbert-base-uncased'</span><span class="token punctuation">,</span> use_cuda<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> cuda_device<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> args<span class="token operator">=</span>train_args<span class="token punctuation">)</span>      model<span class="token punctuation">.</span>train_model<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h2 id="Gradient-Boosting-Descent-Machine"><a href="#Gradient-Boosting-Descent-Machine" class="headerlink" title="Gradient Boosting Descent Machine"></a>Gradient Boosting Descent Machine</h2><p><img src="https://zhuanlan.zhihu.com/p/99069186" alt="参考链接"></p><ul><li><p>GBDM: 每次迭代都需要遍历整个训练数据多次</p></li><li><p>XGBOOST: 基于预排序方法的决策树算法</p><ul><li>Level-wise 增长策略:不容易过拟合，容易进行多线程优化，控制模型复杂度，但效率较低</li><li>Modified Preorder Tree Taversal: 用于层级关系的存储和遍历, 解决邻接表递归查询低效问题，但不适用于增删改操作较多的场景<br>  <img src="https://zhuanlan.zhihu.com/p/91176792" alt="参考链接"><pre class="line-numbers language-sql"><code class="language-sql">      <span class="token comment" spellcheck="true"># 创建数据表</span>      <span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token string">'product_category'</span> <span class="token punctuation">(</span>          <span class="token string">'id'</span> <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">AUTO_INCREMENT</span><span class="token punctuation">,</span>          category_name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token boolean">null</span><span class="token punctuation">,</span>          left_value <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token boolean">null</span><span class="token punctuation">,</span>          right_value <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token boolean">null</span><span class="token punctuation">,</span>          <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span><span class="token string">'id'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-sql"><code class="language-sql">      <span class="token comment" spellcheck="true"># 插入子分类</span>      <span class="token keyword">INSERT</span> <span class="token keyword">into</span> product_category<span class="token punctuation">(</span>category_name<span class="token punctuation">,</span> <span class="token string">'left_value'</span><span class="token punctuation">,</span> <span class="token string">'right_value'</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># 插入数据</span>      <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token string">'food'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true"># 锁表 防止被同时修改导致数据不一致</span>      <span class="token keyword">lock</span> <span class="token keyword">table</span> <span class="token string">'product_category'</span> <span class="token keyword">write</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true"># 插入子分类</span>      <span class="token keyword">select</span> <span class="token variable">@myLeft</span> :<span class="token operator">=</span> <span class="token string">'left_value'</span>       <span class="token keyword">from</span> <span class="token string">'product_category'</span>      <span class="token keyword">where</span> category_name <span class="token operator">=</span> <span class="token string">'food'</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true"># 更新受影响分类左右区间值</span>      <span class="token keyword">update</span> product_category <span class="token keyword">SET</span> left_value<span class="token operator">=</span>left_value <span class="token operator">+</span><span class="token number">2</span> <span class="token keyword">where</span> left_value<span class="token operator">></span><span class="token variable">@myLeft</span><span class="token punctuation">;</span>      <span class="token keyword">update</span> product_category      <span class="token keyword">SET</span> right_value<span class="token operator">=</span>right_value <span class="token operator">+</span> <span class="token number">2</span> <span class="token keyword">where</span> right_value<span class="token operator">></span><span class="token variable">@myLeft</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true"># 插入子分类信息</span>      <span class="token keyword">INSERT</span> <span class="token keyword">into</span> product_category<span class="token punctuation">(</span>category_name<span class="token punctuation">,</span> <span class="token string">'left_value'</span><span class="token punctuation">,</span> <span class="token string">'right_value'</span><span class="token punctuation">)</span>      <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token string">'meat'</span><span class="token punctuation">,</span> <span class="token variable">@myLeft</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token variable">@myLeft</span><span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true"># 解除锁表</span>      unlock <span class="token keyword">tables</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-sql"><code class="language-sql">      <span class="token comment" spellcheck="true"># 查询指定分类子分类</span>      <span class="token keyword">select</span> <span class="token variable">@myLeft</span> :<span class="token operator">=</span> <span class="token string">'left_value'</span><span class="token punctuation">,</span> <span class="token variable">@myRight</span> :<span class="token operator">=</span> <span class="token string">'right_value'</span>      <span class="token keyword">from</span> <span class="token string">'product_category'</span>      <span class="token keyword">where</span> <span class="token string">'category_name'</span><span class="token operator">=</span><span class="token string">'meat'</span><span class="token punctuation">;</span>      <span class="token keyword">select</span> <span class="token operator">*</span>       <span class="token keyword">from</span> <span class="token string">'product_caegory'</span>      <span class="token keyword">where</span> <span class="token string">'left_value'</span> <span class="token operator">>=</span> <span class="token variable">@myLeft</span> <span class="token operator">and</span> <span class="token string">'right_value'</span> <span class="token operator">&lt;=</span> <span class="token variable">@myRight</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p>LightGBM: </p><ul><li>基于Histogram的决策树算法<ul><li>内存占用少，计算代价小</li><li>差加速: 叶子节点直方图由父节点和相邻节点作差得到，<strong>只使用非零特征构建直方图</strong></li></ul></li><li>Leaf_wise 增长策略<ul><li>在分裂次数相同的情况下，可以降低更多的误差</li><li>但可能会长出比较深的决策树，产生过拟合，需要增加最大深度限制，在保证高效率的同时防止过拟合    </li></ul></li><li>Gradient-based One-Side Sampling: 从减少样本的角度出发，排除大部分对计算信息增益没有帮助的小梯度样本</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Technology </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Functions </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
